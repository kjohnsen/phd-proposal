[
  {
    "objectID": "specific-aims.html#aim-1-a-cloc-experiment-simulation-testbed",
    "href": "specific-aims.html#aim-1-a-cloc-experiment-simulation-testbed",
    "title": "2  Specific Aims",
    "section": "Aim 1: A CLOC experiment simulation testbed",
    "text": "Aim 1: A CLOC experiment simulation testbed\nOne significant obstacle to closed-loop optogenetic control (CLOC) experiments is the cost of acquiring and configuring compatible hardware-software systems. Moreover, the maintenance of animals or cell cultures inherent in lab experiments can slow the pace of developing novel techniques. In Aim 1, I attempt to address these obstacles by developing a simulation framework for easily prototyping CLOC experiments in silico, thus enabling faster, cheaper CLOC experiment design and method development. We demonstrate the software’s utility in different virtual experiments and provide it to the public as open-source software with thorough documentation."
  },
  {
    "objectID": "specific-aims.html#aim-2-bidirectional-cloc",
    "href": "specific-aims.html#aim-2-bidirectional-cloc",
    "title": "2  Specific Aims",
    "section": "Aim 2: Bidirectional CLOC",
    "text": "Aim 2: Bidirectional CLOC\nBidirectional CLOC—the simultaneous use of both excitatory and inhibitory opsins—is necessary for precise manipulation of neural systems, especially when maintaining naturalistic activity levels is important. However, the basic control theory methods previously used in conjuction with CLOC do not take actuator constraints into account and are thus inadequate for multi-actuator (i.e., multi-light source) problems. The field of control theory provides elegant, powerful solutions to this class of problems, but applying them requires interdisciplinary expertise. In this aim I will translate more sophisticated model-based feedback control algorithms to the bidirectional CLOC setting and demonstrate the advantages both of bidirectional actuation and these algorithmic improvements."
  },
  {
    "objectID": "specific-aims.html#aim-3-using-cloc-to-manipulate-latent-neural-dynamics",
    "href": "specific-aims.html#aim-3-using-cloc-to-manipulate-latent-neural-dynamics",
    "title": "2  Specific Aims",
    "section": "Aim 3: Using CLOC to manipulate latent neural dynamics",
    "text": "Aim 3: Using CLOC to manipulate latent neural dynamics\nTo our knowledge, CLOC has yet to be applied in answering complex systems neuroscience questions. In this aim, to pave the way for future in-vivo experiments that accomplish this, I propose to develop technical and conceptual guidelines as I control the latent dynamics of simulated neural populations. First, I will produce these virtual models by training recurrent spiking neural networks with state-of-the-art, biologically plausible methods—each differing in their degrees of brain-like architecture and training procedure complexity. I will then use the simulation testbed of Aim 1 to explore how recording, stimulation, and control requirements vary with the complexity and size of the system—thus giving researchers some idea of the relative importance of each factor of CLOC. Finally, I will demonstrate the conceptual utility of CLOC by quantitatively assessing the causal relationship between these latent dynamics and “behavior” (model output)."
  },
  {
    "objectID": "background.html#sec-cl-neuro",
    "href": "background.html#sec-cl-neuro",
    "title": "3  Background",
    "section": "Closed-loop control in neuroscience",
    "text": "Closed-loop control in neuroscience\nMesoscale neuroscience is currently undergoing a revolution fueled by advances in neural manipulation (1–8) and measurement (9–16) technologies as well as data analysis methods (17–22). These have yielded unprecedented datasets (23, 24) and insights into network activity and plasticity (25–29), as well as novel experimental paradigms such as direct closed-loop control of neural activity (30–40).\nAn exciting emerging possibility is closed-loop control of neural activity (30, other-reviews?), enabling intervention in processes that are too fast or unpredictable to control manually or with pre-defined stimulation, such as sensory information processing, motor planning, and oscillatory activity. Unlike other forms of closed-loop control altering the environment [cite examples, mouse knee rotation, visual stimuli to achieve target response,] or using neurofeedback training (8) to achieve a neural or behavioral target, the direct control of neural activity itself can unambiguously reveal the downstream effects of that activity.\n\nTypes of closed-loop control\nClosed-loop control of neural activity can be implemented in an event-triggered sense [cite a bunch of examples, inhibiting seizures, altering power, SWR disruption, ]—enabling the experimenter to respond to discrete events of interest, such as the arrival of a traveling wave [cite Reynolds] or sharp wave ripple [cite some review paper]—or in a feedback sense [cite 2 Bolus papers, all-optical, any others], driving the system towards a target or along a trajectory. The latter has multiple advantages over open-loop control (delivery of a pre-defined stimulus): by rejecting exogenous inputs, noise, and disturbances, it reduces variability across time and across trials, allowing for finer-scale inference. Additionally, it can compensate for model mismatch, allowing it to succeed where open-loop control based on imperfect models is bound to miss the mark. Moreover, whereas traditional perturbation methods include lesioning (41), unnatural silencing, or extreme stimulation, feedback control poses a more naturalistic alternative, increasing generalizability."
  },
  {
    "objectID": "background.html#various-scales-and-tools-for-closed-loop-control",
    "href": "background.html#various-scales-and-tools-for-closed-loop-control",
    "title": "3  Background",
    "section": "Various scales and tools for closed-loop control",
    "text": "Various scales and tools for closed-loop control\nClosed-loop control of neural activity can be performed at multiple scales and with different sets of tools. At the smallest, sub-neuron scale, dynamic clamping has yielded decades of fruitful research (hodgkin53?, cite? some-review-paper) in the forms of tools such as the dynamic clamp and voltage clamp, controlling electrical properties of small patches of membrane. The frontiers of this small-scale neuroscience often involve scaling up to multiple neurons and scaling down to subcellular structures such as dendrites (cite?), but multi-electrode intracellular recording face limitations (42–44, cite? more, not just patch clamping). Optical tools—e.g., optogenetics and fluorescence microscopy—can circumvent the difficulties of working with electrodes at such small scales, but an optical approach is not yet feasible for this purpose. The obstacles lie mainly in recording technology: the kinetics of both voltage indicators (16) and intracellular calcium (cite?) are too slow to capture phenomena faster than a typical action potential.\nBy contrast, the current state of technology is ripe for innovating closed-loop control methods at larger scales of neural activity, from single neurons to populations and circuits. Several promising combinations of recording and stimulation modalities are possible and still relatively novel: electrode recording with optogenetic stimulation (45, our papers), fluorescence microscopy with electrical stimulation (cite?), fluorescence microscopy with photostimulation (all-optical control) (36, 37, 46, 47, flytzanis14?), and fMRI with optionally transcranial (48, 49) photostimulation. Each of these tool combinations has pros and cons in terms of spatial and temporal resolution, crosstalk (50), and degrees of freedom.\nA natural starting point for many neuroscientists is the first of these tool sets—electrode recording combined with optogenetics—since the two methods are so widely used, interfere little with each other (as long as metal electrodes are not directly illuminated (45, 50)), and allow for genetically targeted stimulation. I will henceforth refer to this combination as CLOC, following the convention established by previous works (34, 35)."
  },
  {
    "objectID": "background.html#sec-prev-work",
    "href": "background.html#sec-prev-work",
    "title": "3  Background",
    "section": "Previous work",
    "text": "Previous work\nThe proposed work builds on the work my lab and collaborators have done previously in implementing CLOC feedback control. Newman et al. (33) demonstrated bidirectional CLOC for fixed firing and slowly varying rate targets and using a model-free proportional-integral (PI) control scheme in silico (Figure 3.1 (a)), as well as unidirectional integral control in the anesthetized rat. Bolus et al. (34) used PI control again, but developed a more principled approach to set estimation and control parameters and tracked dynamic firing rate trajectories down to a ~100-ms timescale (Figure 3.1 (b)). Bolus et al. later employed more sophisticated and scalable optimal feedback control methods which are more robust to disturbances—important especially in awake animal experiments, where dynamic brain state changes contribute to high per-trial variability (Figure 3.1 (c)).\n\n\n\n\n\n\n(a)\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n(c)\n\n\n\nFigure 3.1: Previous CLOC experiments. (A) Figure 2 from (33), demonstrating control clamping a cultured neuron to different firing rates. \\(U_C\\) refers to the control signal for channelrhodopsin2(H134R) (ChR2R), parametrizing 470-nm light delivery. \\(U_H\\) likewise parametrizes 590-nm light delivery to activate enhanced halorhodopsin-3.0 (eNpHR3.0). (B) Figure 2 from (34), outlining an in-vivo experiment setup, a control diagram showing how optical input is determined from the firing rate estimated in real time, and a strategy for tuning the controller. (C) Figure 4b from (35), showing how CLOC clamps the firing rate of a single thalamic neuron in the awake mouse over multiple trials, reducing response variability (as measured by the Fano factor)."
  },
  {
    "objectID": "background.html#potential-applications-in-mesoscale-neuroscience",
    "href": "background.html#potential-applications-in-mesoscale-neuroscience",
    "title": "3  Background",
    "section": "Potential applications in mesoscale neuroscience",
    "text": "Potential applications in mesoscale neuroscience\nSeeing that a suitable technological foundation for feedback control of neural activity has already been laid with CLOC, I turn now to a discussion of several exciting areas where CLOC could further causal hypothesis testing. These deal with concrete questions of scientific interest, as opposed to the conceptual/technical advantages previously explained (Section 3.1). Neuroscientists often identify specific variables or phenomena to assess their role in a larger neural system, in search of interpretable components of brain activity. A natural application of CLOC is to control these variables and phenomena of interest directly to enable stronger inference of their relationship to downstream variables. Examples of these potential targets for control include the activity of different cell types (51, more?); the type (52–54), frequency (55), amplitude (55), spike coherence (56, 57) and relationship (58, 59) of different oscillatory patterns (60); discrete phenomena such as bursts (cite?), sharp wave ripples (61), oscillatory bursts (8, 62, 63), traveling waves (64, 65), or sleep spindles (cite?); and latent states describing neural dynamics (66, cite? review, Shenoy lab causal test, Hantman), including those most relevant to behavior (20, 67, 68).\nWhile some of these targets lend themselves easily to CLOC, others require continued innovation in interfacing technology. While recent advances in recording technology allow us to infer neural state with unprecedented precision (9, 10, 15, 16, calcium-imaging?, GEVI?), available actuation technologies are much more limited in their degrees of freedom and thus unlikely to sufficiently control what is observed. For this reason, the development of micro-LED arrays (cite?), multi-channel optrodes (8), and holographic optogenetic stimulation (37, cite?) are of particular interest. Moreover, rigorous investigation of the importance of recording and stimulation capabilities relative to each other would be helpful in guiding technological development and experimental design.\nIn addition to controlling variables of interest, CLOC can serve a paradigm of decoupling variables. This could be in the context of a circuit, where clamping the activity of a given node decouples its activity from all inputs except for the controller. This functionally severs links in the circuit, aiding in circuit identification and in testing the function of different nodes and connections (willats-clinc?). Moreover, CLOC could be used in the more general sense of controlling for confounding variables. For example, one might want to manipulate the synchrony of a population without changing the mean firing rate, or vice-versa. Whereas the conventional open-loop stimulation approach might accomplish this through tedious titration of stimulation parameters (69), the feedback control approach could simultaneously manipulate both variables as desired, requiring only a passable model of the system."
  },
  {
    "objectID": "background.html#innovation",
    "href": "background.html#innovation",
    "title": "3  Background",
    "section": "Innovation",
    "text": "Innovation\nDespite CLOC’s great promise to be applied in these areas, it has not yet been widely applied in mesoscale neuroscience. As outlined in Chapter 2, I identify three main reasons for this, which I will begin to address. First, CLOC experiments are difficult and costly. I propose lowering the barrier to entry and the cost of experiment design and method development for CLOC experiments by creating a simulation framework, since existing mesoscale neural network simulators do not contain the necessary ingredients for CLOC simulation. Second, the algorithms previously used for CLOC are not well suited for actuation via multiple simultaneous light sources. I propose adapting more powerful control theory methods to enable bidirectional CLOC, which to our knowledge has not been done previously. Third, technical and conceptual guidelines for the effective application of CLOC do not exist because CLOC has not yet been applied to answer a complex scientific question. I propose to model how this can be done by controlling latent neural dynamics in silico, exploring how technical requirements scale with model and experiment parameters and inferring a causal relationship between latent variables and model behavior.\n\n\n\n\n1. L. Fenno, O. Yizhar, K. Deisseroth, The development and application of optogenetics. Annual Review of Neuroscience. 34, 389–412 (2011).\n\n\n2. J. S. Wiegert, M. Mahn, M. Prigge, Y. Printz, O. Yizhar, Silencing Neurons: Tools, Applications, and Experimental Constraints. Neuron. 95, 504–529 (2017).\n\n\n3. S. Sridharan, M. A. Gajowa, M. B. Ogando, U. K. Jagadisan, L. Abdeladim, M. Sadahiro, H. A. Bounds, W. D. Hendricks, T. S. Turney, I. Tayler, K. Gopakumar, I. A. Oldenburg, S. G. Brohawn, H. Adesnik, High-performance microbial opsins for spatially and temporally precise perturbations of large neuronal networks. Neuron. 110, 1139–1155.e6 (2022).\n\n\n4. J. Vierock, S. Rodriguez-Rozada, A. Dieter, F. Pieper, R. Sims, F. Tenedini, A. C. F. Bergs, I. Bendifallah, F. Zhou, N. Zeitzschel, J. Ahlbeck, S. Augustin, K. Sauter, E. Papagiakoumou, A. Gottschalk, P. Soba, V. Emiliani, A. K. Engel, P. Hegemann, J. S. Wiegert, BiPOLES is an optogenetic tool developed for bidirectional dual-color control of neurons. Nature Communications. 12, 1–20 (2021).\n\n\n5. H. Adesnik, L. Abdeladim, Probing neural codes with two-photon holographic optogenetics. Nat Neurosci. 24, 1356–1366 (2021).\n\n\n6. G. Faini, C. Molinier, C. Telliez, C. Tourain, B. C. Forget, E. Ronzitti, V. Emiliani, Ultrafast Light Targeting for High-Throughput Precise Control of Neuronal Networks. bioRxiv, 2021.06.14.448315 (2021).\n\n\n7. B. L. Roth, DREADDs for Neuroscientists. Neuron. 89, 683–694 (2016).\n\n\n8. D. Eriksson, A. Schneider, A. Thirumalai, M. Alyahyay, B. de la Crompe, K. Sharma, P. Ruther, I. Diester, Multichannel optogenetics combined with laminar recordings for ultra-controlled neuronal interrogation. Nat Commun. 13, 985 (2022).\n\n\n9. N. A. Steinmetz, C. Aydin, A. Lebedeva, M. Okun, M. Pachitariu, M. Bauza, M. Beau, J. Bhagat, C. Böhm, M. Broux, S. Chen, J. Colonell, R. J. Gardner, B. Karsh, F. Kloosterman, D. Kostadinov, C. Mora-Lopez, J. O’Callaghan, J. Park, J. Putzeys, B. Sauerbrei, R. J. J. van Daal, A. Z. Vollan, S. Wang, M. Welkenhuysen, Z. Ye, J. T. Dudman, B. Dutta, A. W. Hantman, K. D. Harris, A. K. Lee, E. I. Moser, J. O’Keefe, A. Renart, K. Svoboda, M. Häusser, S. Haesler, M. Carandini, T. D. Harris, Neuropixels 2.0: A miniaturized high-density probe for stable, long-term brain recordings. Science. 372 (2021), doi:10.1126/science.abf4588.\n\n\n10. J. H. Siegle, A. C. López, Y. A. Patel, K. Abramov, S. Ohayon, J. Voigts, Open Ephys: an open-source, plugin-based platform for multichannel electrophysiology. J. Neural Eng. 14, 045003 (2017).\n\n\n11. P. Gutruf, J. A. Rogers, Implantable, wireless device platforms for neuroscience research. Current Opinion in Neurobiology. 50, 42–49 (2018).\n\n\n12. W. Göbel, F. Helmchen, In Vivo Calcium Imaging of Neural Network Function. Physiology. 22, 358–365 (2007).\n\n\n13. T. Knöpfel, C. Song, Optical voltage imaging in neurons: moving from technology development to practical tool. Nat Rev Neurosci. 20, 719–727 (2019).\n\n\n14. K. Svoboda, R. Yasuda, Principles of Two-Photon Excitation Microscopy and Its Applications to Neuroscience. Neuron. 50, 823–839 (2006).\n\n\n15. A. Kazemipour, O. Novak, D. Flickinger, J. S. Marvin, A. S. Abdelfattah, J. King, P. M. Borden, J. J. Kim, S. H. Al-Abdullatif, P. E. Deal, E. W. Miller, E. R. Schreiter, S. Druckmann, K. Svoboda, L. L. Looger, K. Podgorski, Kilohertz frame-rate two-photon tomography. Nature Methods. 16, 778–786 (2019).\n\n\n16. J. Wu, Y. Liang, S. Chen, C. L. Hsu, M. Chavarha, S. W. Evans, D. Shi, M. Z. Lin, K. K. Tsia, N. Ji, Kilohertz two-photon fluorescence microscopy imaging of neural activity in vivo. Nature Methods. 17, 287–290 (2020).\n\n\n17. L. van der Maaten, G. Hinton, Visualizing Data using t-SNE. Journal of Machine Learning Research. 9, 2579–2605 (2008).\n\n\n18. G. J. Berman, D. M. Choi, W. Bialek, J. W. Shaevitz, Mapping the stereotyped behaviour of freely moving fruit flies. Journal of The Royal Society Interface. 11, 20140672 (2014).\n\n\n19. A. Mathis, P. Mamidanna, K. M. Cury, T. Abe, V. N. Murthy, M. W. Mathis, M. Bethge, DeepLabCut: markerless pose estimation of user-defined body parts with deep learning. Nat Neurosci. 21, 1281–1289 (2018).\n\n\n20. O. G. Sani, H. Abbaspourazad, Y. T. Wong, B. Pesaran, M. M. Shanechi, Modeling behaviorally relevant neural dynamics enabled by preferential subspace identification. Nature Neuroscience. 24, 140–149 (2021).\n\n\n21. O. Sporns, Graph theory methods: applications in brain networks. Dialogues in Clinical Neuroscience. 20, 111–121 (2018).\n\n\n22. S. Schneider, J. H. Lee, M. W. Mathis, Learnable latent embeddings for joint behavioral and neural analysis (2022), doi:10.48550/arXiv.2204.00673.\n\n\n23. L. K. Scheffer, C. S. Xu, M. Januszewski, Z. Lu, S. Takemura, K. J. Hayworth, G. B. Huang, K. Shinomiya, J. Maitlin-Shepard, S. Berg, J. Clements, P. M. Hubbard, W. T. Katz, L. Umayam, T. Zhao, D. Ackerman, T. Blakely, J. Bogovic, T. Dolafi, D. Kainmueller, T. Kawase, K. A. Khairy, L. Leavitt, P. H. Li, L. Lindsey, N. Neubarth, D. J. Olbris, H. Otsuna, E. T. Trautman, M. Ito, A. S. Bates, J. Goldammer, T. Wolff, R. Svirskas, P. Schlegel, E. Neace, C. J. Knecht, C. X. Alvarado, D. A. Bailey, S. Ballinger, J. A. Borycz, B. S. Canino, N. Cheatham, M. Cook, M. Dreher, O. Duclos, B. Eubanks, K. Fairbanks, S. Finley, N. Forknall, A. Francis, G. P. Hopkins, E. M. Joyce, S. Kim, N. A. Kirk, J. Kovalyak, S. A. Lauchie, A. Lohff, C. Maldonado, E. A. Manley, S. McLin, C. Mooney, M. Ndama, O. Ogundeyi, N. Okeoma, C. Ordish, N. Padilla, C. M. Patrick, T. Paterson, E. E. Phillips, E. M. Phillips, N. Rampally, C. Ribeiro, M. K. Robertson, J. T. Rymer, S. M. Ryan, M. Sammons, A. K. Scott, A. L. Scott, A. Shinomiya, C. Smith, K. Smith, N. L. Smith, M. A. Sobeski, A. Suleiman, J. Swift, S. Takemura, I. Talebi, D. Tarnogorska, E. Tenshaw, T. Tokhi, J. J. Walsh, T. Yang, J. A. Horne, F. Li, R. Parekh, P. K. Rivlin, V. Jayaraman, M. Costa, G. S. Jefferis, K. Ito, S. Saalfeld, R. George, I. A. Meinertzhagen, G. M. Rubin, H. F. Hess, V. Jain, S. M. Plaza, A connectome and analysis of the adult Drosophila central brain. eLife. 9, e57443 (2020).\n\n\n24. A. L. Juavinett, G. Bekheet, A. K. Churchland, Chronically implanted Neuropixels probes enable high-yield recordings in freely moving mice. eLife. 8, e47188 (2019).\n\n\n25. E. R. Oby, M. D. Golub, J. A. Hennig, A. D. Degenhart, E. C. Tyler-Kabara, B. M. Yu, S. M. Chase, A. P. Batista, New neural activity patterns emerge with long-term learning. Proceedings of the National Academy of Sciences. 116, 15210–15215 (2019).\n\n\n26. Y. Yang, S. Qiao, O. G. Sani, J. I. Sedillo, B. Ferrentino, B. Pesaran, M. M. Shanechi, Modelling and prediction of the dynamic responses of large-scale brain networks during direct electrical stimulation. Nature Biomedical Engineering. 5, 324–345 (2021).\n\n\n27. B. R. Cowley, A. C. Snyder, K. Acar, R. C. Williamson, B. M. Yu, M. A. Smith, Slow Drift of Neural Activity as a Signature of Impulsivity in Macaque Visual and Prefrontal Cortex. Neuron. 108, 551–567.e8 (2020).\n\n\n28. L. Avitan, C. Stringer, Not so spontaneous: Multi-dimensional representations of behaviors and context in sensory areas. Neuron (2022), doi:10.1016/j.neuron.2022.06.019.\n\n\n29. M. Jazayeri, S. Ostojic, Interpreting neural computations by examining intrinsic and embedding dimensionality of neural activity. Current Opinion in Neurobiology. 70, 113–120 (2021).\n\n\n30. L. Grosenick, J. H. Marshel, K. Deisseroth, Review Closed-Loop and Activity-Guided Optogenetic Control. Neuron. 86, 106–139 (2015).\n\n\n31. A. Kumar, I. Vlachos, A. Aertsen, C. Boucsein, Challenges of understanding brain function by selective modulation of neuronal subpopulations. Trends in Neurosciences. 36, 579–586 (2013).\n\n\n32. S. M. Potter, A. El Hady, E. E. Fetz, Closed-loop neuroscience and neuroengineering. Frontiers in Neural Circuits. 0, 115 (2014).\n\n\n33. J. P. Newman, M. F. Fong, D. C. Millard, C. J. Whitmire, G. B. Stanley, S. M. Potter, Optogenetic feedback control of neural activity. eLife (2015), doi:10.7554/eLife.07192.\n\n\n34. M. F. Bolus, A. A. Willats, C. J. Whitmire, C. J. Rozell, G. B. Stanley, Design strategies for dynamic closed-loop optogenetic neurocontrol in vivo. Journal of Neural Engineering. 15, 026011 (2018).\n\n\n35. M. F. Bolus, A. A. Willats, C. J. Rozell, G. B. Stanley, State-space optimal feedback control of optogenetically driven neural activity. Journal of neural engineering. 18, 036006 (2021).\n\n\n36. V. Emiliani, A. E. Cohen, K. Deisseroth, M. Häusser, All-optical interrogation of neural circuits. Journal of Neuroscience. 35, 13917–13926 (2015).\n\n\n37. Z. Zhang, L. E. Russell, A. M. Packer, O. M. Gauld, M. Häusser, Closed-loop all-optical interrogation of neural circuits in vivo. Nature Methods. 15, 1037–1040 (2018).\n\n\n38. E. Krook-Magnuson, C. Armstrong, M. Oijala, I. Soltesz, On-demand optogenetic control of spontaneous seizures in temporal lobe epilepsy. Nature Communications. 4, 1–8 (2013).\n\n\n39. A. Witt, A. Palmigiano, A. Neef, A. El Hady, F. Wolf, D. Battaglia, Controlling the oscillation phase through precisely timed closed-loop optogenetic stimulation: a computational study. Frontiers in Neural Circuits. 7, 1–17 (2013).\n\n\n40. S. Dutta, E. Ackermann, C. Kemere, Analysis of an open source, closed-loop, realtime system for hippocampal sharp-wave ripple disruption. Journal of Neural Engineering. 16, 016009 (2019).\n\n\n41. A. R. Vaidya, M. S. Pujara, M. Petrides, E. A. Murray, L. K. Fellows, Lesion Studies in Contemporary Neuroscience. Trends in Cognitive Sciences. 23, 653–671 (2019).\n\n\n42. J. T. Davie, M. H. P. Kole, J. J. Letzkus, E. A. Rancz, N. Spruston, G. J. Stuart, M. Häusser, Dendritic patch-clamp recording. Nature Protocols. 1, 1235–1247 (2006).\n\n\n43. G. Wang, D. R. Wyskiel, W. Yang, Y. Wang, L. C. Milbern, T. Lalanne, X. Jiang, Y. Shen, Q. Q. Sun, J. J. Zhu, An optogenetics- and imaging-assisted simultaneous multiple patch-clamp recording system for decoding complex neural circuits. Nature Protocols. 10, 397–412 (2015).\n\n\n44. D. Engel, Subcellular patch-clamp recordings from the somatodendritic domain of nigral dopamine neurons. Journal of Visualized Experiments. 2016, e54601 (2016).\n\n\n45. J. A. Cardin, M. Carlén, K. Meletis, U. Knoblich, F. Zhang, K. Deisseroth, L. H. Tsai, C. I. Moore, Targeted optogenetic stimulation and recording of neurons in vivo using cell-type-specific expression of Channelrhodopsin-2. Nature Protocols. 5, 247–254 (2010).\n\n\n46. D. R. Hochbaum, Y. Zhao, S. L. Farhi, N. Klapoetke, C. A. Werley, V. Kapoor, P. Zou, J. M. Kralj, D. MacLaurin, N. Smedemark-Margulies, J. L. Saulnier, G. L. Boulting, C. Straub, Y. K. Cho, M. Melkonian, G. K. S. Wong, D. J. Harrison, V. N. Murthy, B. L. Sabatini, E. S. Boyden, R. E. Campbell, A. E. Cohen, All-optical electrophysiology in mammalian neurons using engineered microbial rhodopsins. Nature Methods. 11, 825–833 (2014).\n\n\n47. K. E. Kishi, Y. S. Kim, M. Fukuda, M. Inoue, T. Kusakizako, P. Y. Wang, C. Ramakrishnan, E. F. X. Byrne, E. Thadhani, J. M. Paggi, T. E. Matsui, K. Yamashita, T. Nagata, M. Konno, S. Quirin, M. Lo, T. Benster, T. Uemura, K. Liu, M. Shibata, N. Nomura, S. Iwata, O. Nureki, R. O. Dror, K. Inoue, K. Deisseroth, H. E. Kato, Structural basis for channel conduction in the pump-like channelrhodopsin ChRmine. Cell. 185, 672–689.e23 (2022).\n\n\n48. J. Y. Lin, P. M. Knutsen, A. Muller, D. Kleinfeld, R. Y. Tsien, ReaChR: A red-shifted variant of channelrhodopsin enables deep transcranial optogenetic excitation. Nature Neuroscience. 16, 1499–1508 (2013).\n\n\n49. S. Chen, A. Z. Weitemier, X. Zeng, L. He, X. Wang, Y. Tao, A. J. Y. Huang, Y. Hashimotodani, M. Kano, H. Iwasaki, L. K. Parajuli, S. Okabe, D. B. Loong Teh, A. H. All, I. Tsutsui-Kimura, K. F. Tanaka, X. Liu, T. J. McHugh, Near-infrared deep brain stimulation via upconversion nanoparticle–mediated optogenetics. Science. 359, 679–684 (2018).\n\n\n50. A. M. Packer, B. Roska, M. Häuser, Targeting neurons and photons for optogenetics. Nature Neuroscience. 16, 805–815 (2013).\n\n\n51. R. I. Martinez-Garcia, B. Voelcker, J. B. Zaltsman, S. L. Patrick, T. R. Stevens, B. W. Connors, S. J. Cruikshank, Two dynamically distinct circuits drive inhibition in the sensory thalamus. Nature. 583, 813–818 (2020).\n\n\n52. S. R. Cole, B. Voytek, Brain Oscillations and the Importance of Waveform Shape. Trends in Cognitive Sciences. 21, 137–149 (2017).\n\n\n53. S. Cole, B. Voytek, Cycle-by-cycle analysis of neural oscillations. Journal of Neurophysiology. 122, 849–861 (2019).\n\n\n54. M. S. Fabus, A. J. Quinn, C. E. Warnaby, M. W. Woolrich, Automatic decomposition of electrophysiological data into distinct nonsinusoidal oscillatory modes. Journal of Neurophysiology. 126, 1670–1684 (2021).\n\n\n55. A. B. Saleem, A. D. Lien, M. Krumin, B. Haider, M. R. Rosón, A. Ayaz, K. Reinhold, L. Busse, M. Carandini, K. D. Harris, M. Carandini, Subcortical Source and Modulation of the Narrowband Gamma Oscillation in Mouse Visual Cortex. Neuron. 93, 315–322 (2017).\n\n\n56. T. J. Buschman, E. L. Denovellis, C. Diogo, D. Bullock, E. K. Miller, Synchronous Oscillatory Neural Ensembles for Rules in the Prefrontal Cortex. Neuron. 76, 838–846 (2012).\n\n\n57. E. A. Buffalo, P. Fries, R. Landman, T. J. Buschman, R. Desimone, Laminar differences in gamma and alpha coherence in the ventral stream. Proceedings of the National Academy of Sciences of the United States of America. 108, 11262–11267 (2011).\n\n\n58. J. Aru, J. Aru, V. Priesemann, M. Wibral, L. Lana, G. Pipa, W. Singer, R. Vicente, Untangling cross-frequency coupling in neuroscience. Current Opinion in Neurobiology. 31, 51–61 (2015).\n\n\n59. L. Zhang, J. Lee, C. Rozell, A. C. Singer, Sub-second dynamics of theta-gamma coupling in hippocampal CA1. eLife. 8 (2019), doi:10.7554/eLife.44320.\n\n\n60. G. Buzsáki, A. Draguhn, Neuronal oscillations in cortical networks. Science. 304, 1926–1929 (2004).\n\n\n61. G. Buzsáki, Hippocampal sharp wave-ripple: A cognitive biomarker for episodic memory and planning. Hippocampus. 25, 1073–1188 (2015).\n\n\n62. M. Lundqvist, J. Rose, P. Herman, S. L. L. Brincat, T. J. J. Buschman, E. K. K. Miller, Gamma and Beta Bursts Underlie Working Memory. Neuron. 90, 152–164 (2016).\n\n\n63. M. Lundqvist, J. Rose, M. Warden, T. Buschman, P. Herman, Reduced variability of bursting activity during working memory (2022), doi:10.1101/2022.02.18.481088.\n\n\n64. L. Muller, F. Chavane, J. Reynolds, T. J. Sejnowski, Cortical travelling waves: Mechanisms and computational principles. Nature Reviews Neuroscience. 19, 255–268 (2018).\n\n\n65. Z. W. Davis, L. Muller, J. Martinez-Trujillo, T. Sejnowski, J. H. Reynolds, Spontaneous travelling cortical waves gate perception in behaving primates. Nature. 587, 432–436 (2020).\n\n\n66. S. Vyas, M. D. Golub, D. Sussillo, K. V. Shenoy, Computation through Neural Population Dynamics. Annual Review of Neuroscience. 43, 249–275 (2020).\n\n\n67. O. G. Sani, B. Pesaran, M. M. Shanechi, M. Hsieh, Where is all the nonlinearity: flexible nonlinear modeling of behaviorally relevant neural dynamics using recurrent neural networks. bioRxiv, 2021.09.03.458628 (2021).\n\n\n68. C. Hurwitz, A. Srivastava, K. Xu, J. Jude, M. G. Perich, L. E. Miller, M. H. Hennig, \"Targeted Neural Dynamical Modeling\" in Advances in Neural Information Processing Systems (2021; https://github.com/HennigLab/tndm.), vol. 35, pp. 29379–29392.\n\n\n69. A. Nandy, J. J. Nassi, M. P. Jadi, J. Reynolds, Optogenetically induced low-frequency correlations impair perception. eLife. 8 (2019), doi:10.7554/eLife.35123."
  },
  {
    "objectID": "aim1.html#rationale",
    "href": "aim1.html#rationale",
    "title": "4  Aim 1: A CLOC simulation testbed",
    "section": "Rationale",
    "text": "Rationale\nCLOC experiments are difficult and costly. This can be a barrier to entry for neuroscientists that find CLOC’s advantages attractive. Their lab might lack the funds to invest in necessary hardware or the time to invest in adding high-performance signal processing loop to their experimental workflow. Or, they may possess the resources but do not want to spend them without some assurance that their proposed experiment would be fruitful. Finally, when the proposed experiment requires signal processing/control method development, iterating on designs in-vivo may be cumbersome, given the additional cost of animal care and training.\nTaken together, these factors not only make CLOC experiments a significant investment for a researcher, but one laden with risk. Unknown properties of the system under study can make it hard to predict whether a proposed experiment (e.g., whether a given population of neurons can be controlled in a given way) is likely to succeed, and even more so when working with innovative methods with little precedent in the literature.\nHowever, these costs and risks can be mitigated through in silico prototyping. Given a reliable model of the system of interest, one can simulate a proposed experiment, assessing the effectiveness of a given setup. Alternate models can be tested to assess robustness of the given method to unknown model properties, or a single method can be validated on a variety of models to determine its general applicability. This strategy not only allows for a researcher to evaluate and optimize methods before committing significant resources to them, but also accelerates the development cycle.\nFor these reasons, I have developed Cleo: Closed Loop, Electrophysiology, and Optogenetics experiment simulation testbed. Unlike existing software, Cleo simultaneously provides a high-level interface to fast and flexible neural network simulations; easy, model-independent injection of electrode recording and optogenetic perturbations; and a real-time, closed-loop processing module capable of modeling communication and processing delays inherent in real experiments. I thus provide a “free trial” to researchers who are unsure if CLOC will serve their research agenda, as well as a low-cost environment to design experiments and develop methods, for those who are already committed to the technqiue."
  },
  {
    "objectID": "aim1.html#guiding-principles",
    "href": "aim1.html#guiding-principles",
    "title": "4  Aim 1: A CLOC simulation testbed",
    "section": "Guiding principles",
    "text": "Guiding principles\nTwo factors drove our choice of recording and stimulation models to integrate into Cleo. First, because a main purpose of Cleo is to enable prototyping of experiments, we focused on models at the level of the parameters an experimenter is able to alter. Because parameters such as electrode location, channel count and density, and optic fiber depth and size are all defined naturally in spatially extended models, Cleo’s electrode and optogenetics modules require a “spatial” network model where relevant neurons must be assigned coordinates in space.\nSecond, we assumed that highly realistic models of individual neurons are not needed to capture most mesoscale-level phenomena. Accordingly, Cleo was developed with the intention of using point neurons models, rather than multi-compartment neuron models with realistic morphologies. Simulating simpler neuron models offers advantages of speed and intuitiveness, which are important in the context of prototyping an experiment. This decision had consequences in our software (Section 4.3) and LFP modeling (Section 4.4) decisions.\nIn addition to our modeling priorities, the goals of usability, flexibility, and extensibility guided our choices in software dependencies and infrastructure. Ease of use is important to make Cleo as accessible as possible, especially to researchers with primarily experimental backgrounds who may not have extensive experience with computational modeling. This usability goal also motivated Cleo’s modular design, which allows users to add different recording or stimulation devices with little or no modification to the underlying network model, easing the burden of testing a variety of experimental configurations. Flexibility in the underlying simulator, in addition to enabling compatibility with a wide variety of models, is necessary for arbitrarily interacting with the simulation in a closed-loop fashion. Finally, extensibility is important for the testbed to remain relevant under changing needs in the future, allowing for new functionality to be easily added in a “plug-in,” modular architecture.\n\nLimitations and workarounds\nBecause we prioritize point neuron models, Cleo does not currently provide tools for recording realistic extracellular potentials. This would preclude realistically simulating such methods as spike sorting. Currently, the sorted spikes signal Cleo can record assumes perfect sorting but could be made more realistic by adding sorting noise."
  },
  {
    "objectID": "aim1.html#sec-cleo-arch",
    "href": "aim1.html#sec-cleo-arch",
    "title": "4  Aim 1: A CLOC simulation testbed",
    "section": "Closed-loop simulation architecture",
    "text": "Closed-loop simulation architecture\nWe chose Brian 2 (1) as the spiking neural network simulator to build Cleo around. Brian is a relatively new spiking neural network simulator written in Python with multiple advantages. It flexibly allows (and even requires) the user to define models mathematically rather than selecting from a pre-defined library of cell types and features, while maintaining the ease of a high-level interface. This keeps model and experiment details together and enables us to define arbitrary recording and stimulation models that easily interface with the simulation. Moreover, the Python programming language has the advantages of being open-source, intuitive to learn (2), and widely used in computational neuroscience (3, 4). Users do not need to use any other languages to use Brian. Brian is also relatively fast (especially since it is developed primarily for point neuron simulations), as shown in benchmarks (1).\nCleo provides three modules—recording, stimulation, and closed-loop processing—for integration with an existing Brian model (see Figure 4.1). Cleo’s functionality centers around a CLSimulator object that orchestrates the interactions between these three modules and the Brian simulation by injecting devices, running the simulation, and communicating with an IOProcessor object at each time step. The IOProcessor receives recorder measurements according to a specified sampling rate and returns any updates to stimulator devices.\n\n\n\n\n\n\n\nFigure 4.1: A conceptual diagram of Cleo’s functionality. Cleo wraps a Brian network model, injects stimulation and recording devices, and interfaces with the network in real time through a simulated “I/O processor”.\n\n\nIn order to simulate the effects of latency in closed-loop control, Cleo provides a LatencyIOProcessor class capable of delivering control signals after some delay. It does this by storing the outputs calculated for every sample in a buffer along with the time they can be delivered to the network. For example, if a sample is taken at 20 ms and the user wishes to simulate a processing and communication latency of 3 ms, the control signal, along with the output time of 23 ms is stored in a buffer which the simulation checks at every timestep. As soon as the simulation clock reaches 23 ms, the control signal is taken from the buffer and applied to the stimulator devices. Because the user has arbitrary control over this latency, they can easily simulate probabilistic delays if, for example, they wish to assess the effect of the experimental platform stalling occasionally.\nBy default, LatencyIOProcessor samples on a fixed schedule and simulates processing samples in parallel—that is, the computation time for one sample does not affect that of others. Some alternatives are available, as illustrated in Figure 4.2.\n\n\n\n\n\n\n\nFigure 4.2: Latency emulation strategy and available configurations. (A) Cleo registers the time a sample is taken from the recording devices, the times the computation starts and ends, applying the user-specified delay, and updates stimulation devices when finished. (B) The default, parallel processing/fixed sampling mode. (C) The serial processing/fixed sampling case reflects when computations are not performed in parallel, but sampling continues on a fixed schedule. (D) The final processing mode avoids buffer overflow by sampling only once the computation for the previous step has terminated.\n\n\n\nLimitations\nOne downside of using Brian is that it does not have the same first-class support for multi-compartment neurons as the popular NEURON (5) simulator. Using point neurons precludes advanced, morphology-dependent features of neural dynamics as well as recording and stimulation. However, if this feature is needed, Cleo could be developed further to integrate with Brian’s morphological neuron features.\nBoth a strength and a limitation of Cleo’s design is that it works with whatever model the user provides. This avoids the pitfall of offering stock models that claim to represent a researcher’s system of interest, leaving it up to them to identify and/or develop a model that adequately describe the phenomena being studied. If a sufficiently realistic model for the studied system does not exist, for example, developing one may be prohibitively costly, becoming a computational project in its own right as opposed to simply a stepping-stone towards an experiment. In these cases we suggest that a workaround could be to test a variety of potential models to identify which experimental configurations would be robust to unknown properties of the system. Indeed, the desired experiment in this case could be one that best adjudicates between these hypotheses (willats-clinc?)."
  },
  {
    "objectID": "aim1.html#sec-elec",
    "href": "aim1.html#sec-elec",
    "title": "4  Aim 1: A CLOC simulation testbed",
    "section": "Electrode recording",
    "text": "Electrode recording\n\nSpiking\nBecause we have prioritized point neuron simulations, the electrode functionality currently implemented in Cleo does not rely on raw extracellular potentials, which can only be computed from multi-compartment neurons (6, 7). This biophysical forward modeling approach has been taken in other software (8–11).\nTo approximate spike recording without filtering and thresholding of extracellular potentials, Cleo simply takes ground-truth spikes and stochastically determines which to report using a detection probability function. This function is parametrized by a perfect detection radius, within which all spikes are reported, a half detection radius, at which distance there is a 50% chance a spike will be detected, and a cutoff probability, below which all neurons are ignored. The detection probability function is interpolated between the parametrized points with a \\(1/r\\) function (12, 13), where \\(r\\) is the distance between the neuron and the electrode (see Figure 4.3).\nCleo provides spike recording functionality in two forms: multi-unit and sorted. Multi-unit spiking reports every spike detected by every channel, without regard for the origin of the spike. Thus, each channel can report spikes from multiple neurons and a single spike can be reported on multiple channels. Sorted spiking reports all spikes detected on at least one channel, where each neuron is identified by a unique index. While real-time spike sorting is currently not feasible in practice for large numbers of contacts, this sorted spiking option could be used to emulate a common workflow of isolating one or a few neurons to report spikes from in real time.\n\n\n\n\n\n\n\nFigure 4.3: Illustration of LFP and spiking from Cleo’s electrophysiology module. (A) The probabilistic spike detection model. All spikes within the 100% detection radius, 50% of spikes at the 50% detection radius, and none of those outside the threshold radius are recorded. The detection probability decays with 1/r. (B) An example plot generated by Cleo showing the positions of neurons and electrode contacts. (C) Randomly generated spikes for the neurons shown in B. Top: the sorted spike signal, which gives the ground truth source neuron for every spike as a perfect proxy for spike sorting. Bottom: multi-unit spikes, where spikes are reported on every channel they are detected on, regardless of the source neuron. (D) The TKLFP signal generated from the spikes in C for each channel. Y-axis units are not shown.\n\n\n\n\nLFP\nIn order to approximate cortical LFP without recurring to morphological neurons and biophysical forward modeling, we implemented the kernel LFP approximation from (14), which we term TKLFP (Teleńczuk kernel LFP). This method approximates the per-spike contribution to LFP (termed uLFP: unitary LFP) with a delayed Gaussian function, where amplitude and delay depend on the position of the neuron relative to the electrode. While the original study included reference peak amplitude \\(A_0\\) values at just four cortical depths, we inferred these values for arbitrary depths by performing cubic interpolation on data from their figure 5 and assumed that this profile dropped to zero at 600 µm below the soma and 1000 µm above. This implementation is available as a standalone Python package on PyPI (15). Accuracy of this implementation is verified in automated test suites in both TKLFP and Cleo packages.\n\n\nLimitations\nUsing point neurons requires approximation of extraceullar potentials, which do not perfectly match ground-truth signals. The TKLFP approximation Cleo uses, for example, underrepresents high-frequency signals. Fortunately, there is an alternate, potentially more accurate, LFP approximation for point neurons that can be added to Cleo in the future if needed (16)."
  },
  {
    "objectID": "aim1.html#optogenetic-stimulation",
    "href": "aim1.html#optogenetic-stimulation",
    "title": "4  Aim 1: A CLOC simulation testbed",
    "section": "Optogenetic stimulation",
    "text": "Optogenetic stimulation\n\nApproach\n\nLight model\nCleo simulates optogenetic stimulation by combining a model of light propagation with an opsin model relating light to current. The light model is taken from (17) and uses Kubelka-Munk light propagation. This is a simplified model operating on the assumption that the medium is optically homogeneous, which, while not true, was shown by Foutz et al. to be a suitable approximation. Cleo includes absorbance, scattering, and refraction parameters for blue, 473-nm light as given in (17).\n\n\nOpsin models\nIndependent of the light propagation model, Cleo provides two different opsin models. One is a four-state Markov model as presented in (18), which captures rise, peak, plateau, and fall dynamics as the opsin is activated and deactivated through a Markov process. Additionally, by defining conductance rather than current directly, the model is able to reproduce the photocurrent’s dependence on the membrane potential (see Figure 4.4). While the four-state model fits experimental data fairly well, the code is structured so that the three- or six-state models in (18) could also be easily implemented.\nBecause the Markov model depends on somewhat realistic membrane potential and resistance values, however, it is not well suited for many pre-existing models that do not. For example, many commonly used leaky integrate-and-fire (LIF) neurons define the membrane potential as ranging from 0 to 1, rather than -70 mV to -50 mV, rendering both the units and values (relative to the opsin’s reversal potential) incompatible. One solution would be for users to adapt their neuron models for compatibility with this Markov opsin model, but since this would be burdensome, we developed an alternative model that simply delivers photocurrent proportional to the light intensity at each neuron. Thus, users can retain their original model with no need to add units or modify parameters.\nIn addition to options for opsin modeling, Cleo allows the user to specify both the probability that cells of a target population express an opsin and the per-cell expression level. This allows for the study of the impact of heterogeneous expression on the outcome of an experiment.\n\n\n\nResults\nThe light model from (17) was successfully replicated, and the light intensity-firing rate relationship was qualitatively similar to that originally reported, though differing in some respects. This can be attributed to the use of point neurons rather than morphological neurons. See Figure 4.4 for details. Additionally, preliminary experiments show that the simplified, proportional current opsin model is able to produce a firing response qualitatively similar to that of the Markov model.\n\n\n\n\n\n\n\nFigure 4.4: Validation of the optogenetics module. (A) Light transmittance T as a function of radius and axial distance from the optic fiber tip. Transmittance refers to the irradiance Irr as a proportion of the irradiance at the fiber tip Irr0 . After Figure 2a from (17) (B) Light transmittance T as a function of axial radius z for different optic fiber sizes. After Figure 2b from (17) (C) Photocurrent Iopto for ramping light of different intensities. After the figure produced by the “ramp” protocol from the default PyRhO simulator (18) (D) Neuron firing rates in response to optical stimulation with 5-ms pulse frequencies ranging from 1 to 200Hz. The left column re-plots data from (17). The middle column shows results for an LIF neuron with a simple opsin, and the right column for a tonic AdEx neuron with a Markov opsin model. The top row shows results for different light intensities: 100%, 120%, and 140% of the threshold for producing a single spike with a 5-ms pulse. The bottom row shows results for different expression levels relative to the default, \\(\\rho_{\\text{rel}}\\). The irradiance used for these simulations was 120% of the single-spike threshold.\n\n\n\n\nLimitations\nCurrently only channelrhodopsin-2 model parameters are included—comparing the effectiveness of different opsins will require first obtaining parameters. This is important since new opsins have been engineered with improved characteristics (19–25), as well as chloride pumps (26–28), channels (29, 30), and other innovations (28, 31)]. Thankfully, parameters for many opsins are available in published literature (32–36).\nAnother limitation is support for multiple simultaneous opsins or light sources. At present, the user could manually include separate current terms for each opsin in neuron model equations or approximate spectral overlap by adding a fraction of a light source’s intensity to that of another, but this potentially slow workflow is antithetical to Cleo’s goal of requiring minimum work to test different scenarios. We plan on adding this functionality shortly, since it will be important for Aims 2 and 3."
  },
  {
    "objectID": "aim1.html#usability-accessibility",
    "href": "aim1.html#usability-accessibility",
    "title": "4  Aim 1: A CLOC simulation testbed",
    "section": "Usability & accessibility",
    "text": "Usability & accessibility\n\nOpen-source code and documentation\nCleo is open-source and can be installed from the Python Package Index under the name cleosim. The code can be found on GitHub. Documentation, including an overview, tutorials, and API reference, can be found at .\n\n\nExample experiments\nIn order to demonstrate Cleo’s utility to the public, we implemented three example experiments to feature in the upcoming publication:\n\nClosed-loop inhibition of a traveling wave in a rodent somatosensory cortex model (37).\nFeedback control of layer 2/3 interneurons, disrupting plasticity in a model of primary visual cortex (38).\nOptogenetic evocation of sharp wave-ripples in an anatomically detailed model of hippocampus (39, 40). See Figure 4.5 for details, and note that feedback control, not looking ahead, so to speak, fails to evoke the reference signal at the desired time. The strategy I propose in Chapter 5 should remedy this.\n\n\n\n\n\n\n\n\nFigure 4.5: An example application of Cleo to the anatomical hippocampus model by Aussel et al.(39). (A) A 2.5 mm-thick slice of the 15 mm-tall model is shown using Cleo’s built-in experiment plotting utilities. The model consists of four regions, entorhinal cortex (EC), dentate gyrus (DG), CA3, and CA1. Electrode contacts are represented as black dots and are in the same location as in the original model. Two light sources are shown in EC. Nine other such pairs (for a total of 20 light sources) not pictured here were spaced regularly parallel to the z axis. (B) Results are shown for ten trials each of three stimulation paradigms: naïve open-loop, where the input is simply a mirrored, rectified version of the reference signal; model-based open-loop, where a controller is run offline on a simulated model; and feedback control, where a controller is run using online measurements. Input Irr0 is the light intensity at the tip of each optic fiber. The system output TKLFP refers to the Teleńczuk kernel LFP approximation.\n\n\n\n\n\n\n1. M. Stimberg, R. Brette, D. F. M. Goodman, Brian 2, an intuitive and efficient neural simulator. eLife. 8 (2019), doi:10.7554/eLife.47314.\n\n\n2. A. Bogdanchikov, M. Zhaparov, R. Suliyev, \"Python to learn programming\" in Journal of Physics: Conference Series (IOP Publishing, 2013; https://iopscience.iop.org/article/10.1088/1742-6596/423/1/012027), vol. 423, p. 012027.\n\n\n3. A. P. Davison, M. L. Hines, E. Muller, Trends in programming languages for neuroscience simulations. Frontiers in Neuroscience. 3, 374–380 (2009).\n\n\n4. E. Muller, J. A. Bednar, M. Diesmann, M. O. Gewaltig, M. Hines, A. P. Davison, Python in neuroscience. Frontiers in Neuroinformatics. 9, 11 (2015).\n\n\n5. M. L. Hines, N. T. Carnevale, The NEURON Simulation Environment. Neural Computation. 9, 1179–1209 (1997).\n\n\n6. K. H. Pettersen, H. Lindén, A. M. Dale, G. T. Einevoll, Extracellular spikes and CSD. Handbook of neural activity measurement. 1, 92–135 (2012).\n\n\n7. G. Buzsáki, C. A. Anastassiou, C. Koch, The origin of extracellular fields and currents — EEG, ECoG, LFP and spikes. Nature Reviews Neuroscience 2012 13:6. 13, 407–420 (2012).\n\n\n8. E. Hagen, S. Næss, T. V. Ness, G. T. Einevoll, Multimodal modeling of neural network activity: Computing LFP, ECoG, EEG, and MEG signals with LFPy 2.0. Frontiers in Neuroinformatics. 12, 92 (2018).\n\n\n9. H. Parasuram, B. Nair, E. D’Angelo, M. Hines, G. Naldi, S. Diwakar, Computational modeling of single neuron extracellular electric potentials and network local field potentials using LFPsim. Frontiers in Computational Neuroscience. 10, 65 (2016).\n\n\n10. R. J. Tomsett, M. Ainsworth, A. Thiele, M. Sanayei, X. Chen, M. A. Gieselmann, M. A. Whittington, M. O. Cunningham, M. Kaiser, Virtual Electrode Recording Tool for EXtracellular potentials (VERTEX): comparing multi-electrode recordings from simulated and biological mammalian cortical tissue. Brain Structure and Function. 220, 2333–2353 (2015).\n\n\n11. C. Thornton, F. Hutchings, M. Kaiser, The virtual electrode recording tool for extracellular potentials (VERTEX) Version 2.0: Modelling in vitro electrical stimulation of brain tissue. Wellcome Open Research. 4 (2019), doi:10.12688/wellcomeopenres.15058.1.\n\n\n12. S. R. Nason, A. K. Vaskov, M. S. Willsey, E. J. Welle, H. An, P. P. Vu, A. J. Bullard, C. S. Nu, J. C. Kao, K. V. Shenoy, T. Jang, H.-S. Kim, D. Blaauw, P. G. Patil, C. A. Chestek, A low-power band of neuronal spiking activity dominated by local single units improves the performance of brain–machine interfaces. Nature Biomedical Engineering 2020, 1–11 (2020).\n\n\n13. G. R. Holt, C. Koch, Electrical interactions via the extracellular potential near cell bodies. Journal of Computational Neuroscience. 6, 169–184 (1999).\n\n\n14. B. Telenczuk, M. Telenczuk, A. Destexhe, A kernel-based method to calculate local field potentials from networks of spiking neurons. Journal of Neuroscience Methods. 344, 108871 (2020).\n\n\n15. K. Johnsen, kjohnsen/tklfp: v0.2.0 (2022), doi:10.5281/zenodo.6787979.\n\n\n16. A. Mazzoni, H. Lindén, H. Cuntz, A. Lansner, S. Panzeri, G. T. Einevoll, Computing the Local Field Potential (LFP) from Integrate-and-Fire Network Models. PLOS Computational Biology. 11, e1004584 (2015).\n\n\n17. T. J. Foutz, R. L. Arlow, C. C. Mcintyre, Theoretical principles underlying optical stimulation of a channelrhodopsin-2 positive pyramidal neuron. J Neurophysiol. 107, 3235–3245 (2012).\n\n\n18. B. D. Evans, S. Jarvis, S. R. Schultz, K. Nikolic, PyRhO: A Multiscale Optogenetics Simulation Platform. Frontiers in Neuroinformatics. 10, 8 (2016).\n\n\n19. L. A. Gunaydin, O. Yizhar, A. Berndt, V. S. Sohal, K. Deisseroth, P. Hegemann, Ultrafast optogenetic control. Nature Neuroscience. 13, 387–392 (2010).\n\n\n20. J. Y. Lin, P. M. Knutsen, A. Muller, D. Kleinfeld, R. Y. Tsien, ReaChR: A red-shifted variant of channelrhodopsin enables deep transcranial optogenetic excitation. Nature Neuroscience. 16, 1499–1508 (2013).\n\n\n21. N. C. Klapoetke, Y. Murata, S. S. Kim, S. R. Pulver, A. Birdsey-Benson, Y. K. Cho, T. K. Morimoto, A. S. Chuong, E. J. Carpenter, Z. Tian, J. Wang, Y. Xie, Z. Yan, Y. Zhang, B. Y. Chow, B. Surek, M. Melkonian, V. Jayaraman, M. Constantine-Paton, G. K. S. Wong, E. S. Boyden, Independent optical excitation of distinct neural populations. Nature Methods. 11, 338–346 (2014).\n\n\n22. D. R. Hochbaum, Y. Zhao, S. L. Farhi, N. Klapoetke, C. A. Werley, V. Kapoor, P. Zou, J. M. Kralj, D. MacLaurin, N. Smedemark-Margulies, J. L. Saulnier, G. L. Boulting, C. Straub, Y. K. Cho, M. Melkonian, G. K. S. Wong, D. J. Harrison, V. N. Murthy, B. L. Sabatini, E. S. Boyden, R. E. Campbell, A. E. Cohen, All-optical electrophysiology in mammalian neurons using engineered microbial rhodopsins. Nature Methods. 11, 825–833 (2014).\n\n\n23. T. Mager, D. L. D. L. Morena, V. Senn, J. Schlotte, A. Derrico, K. Feldbauer, C. Wrobel, S. Jung, K. Bodensiek, V. Rankovic, L. Browne, A. Huet, J. Jüttner, P. G. Wood, J. J. Letzkus, T. Moser, E. Bamberg, High frequency neural spiking and auditory signaling by ultrafast red-shifted optogenetics. Nature Communications. 9, 1–14 (2018).\n\n\n24. S. Sridharan, M. A. Gajowa, M. B. Ogando, U. K. Jagadisan, L. Abdeladim, M. Sadahiro, H. A. Bounds, W. D. Hendricks, T. S. Turney, I. Tayler, K. Gopakumar, I. A. Oldenburg, S. G. Brohawn, H. Adesnik, High-performance microbial opsins for spatially and temporally precise perturbations of large neuronal networks. Neuron. 110, 1139–1155.e6 (2022).\n\n\n25. K. E. Kishi, Y. S. Kim, M. Fukuda, M. Inoue, T. Kusakizako, P. Y. Wang, C. Ramakrishnan, E. F. X. Byrne, E. Thadhani, J. M. Paggi, T. E. Matsui, K. Yamashita, T. Nagata, M. Konno, S. Quirin, M. Lo, T. Benster, T. Uemura, K. Liu, M. Shibata, N. Nomura, S. Iwata, O. Nureki, R. O. Dror, K. Inoue, K. Deisseroth, H. E. Kato, Structural basis for channel conduction in the pump-like channelrhodopsin ChRmine. Cell. 185, 672–689.e23 (2022).\n\n\n26. V. Gradinaru, F. Zhang, C. Ramakrishnan, J. Mattis, R. Prakash, I. Diester, I. Goshen, K. R. Thompson, K. Deisseroth, Molecular and Cellular Approaches for Diversifying and Extending Optogenetics. Cell. 141, 154–165 (2010).\n\n\n27. A. S. Chuong, M. L. Miri, V. Busskamp, G. A. C. Matthews, L. C. Acker, A. T. Sørensen, A. Young, N. C. Klapoetke, M. A. Henninger, S. B. Kodandaramaiah, M. Ogawa, S. B. Ramanlal, R. C. Bandler, B. D. Allen, C. R. Forest, B. Y. Chow, X. Han, Y. Lin, K. M. Tye, B. Roska, J. A. Cardin, E. S. Boyden, Noninvasive optical inhibition with a red-shifted microbial rhodopsin. Nature Neuroscience. 17, 1123–1129 (2014).\n\n\n28. A. Berndt, S. Y. Lee, J. Wietek, C. Ramakrishnan, E. E. Steinberg, A. J. Rashid, H. Kim, S. Park, A. Santoro, P. W. Frankland, S. M. Iyer, S. Pak, S. Ährlund-Richter, S. L. Delp, R. C. Malenka, S. A. Josselyn, M. Carlén, P. Hegemann, K. Deisseroth, Structural foundations of optogenetics: Determinants of channelrhodopsin ion selectivity. Proceedings of the National Academy of Sciences of the United States of America. 113, 822–829 (2016).\n\n\n29. E. G. Govorunova, O. A. Sineshchekov, R. Janz, X. Liu, J. L. Spudich, Natural light-gated anion channels: A family of microbial rhodopsins for advanced optogenetics. Science. 349, 647–650 (2015).\n\n\n30. E. G. Govorunova, O. A. Sineshchekov, E. M. Rodarte, R. Janz, O. Morelle, M. Melkonian, G. K. S. Wong, J. L. Spudich, The Expanding Family of Natural Anion Channelrhodopsins Reveals Large Variations in Kinetics, Conductance, and Spectral Sensitivity. Scientific Reports. 7, 1–10 (2017).\n\n\n31. J. Vierock, S. Rodriguez-Rozada, A. Dieter, F. Pieper, R. Sims, F. Tenedini, A. C. F. Bergs, I. Bendifallah, F. Zhou, N. Zeitzschel, J. Ahlbeck, S. Augustin, K. Sauter, E. Papagiakoumou, A. Gottschalk, P. Soba, V. Emiliani, A. K. Engel, P. Hegemann, J. S. Wiegert, BiPOLES is an optogenetic tool developed for bidirectional dual-color control of neurons. Nature Communications. 12, 1–20 (2021).\n\n\n32. S. Saran, N. Gupta, S. Roy, Theoretical analysis of low-power fast optogenetic control of firing of Chronos-expressing neurons. Neurophotonics. 5, 1 (2018).\n\n\n33. N. Gupta, H. Bansal, S. Roy, Theoretical optimization of high-frequency optogenetic spiking of red-shifted very fast-Chrimson-expressing neurons. Neurophotonics. 6, 1 (2019).\n\n\n34. H. Bansal, N. Gupta, S. Roy, Theoretical Analysis of Low-power Bidirectional Optogenetic Control of High-frequency Neural Codes with Single Spike Resolution. Neuroscience. 449, 165–188 (2020).\n\n\n35. H. Bansal, N. Gupta, S. Roy, Comparison of low-power, high-frequency and temporally precise optogenetic inhibition of spiking in NpHR, eNpHR3.0 and Jaws-expressing neurons. Biomedical Physics and Engineering Express. 6, 045011 (2020).\n\n\n36. H. Bansal, N. Gupta, S. Roy, Theoretical analysis of optogenetic spiking with ChRmine, bReaChES and CsChrimson-expressing neurons for retinal prostheses. Journal of Neural Engineering. 18, 0460b8 (2021).\n\n\n37. S. Moldakarimov, M. Bazhenov, D. E. Feldman, T. J. Sejnowski, Structured networks support sparse traveling waves in rodent somatosensory cortex. Proceedings of the National Academy of Sciences of the United States of America. 115, 5277–5282 (2018).\n\n\n38. K. A. Wilmes, C. Clopath, Inhibitory microcircuits for top-down plasticity of sensory representations. Nat Commun. 10, 5055 (2019).\n\n\n39. A. Aussel, L. Buhry, L. Tyvaert, R. Ranta, A detailed anatomical and mathematical model of the hippocampal formation for the generation of sharp-wave ripples and theta-nested gamma oscillations. J Comput Neurosci. 45, 207–221 (2018).\n\n\n40. A. Aussel, R. Ranta, O. Aron, S. Colnat-Coulbois, L. Maillard, L. Buhry, Cell to network computational model of the epileptic human hippocampus suggests specific roles of network and channel dysfunctions in the ictal and interictal oscillations. J Comput Neurosci (2022), doi:10.1007/s10827-022-00829-5."
  },
  {
    "objectID": "aim2.html#rationale",
    "href": "aim2.html#rationale",
    "title": "5  Aim 2: Multi-input CLOC",
    "section": "Rationale",
    "text": "Rationale\n\nAdvantages of multi-input control\nThe power of closed-loop optogenetic control (CLOC, henceforth referring specifically to feedback control; see Section 3.1.1) is limited by the degrees of freedom provided by the optogenetic actuation scheme. One important distinction in possible actuation schemes is between “unidirectional”—control by a single opsin type—and “bidirectional”—where both excitatory and inhibitory opsins are used. Unidirectional control has obvious shortcomings: for example, an excitatory opsin alone can only raise the firing rate of target neurons, not lower it or even clamp to a baseline level. This setup would also be unable to lower the firing rate quickly, in the case of a dynamic reference trajectory. Moreover, besides enabling bidirectional stimulation, general multi-input methods could enable more precise control by targeting different neurons simultaneously, such as stimulation of cells at different depths in a cortical column or across columns.\n\n\nAdvantages of model-based, optimal control\nWhile a previous study (1) has already laid the foundation for bidirectional CLOC, it does not feature the generalizability and scalability of the model-based, optimal control algorithms introduced by later work (2) (see Section 3.3) for unidirectional actuation. This adaptive linear-quadratic regulator (LQR) approach is more robust to disturbances and can scale to multi-input multi-output (MIMO) systems. Moreover, its behavior can be easily configured by setting penalties on state error, the control signal, and even the derivative of the control signal to encourage smooth actuation.\n\n\nChallenges of combining\nThus, a natural goal for furthering CLOC is to combine the advantages of bidirectional actuation and model-based optimal control—however, this poses additional challenges and opportunities. The adaptive LQR method previously developed is unsuitable for bidirectional actuation because it does not model the constraint that the input (light intensity) must be nonnegative. While violations of this constraint are relatively infrequent and of little consequence when using an excitatory opsin to reach elevated, slowly varying trajectories, a dual-input scenario would be different. For instance, the controller might call for negative inhibitory input rather than positive excitatory input—a problem that might be solvable with heuristics for the simplest cases but which would pose serious limitations with increasing actuator count.\n\n\nInnovation\nI propose addressing this problem using model predictive control (MPC), which is widely used for its flexibility in implementing optimal control with constraints. Rather than computing the control signal from the current error signal at each step, MPC looks ahead, optimizing over the predicted trajectory some finite number of steps into the future, in what is known as “receding horizon control.” I hypothesize that a model predictive strategy will be able to optimize multi-input optogenetic actuation while accommodating experimental constraints and considerations and maintaining low error levels during fast, real-time control. I plan to achieve this aim by adapting previously demonstrated linear models and adding input constraints, demonstrating the advantage of MPC-powered multi-input CLOC in silico, and benchmarking algorithm performance to inform future in-vivo experiments.\n\n\n\n\n\n\n\n\n\nFigure 5.1: An illustration of how MPC optimizes the system input over a receding horizon. By Martin Behrendt, licensed under CC BY-SA 3.0."
  },
  {
    "objectID": "aim2.html#approach",
    "href": "aim2.html#approach",
    "title": "5  Aim 2: Multi-input CLOC",
    "section": "Approach",
    "text": "Approach\n\nSystem and controller formulation\nNaturally, the model is a vital element of MPC. I will use a previously developed Gaussian linear dynamical system (GLDS) model (2), which has been shown to reliably capture firing rate dynamics in a light-driven spiking neuron system. The discrete-time GLDS is governed by the following equations:\n\\[ x_{t + 1} = Ax_{t} + Bu_{t} + w_t\\ , \\]\n\\[ y_{t} = Cx_{t} + d\\ , \\]\n\\[ z_{t} = y_{t} + v_t\\ , \\]\nwhere \\(x_{t} \\in \\mathbb{R}^n\\) is the \\(n\\)-dimensional state, \\(u_{t} \\in \\mathbb{R}^k\\) is the \\(k\\)-dimensional stimulus (i.e., \\(k = 2\\) for two opsins, one light source each), \\(y_{t} \\in \\mathbb{R}^m\\) is the firing rate in spikes/timestep (for each of \\(m\\) measured neurons), and \\(z_{t} \\in \\mathbb{R}^m\\) is the number of binned spikes observed at time \\(t\\). \\(A \\in \\mathbb{R}^{n \\times n}\\), \\(B \\in \\mathbb{R}^{n \\times k}\\), and \\(C \\in \\mathbb{R}^{m \\times n}\\) are the state transition, input, and output matrices, respectively. \\(w_{t} \\sim \\mathcal{N}\\left( 0, Q \\right)\\) and \\(v_{t}\\mathcal{\\sim N}\\left( 0, R \\right)\\) are Gaussian-distributed process and measurement noise, respectively, and \\(d \\in \\mathbb{R}^{m \\times 1}\\) represents baseline firing rates. Model order (\\(n\\)) and horizon length (\\(T \\in \\mathbb{N}\\)) will be chosen to balance complexity and prediction error for noise-driven fitting data generated from the test network. The latent state \\(x_{t}\\) will be estimated online using the Kalman filter (3), driven by the prediction error \\(z_{t} - {\\widehat{y}}_{t|t - 1}\\).\nI will set hard non-negative constraints on the light input as well as a ceiling determined by hardware limitations (i.e., the maximum voltage deliverable to the LED driver). To design an appropriate cost function, I will use a conventional per-time step quadratic form\n\\[\\ell( x_{t},r_{t},u_{t} ) = ( x_{t} - r_{t} )^{T}Q^{\\text{ctrl}}( x_{t} - r_{t} ) + u^{T}R^{\\text{ctrl}}u\\ ,\\]\nwhere \\(r_{t} \\in \\mathbb{R}^n\\) is the reference trajectory at time \\(t\\). \\(Q^{\\text{ctrl}}\\) and \\(R^{\\text{ctrl}}\\) are real \\(n \\times n\\) and \\(k \\times k\\) matrices chosen to appropriately penalize tracking error and stimulus size, respectively. This quadratic cost function formulation lends the problem well to standard optimization techniques—combined with a linear dynamical system, it constitutes the classical linear-quadratic-Gaussian (LQG) control problem.\nThen, at every time step \\(t\\) the controller solves the following quadratic program:\n\\[\n\\begin{aligned}\n    \\text{minimize}{} \\quad & \\sum_{\\tau=t}^{t+T} \\ell(x_\\tau, u_\\tau) \\\\\n    \\text{subject to} \\quad & u_\\tau \\succeq 0 \\\\\n        & x_{\\tau + 1} = Ax_{\\tau}+Bu_\\tau \\\\\n\\end{aligned}\n\\]\nwhere \\(T \\in \\mathbb{N}\\) is the number of steps in the prediction/control horizon and \\(\\succeq\\) indicates an inequality for each element of \\(u_\\tau \\in \\mathbb{R}^k\\). This yields the solution \\(\\tilde{u}_\\tau,...,\\tilde{u}_{\\tau+T-1}\\), of which we take just the first step to apply to the system:\n\\[ u_t = \\tilde{u}_t \\]\n\n\nDemonstration of advantages in silico\nTo demonstrate the advantages of bidirectional control and of MPC, I will control the firing rate of simulated spiking neurons under four conditions: LQR with one opsin, LQR with two opsins, MPC with one opsin and MPC with two opsins. I will test scenarios where the limitations of unidirectional control and LQR will be manifest, namely clamping activity to baseline levels in the presence of unmodeled disturbances to the system and for time-varying reference trajectories. I will also demonstrate the more advanced multi-input applications of MPC by controlling multiple neurons simultaneously with multiple light sources.\nAll experiments will be performed on a simulated randomly connected network of excitatory and inhibitory leaky integrate-and-fire (LIF) neurons or a Poisson linear dynamical system (4) model fit to simulated data. The framework of Aim 1 will be leveraged to simulate electrode recording and optogenetic stimulation, and spikes from individual neurons will be used as inputs to the controller. In all experiments I will compare my MPC approach to the unconstrained LQR controller developed previously (2). I will also compare to an optimal open-loop stimulus computed over a whole-trial horizon. To evaluate controller performance, I will use metrics such as the mean-squared error (MSE) between the reference firing rate and the Gaussian window-smoothed firing rate of the spikes received by the controller during the trial. Noise will be provided to the network where needed to simulate an external disturbance.\n\n\nPreparation for real-time experiments\nTo inform future experiments where compute time is crucial for control performance, I will record compute time of LQR and MPC approaches for varying numbers of input and output channels \\(k\\) and \\(m\\). For instance, the time required to solve the quadratic program for MPC would provide a preliminary estimate of the minimum control period we may want to use when implementing MPC in real time. To get a better idea of how this compute latency might affect a real experiment, I will also test multi-input MPC on a more realistic simulation, such as one of the example experiments from Section 4.6.2, leveraging the latency simulation capabilities of the CLOC simulation framework."
  },
  {
    "objectID": "aim2.html#expected-results",
    "href": "aim2.html#expected-results",
    "title": "5  Aim 2: Multi-input CLOC",
    "section": "Expected results",
    "text": "Expected results\nI expect that bidirectional control will be perform better than unidirectional control at the aforementioned tasks of clamping baseline activities and following a dynamic reference trajectory. I also expect that MPC will attain higher performance than LQR for all multi-input conditions and especially in the case of a dynamic reference. While MPC will be considerably slower than LQR, it should be fast enough for control of neural phenomena on the timescale of hundreds of milliseconds."
  },
  {
    "objectID": "aim2.html#preliminary-results",
    "href": "aim2.html#preliminary-results",
    "title": "5  Aim 2: Multi-input CLOC",
    "section": "Preliminary results",
    "text": "Preliminary results\nBasic simulations controlling a linear dynamical system model fit to experimental data show the advantages of bidirectional control and of MPC (see Figure 5.2). Bidirectional actuation allows the system to avoid overshooting the reference, in the case of LQR, or to minimize error faster by first exciting then inhibiting, in the case of MPC. MPC’s advantages in looking ahead also clearly allow it to follow the reference more closely than the heuristic LQR controller (assigning negative inputs to the second light source).\n\n\n\n\n\nFigure 5.2: Simulated control of an linear dynamical system with 1- and 2-input control, using LQR and MPC controllers. The top panel of each contains the reference and the actual firing rate, in spikes/second. The bottom contains the light intensity, in terms of mW/mm2, where blue represents light for an excitatory opsin (such as ChR2) and red-orange that for an inhibitory opsin (such as Jaws)."
  },
  {
    "objectID": "aim2.html#potential-pitfalls-alternative-strategies",
    "href": "aim2.html#potential-pitfalls-alternative-strategies",
    "title": "5  Aim 2: Multi-input CLOC",
    "section": "Potential pitfalls, alternative strategies",
    "text": "Potential pitfalls, alternative strategies\nThere are some limitations in the proposed GLDS model that may need to be addressed. While it was adequate for the experiments in (2), a Poisson linear dynamical system model (4) may be needed in the case that negative predicted firing rates (because the output is not constrained to be nonnegative) produce significant model mismatch error. Also, in case the data is not fit well by a GLDS, I may explore the impact of making parts of the model nonlinear. The output equation \\(y=Cx+d\\), for example, could be replaced by a nonlinear equation of the form \\(y=f(x)\\). While this would likely make the estimation of \\(x\\) more expensive, the underlying dynamics could remain linear, leaving the same underlying quadratic program for the controller to solve.\nThis touches another potential concern: the speed of the algorithm. If the optimization problem takes too long to solve, there are a few options to explore. One is that some variations in the control scheme can help balance speed and performance, such as letting the control horizon be shorter than the prediction horizon, which shrinks the optimization problem. Likewise, the control period can be longer than the time step of the system, reducing how often the control signal is computed. If conventional methods such as these are unsuccessful, I may turn to methods such as that described in (5) or training an artificial neural network to approximate the exact solution of the quadratic program or to minimize the cost directly. Another potential solution is explicit MPC (6), which finds a piecewise-affine explicit solution to the quadratic program which can be faster than using a solver to obtain the implicit solution for small-enough problems.\n\n\n\n\n1. J. P. Newman, M. F. Fong, D. C. Millard, C. J. Whitmire, G. B. Stanley, S. M. Potter, Optogenetic feedback control of neural activity. eLife (2015), doi:10.7554/eLife.07192.\n\n\n2. M. F. Bolus, A. A. Willats, C. J. Rozell, G. B. Stanley, State-space optimal feedback control of optogenetically driven neural activity. Journal of neural engineering. 18, 036006 (2021).\n\n\n3. R. E. Kalman, A new approach to linear filtering and prediction problems. Journal of Fluids Engineering, Transactions of the ASME. 82, 35–45 (1960).\n\n\n4. J. H. Macke, L. Buesing, J. P. Cunningham, B. M. Yu, K. V. Shenoy, M. Sahani, \"Empirical models of spiking in neural populations\" in Advances in Neural Information Processing Systems (Curran Associates, Inc., 2011; https://proceedings.neurips.cc/paper/2011/hash/7143d7fbadfa4693b9eec507d9d37443-Abstract.html), vol. 24.\n\n\n5. Y. Wang, S. Boyd, Fast Model Predictive Control Using Online Optimization. IEEE TRANSACTIONS ON CONTROL SYSTEMS TECHNOLOGY. 18, 267 (2010).\n\n\n6. A. Bemporad, M. Morari, V. Dua, E. N. Pistikopoulos, The explicit linear quadratic regulator for constrained systems. Automatica. 38, 3–20 (2002)."
  },
  {
    "objectID": "aim3.html#rationale",
    "href": "aim3.html#rationale",
    "title": "6  Aim 3: Latent Factor Control",
    "section": "Rationale",
    "text": "Rationale\nTunguska event Vangelis rings of Uranus take root and flourish Jean-François Champollion not a sunrise but a galaxyrise. Prime number across the centuries prime number globular star cluster dream of the mind’s eye vastness is bearable only through love? Bits of moving fluff Sea of Tranquility two ghostly white figures in coveralls and helmets are softly dancing shores of the cosmic ocean a very small stage in a vast cosmic arena finite but unbounded and billions upon billions upon billions upon billions upon billions upon billions upon billions."
  },
  {
    "objectID": "aim3.html#approach",
    "href": "aim3.html#approach",
    "title": "6  Aim 3: Latent Factor Control",
    "section": "Approach",
    "text": "Approach\n\nSubaim 1\nPoutine distillery cray letterpress ex viral cronut. Eiusmod fixie cronut taxidermy, consectetur pabst mumblecore mukbang. Franzen snackwave squid enamel pin. Waistcoat poutine occaecat, cornhole chia art party voluptate.\n\nPreliminary results\nSelfies church-key mollit viral synth, in fanny pack humblebrag messenger bag before they sold out pour-over. Health goth trust fund raw denim irure. Consectetur shaman flexitarian pickled chicharrones. Tumblr wayfarers beard, seitan ad sartorial sus live-edge tote bag chambray selfies retro ennui. Crucifix incididunt food truck pour-over sus.\n\n\nPotential pitfalls, alternative strategies\nGreen juice tote bag edison bulb fingerstache meh before they sold out mixtape iPhone locavore bushwick cardigan kombucha literally est. Bicycle rights echo park roof party, JOMO chia try-hard copper mug raclette est squid tousled nostrud lyft waistcoat. Next level DIY tacos irure aute, kinfolk echo park green juice. Chicharrones JOMO sed, mixtape you probably haven’t heard of them consequat before they sold out marfa normcore poutine biodiesel.\n\n\n\nSubaim 2\nPoutine distillery cray letterpress ex viral cronut. Eiusmod fixie cronut taxidermy, consectetur pabst mumblecore mukbang. Franzen snackwave squid enamel pin. Waistcoat poutine occaecat, cornhole chia art party voluptate.\n\nPreliminary results\nSelfies church-key mollit viral synth, in fanny pack humblebrag messenger bag before they sold out pour-over. Health goth trust fund raw denim irure. Consectetur shaman flexitarian pickled chicharrones. Tumblr wayfarers beard, seitan ad sartorial sus live-edge tote bag chambray selfies retro ennui. Crucifix incididunt food truck pour-over sus.\n\n\nPotential pitfalls, alternative strategies\nGreen juice tote bag edison bulb fingerstache meh before they sold out mixtape iPhone locavore bushwick cardigan kombucha literally est. Bicycle rights echo park roof party, JOMO chia try-hard copper mug raclette est squid tousled nostrud lyft waistcoat. Next level DIY tacos irure aute, kinfolk echo park green juice. Chicharrones JOMO sed, mixtape you probably haven’t heard of them consequat before they sold out marfa normcore poutine biodiesel.\n\n\n\nSubaim 3\nPoutine distillery cray letterpress ex viral cronut. Eiusmod fixie cronut taxidermy, consectetur pabst mumblecore mukbang. Franzen snackwave squid enamel pin. Waistcoat poutine occaecat, cornhole chia art party voluptate.\n\nPreliminary results\nSelfies church-key mollit viral synth, in fanny pack humblebrag messenger bag before they sold out pour-over. Health goth trust fund raw denim irure. Consectetur shaman flexitarian pickled chicharrones. Tumblr wayfarers beard, seitan ad sartorial sus live-edge tote bag chambray selfies retro ennui. Crucifix incididunt food truck pour-over sus.\n\n\nPotential pitfalls, alternative strategies\nGreen juice tote bag edison bulb fingerstache meh before they sold out mixtape iPhone locavore bushwick cardigan kombucha literally est. Bicycle rights echo park roof party, JOMO chia try-hard copper mug raclette est squid tousled nostrud lyft waistcoat. Next level DIY tacos irure aute, kinfolk echo park green juice. Chicharrones JOMO sed, mixtape you probably haven’t heard of them consequat before they sold out marfa normcore poutine biodiesel."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "1. H.\nAdesnik, L. Abdeladim, Probing neural codes\nwith two-photon holographic optogenetics. Nat Neurosci.\n24, 1356–1366 (2021).\n\n\n2. J.\nAru, J. Aru, V. Priesemann, M. Wibral, L. Lana, G. Pipa, W. Singer, R.\nVicente, Untangling\ncross-frequency coupling in neuroscience. Current Opinion in\nNeurobiology. 31, 51–61 (2015).\n\n\n3. A.\nAussel, L. Buhry, L. Tyvaert, R. Ranta, A detailed anatomical\nand mathematical model of the hippocampal formation for the generation\nof sharp-wave ripples and theta-nested gamma oscillations. J\nComput Neurosci. 45, 207–221 (2018).\n\n\n4. A.\nAussel, R. Ranta, O. Aron, S. Colnat-Coulbois, L. Maillard, L. Buhry,\nCell to network computational model of the epileptic human hippocampus\nsuggests specific roles of network and channel dysfunctions in the ictal\nand interictal oscillations. J Comput Neurosci (2022), doi:10.1007/s10827-022-00829-5.\n\n\n5. L.\nAvitan, C. Stringer, Not so spontaneous: Multi-dimensional\nrepresentations of behaviors and context in sensory areas.\nNeuron (2022), doi:10.1016/j.neuron.2022.06.019.\n\n\n6. H.\nBansal, N. Gupta, S. Roy, Theoretical\nAnalysis of Low-power Bidirectional Optogenetic Control of\nHigh-frequency Neural Codes with Single Spike Resolution.\nNeuroscience. 449, 165–188 (2020).\n\n\n7. H.\nBansal, N. Gupta, S. Roy, Comparison of low-power,\nhigh-frequency and temporally precise optogenetic inhibition of spiking\nin NpHR, eNpHR3.0 and Jaws-expressing neurons. Biomedical\nPhysics and Engineering Express. 6, 045011\n(2020).\n\n\n8. H.\nBansal, N. Gupta, S. Roy, Theoretical analysis of\noptogenetic spiking with ChRmine, bReaChES and CsChrimson-expressing\nneurons for retinal prostheses. Journal of Neural\nEngineering. 18, 0460b8 (2021).\n\n\n9. A.\nBemporad, M. Morari, V. Dua, E. N. Pistikopoulos, The explicit linear\nquadratic regulator for constrained systems. Automatica.\n38, 3–20 (2002).\n\n\n10. G.\nJ. Berman, D. M. Choi, W. Bialek, J. W. Shaevitz, Mapping the stereotyped\nbehaviour of freely moving fruit flies. Journal of The Royal\nSociety Interface. 11, 20140672 (2014).\n\n\n11. A.\nBerndt, S. Y. Lee, J. Wietek, C. Ramakrishnan, E. E. Steinberg, A. J.\nRashid, H. Kim, S. Park, A. Santoro, P. W. Frankland, S. M. Iyer, S.\nPak, S. Ährlund-Richter, S. L. Delp, R. C. Malenka, S. A. Josselyn, M.\nCarlén, P. Hegemann, K. Deisseroth, Structural foundations of\noptogenetics: Determinants of channelrhodopsin ion selectivity.\nProceedings of the National Academy of Sciences of the United States\nof America. 113, 822–829 (2016).\n\n\n12. A.\nBogdanchikov, M. Zhaparov, R. Suliyev, \"Python to learn programming\" in\nJournal of Physics: Conference Series (IOP Publishing, 2013; https://iopscience.iop.org/article/10.1088/1742-6596/423/1/012027),\nvol. 423, p. 012027.\n\n\n13. M.\nF. Bolus, A. A. Willats, C. J. Whitmire, C. J. Rozell, G. B. Stanley, Design strategies for\ndynamic closed-loop optogenetic neurocontrol in vivo. Journal of\nNeural Engineering. 15, 026011 (2018).\n\n\n14. M.\nF. Bolus, A. A. Willats, C. J. Rozell, G. B. Stanley, State-space optimal\nfeedback control of optogenetically driven neural activity.\nJournal of neural engineering. 18, 036006\n(2021).\n\n\n15. E.\nA. Buffalo, P. Fries, R. Landman, T. J. Buschman, R. Desimone, Laminar differences in\ngamma and alpha coherence in the ventral stream. Proceedings of\nthe National Academy of Sciences of the United States of America.\n108, 11262–11267 (2011).\n\n\n16. T.\nJ. Buschman, E. L. Denovellis, C. Diogo, D. Bullock, E. K. Miller, Synchronous\nOscillatory Neural Ensembles for Rules in the Prefrontal Cortex.\nNeuron. 76, 838–846 (2012).\n\n\n17. G.\nBuzsáki, A. Draguhn, Neuronal oscillations in\ncortical networks. Science. 304, 1926–1929\n(2004).\n\n\n18. G.\nBuzsáki, C. A. Anastassiou, C. Koch, The origin of extracellular\nfields and currents — EEG, ECoG, LFP and spikes. Nature Reviews\nNeuroscience 2012 13:6. 13, 407–420 (2012).\n\n\n19. G.\nBuzsáki, Hippocampal sharp\nwave-ripple: A cognitive biomarker for episodic memory and planning.\nHippocampus. 25, 1073–1188 (2015).\n\n\n20. J.\nA. Cardin, M. Carlén, K. Meletis, U. Knoblich, F. Zhang, K. Deisseroth,\nL. H. Tsai, C. I. Moore, Targeted optogenetic\nstimulation and recording of neurons in vivo using cell-type-specific\nexpression of Channelrhodopsin-2. Nature Protocols.\n5, 247–254 (2010).\n\n\n21. S.\nChen, A. Z. Weitemier, X. Zeng, L. He, X. Wang, Y. Tao, A. J. Y. Huang,\nY. Hashimotodani, M. Kano, H. Iwasaki, L. K. Parajuli, S. Okabe, D. B.\nLoong Teh, A. H. All, I. Tsutsui-Kimura, K. F. Tanaka, X. Liu, T. J.\nMcHugh, Near-infrared\ndeep brain stimulation via upconversion nanoparticle–mediated\noptogenetics. Science. 359, 679–684\n(2018).\n\n\n22. A.\nS. Chuong, M. L. Miri, V. Busskamp, G. A. C. Matthews, L. C. Acker, A.\nT. Sørensen, A. Young, N. C. Klapoetke, M. A. Henninger, S. B.\nKodandaramaiah, M. Ogawa, S. B. Ramanlal, R. C. Bandler, B. D. Allen, C.\nR. Forest, B. Y. Chow, X. Han, Y. Lin, K. M. Tye, B. Roska, J. A.\nCardin, E. S. Boyden, Noninvasive optical inhibition\nwith a red-shifted microbial rhodopsin. Nature\nNeuroscience. 17, 1123–1129 (2014).\n\n\n23. S.\nR. Cole, B. Voytek, Brain Oscillations and\nthe Importance of Waveform Shape. Trends in Cognitive\nSciences. 21, 137–149 (2017).\n\n\n24. S.\nCole, B. Voytek, Cycle-by-cycle analysis of\nneural oscillations. Journal of Neurophysiology.\n122, 849–861 (2019).\n\n\n25. B.\nR. Cowley, A. C. Snyder, K. Acar, R. C. Williamson, B. M. Yu, M. A.\nSmith, Slow Drift\nof Neural Activity as a Signature of Impulsivity in Macaque Visual and\nPrefrontal Cortex. Neuron. 108, 551–567.e8\n(2020).\n\n\n26. J.\nT. Davie, M. H. P. Kole, J. J. Letzkus, E. A. Rancz, N. Spruston, G. J.\nStuart, M. Häusser, Dendritic patch-clamp\nrecording. Nature Protocols. 1, 1235–1247\n(2006).\n\n\n27. Z.\nW. Davis, L. Muller, J. Martinez-Trujillo, T. Sejnowski, J. H. Reynolds,\nSpontaneous\ntravelling cortical waves gate perception in behaving primates.\nNature. 587, 432–436 (2020).\n\n\n28. A.\nP. Davison, M. L. Hines, E. Muller, Trends in programming\nlanguages for neuroscience simulations. Frontiers in\nNeuroscience. 3, 374–380 (2009).\n\n\n29. S.\nDutta, E. Ackermann, C. Kemere, Analysis of an open\nsource, closed-loop, realtime system for hippocampal sharp-wave ripple\ndisruption. Journal of Neural Engineering.\n16, 016009 (2019).\n\n\n30. V.\nEmiliani, A. E. Cohen, K. Deisseroth, M. Häusser, All-optical\ninterrogation of neural circuits. Journal of Neuroscience.\n35, 13917–13926 (2015).\n\n\n31. D.\nEngel, Subcellular patch-clamp\nrecordings from the somatodendritic domain of nigral dopamine\nneurons. Journal of Visualized Experiments.\n2016, e54601 (2016).\n\n\n32. D.\nEriksson, A. Schneider, A. Thirumalai, M. Alyahyay, B. de la Crompe, K.\nSharma, P. Ruther, I. Diester, Multichannel\noptogenetics combined with laminar recordings for ultra-controlled\nneuronal interrogation. Nat Commun. 13,\n985 (2022).\n\n\n33. B.\nD. Evans, S. Jarvis, S. R. Schultz, K. Nikolic, PyRhO: A Multiscale\nOptogenetics Simulation Platform. Frontiers in\nNeuroinformatics. 10, 8 (2016).\n\n\n34. M.\nS. Fabus, A. J. Quinn, C. E. Warnaby, M. W. Woolrich, Automatic decomposition of\nelectrophysiological data into distinct nonsinusoidal oscillatory\nmodes. Journal of Neurophysiology. 126,\n1670–1684 (2021).\n\n\n35. G.\nFaini, C. Molinier, C. Telliez, C. Tourain, B. C. Forget, E. Ronzitti,\nV. Emiliani, Ultrafast Light\nTargeting for High-Throughput Precise Control of Neuronal Networks.\nbioRxiv, 2021.06.14.448315 (2021).\n\n\n36. L.\nFenno, O. Yizhar, K. Deisseroth, The\ndevelopment and application of optogenetics. Annual Review of\nNeuroscience. 34, 389–412 (2011).\n\n\n37. T.\nJ. Foutz, R. L. Arlow, C. C. Mcintyre, Theoretical\nprinciples underlying optical stimulation of a channelrhodopsin-2\npositive pyramidal neuron. J Neurophysiol.\n107, 3235–3245 (2012).\n\n\n38. W.\nGöbel, F. Helmchen, In Vivo Calcium\nImaging of Neural Network Function. Physiology.\n22, 358–365 (2007).\n\n\n39. E.\nG. Govorunova, O. A. Sineshchekov, R. Janz, X. Liu, J. L. Spudich, Natural light-gated anion\nchannels: A family of microbial rhodopsins for advanced\noptogenetics. Science. 349, 647–650\n(2015).\n\n\n40. E.\nG. Govorunova, O. A. Sineshchekov, E. M. Rodarte, R. Janz, O. Morelle,\nM. Melkonian, G. K. S. Wong, J. L. Spudich, The Expanding Family of Natural\nAnion Channelrhodopsins Reveals Large Variations in Kinetics,\nConductance, and Spectral Sensitivity. Scientific Reports.\n7, 1–10 (2017).\n\n\n41. V.\nGradinaru, F. Zhang, C. Ramakrishnan, J. Mattis, R. Prakash, I. Diester,\nI. Goshen, K. R. Thompson, K. Deisseroth, Molecular and Cellular\nApproaches for Diversifying and Extending Optogenetics.\nCell. 141, 154–165 (2010).\n\n\n42. L.\nGrosenick, J. H. Marshel, K. Deisseroth, Review Closed-Loop\nand Activity-Guided Optogenetic Control. Neuron.\n86, 106–139 (2015).\n\n\n43. L.\nA. Gunaydin, O. Yizhar, A. Berndt, V. S. Sohal, K. Deisseroth, P.\nHegemann, Ultrafast\noptogenetic control. Nature Neuroscience.\n13, 387–392 (2010).\n\n\n44. N.\nGupta, H. Bansal, S. Roy, Theoretical optimization\nof high-frequency optogenetic spiking of red-shifted very\nfast-Chrimson-expressing neurons. Neurophotonics.\n6, 1 (2019).\n\n\n45. P.\nGutruf, J. A. Rogers, Implantable, wireless\ndevice platforms for neuroscience research. Current Opinion in\nNeurobiology. 50, 42–49 (2018).\n\n\n46. E.\nHagen, S. Næss, T. V. Ness, G. T. Einevoll, Multimodal modeling of\nneural network activity: Computing LFP, ECoG, EEG, and MEG signals with\nLFPy 2.0. Frontiers in Neuroinformatics.\n12, 92 (2018).\n\n\n47. M.\nL. Hines, N. T. Carnevale, The NEURON Simulation\nEnvironment. Neural Computation. 9,\n1179–1209 (1997).\n\n\n48. D.\nR. Hochbaum, Y. Zhao, S. L. Farhi, N. Klapoetke, C. A. Werley, V.\nKapoor, P. Zou, J. M. Kralj, D. MacLaurin, N. Smedemark-Margulies, J. L.\nSaulnier, G. L. Boulting, C. Straub, Y. K. Cho, M. Melkonian, G. K. S.\nWong, D. J. Harrison, V. N. Murthy, B. L. Sabatini, E. S. Boyden, R. E.\nCampbell, A. E. Cohen, All-optical electrophysiology\nin mammalian neurons using engineered microbial rhodopsins.\nNature Methods. 11, 825–833 (2014).\n\n\n49. G.\nR. Holt, C. Koch, Electrical interactions\nvia the extracellular potential near cell bodies. Journal of\nComputational Neuroscience. 6, 169–184\n(1999).\n\n\n50. C.\nHurwitz, A. Srivastava, K. Xu, J. Jude, M. G. Perich, L. E. Miller, M.\nH. Hennig, \"Targeted Neural Dynamical Modeling\" in Advances in\nNeural Information Processing Systems (2021; https://github.com/HennigLab/tndm.),\nvol. 35, pp. 29379–29392.\n\n\n51. M.\nJazayeri, S. Ostojic, Interpreting neural\ncomputations by examining intrinsic and embedding dimensionality of\nneural activity. Current Opinion in Neurobiology.\n70, 113–120 (2021).\n\n\n52. K.\nJohnsen, kjohnsen/tklfp: v0.2.0 (2022), doi:10.5281/zenodo.6787979.\n\n\n53. A.\nL. Juavinett, G. Bekheet, A. K. Churchland, Chronically implanted\nNeuropixels probes enable high-yield recordings in freely moving\nmice. eLife. 8, e47188 (2019).\n\n\n54. R.\nE. Kalman, A new approach to\nlinear filtering and prediction problems. Journal of Fluids\nEngineering, Transactions of the ASME. 82, 35–45\n(1960).\n\n\n55. A.\nKazemipour, O. Novak, D. Flickinger, J. S. Marvin, A. S. Abdelfattah, J.\nKing, P. M. Borden, J. J. Kim, S. H. Al-Abdullatif, P. E. Deal, E. W.\nMiller, E. R. Schreiter, S. Druckmann, K. Svoboda, L. L. Looger, K.\nPodgorski, Kilohertz\nframe-rate two-photon tomography. Nature Methods.\n16, 778–786 (2019).\n\n\n56. K.\nE. Kishi, Y. S. Kim, M. Fukuda, M. Inoue, T. Kusakizako, P. Y. Wang, C.\nRamakrishnan, E. F. X. Byrne, E. Thadhani, J. M. Paggi, T. E. Matsui, K.\nYamashita, T. Nagata, M. Konno, S. Quirin, M. Lo, T. Benster, T. Uemura,\nK. Liu, M. Shibata, N. Nomura, S. Iwata, O. Nureki, R. O. Dror, K.\nInoue, K. Deisseroth, H. E. Kato, Structural basis for\nchannel conduction in the pump-like channelrhodopsin ChRmine.\nCell. 185, 672–689.e23 (2022).\n\n\n57. N.\nC. Klapoetke, Y. Murata, S. S. Kim, S. R. Pulver, A. Birdsey-Benson, Y.\nK. Cho, T. K. Morimoto, A. S. Chuong, E. J. Carpenter, Z. Tian, J. Wang,\nY. Xie, Z. Yan, Y. Zhang, B. Y. Chow, B. Surek, M. Melkonian, V.\nJayaraman, M. Constantine-Paton, G. K. S. Wong, E. S. Boyden, Independent optical excitation\nof distinct neural populations. Nature Methods.\n11, 338–346 (2014).\n\n\n58. T.\nKnöpfel, C. Song, Optical voltage imaging\nin neurons: moving from technology development to practical tool.\nNat Rev Neurosci. 20, 719–727 (2019).\n\n\n59. E.\nKrook-Magnuson, C. Armstrong, M. Oijala, I. Soltesz, On-demand optogenetic control\nof spontaneous seizures in temporal lobe epilepsy. Nature\nCommunications. 4, 1–8 (2013).\n\n\n60. A.\nKumar, I. Vlachos, A. Aertsen, C. Boucsein, Challenges of\nunderstanding brain function by selective modulation of neuronal\nsubpopulations. Trends in Neurosciences.\n36, 579–586 (2013).\n\n\n61. J.\nY. Lin, P. M. Knutsen, A. Muller, D. Kleinfeld, R. Y. Tsien, ReaChR: A red-shifted variant of\nchannelrhodopsin enables deep transcranial optogenetic excitation.\nNature Neuroscience. 16, 1499–1508\n(2013).\n\n\n62. M.\nLundqvist, J. Rose, P. Herman, S. L. L. Brincat, T. J. J. Buschman, E.\nK. K. Miller, Gamma and Beta\nBursts Underlie Working Memory. Neuron.\n90, 152–164 (2016).\n\n\n63. M.\nLundqvist, J. Rose, M. Warden, T. Buschman, P. Herman, Reduced\nvariability of bursting activity during working memory (2022), doi:10.1101/2022.02.18.481088.\n\n\n64. L.\nvan der Maaten, G. Hinton, Visualizing Data\nusing t-SNE. Journal of Machine Learning Research.\n9, 2579–2605 (2008).\n\n\n65. J.\nH. Macke, L. Buesing, J. P. Cunningham, B. M. Yu, K. V. Shenoy, M.\nSahani, \"Empirical models of spiking in neural populations\" in\nAdvances in Neural Information Processing Systems (Curran\nAssociates, Inc., 2011; https://proceedings.neurips.cc/paper/2011/hash/7143d7fbadfa4693b9eec507d9d37443-Abstract.html),\nvol. 24.\n\n\n66. T.\nMager, D. L. D. L. Morena, V. Senn, J. Schlotte, A. Derrico, K.\nFeldbauer, C. Wrobel, S. Jung, K. Bodensiek, V. Rankovic, L. Browne, A.\nHuet, J. Jüttner, P. G. Wood, J. J. Letzkus, T. Moser, E. Bamberg, High frequency neural\nspiking and auditory signaling by ultrafast red-shifted\noptogenetics. Nature Communications. 9,\n1–14 (2018).\n\n\n67. R.\nI. Martinez-Garcia, B. Voelcker, J. B. Zaltsman, S. L. Patrick, T. R.\nStevens, B. W. Connors, S. J. Cruikshank, Two dynamically\ndistinct circuits drive inhibition in the sensory thalamus.\nNature. 583, 813–818 (2020).\n\n\n68. A.\nMathis, P. Mamidanna, K. M. Cury, T. Abe, V. N. Murthy, M. W. Mathis, M.\nBethge, DeepLabCut:\nmarkerless pose estimation of user-defined body parts with deep\nlearning. Nat Neurosci. 21, 1281–1289\n(2018).\n\n\n69. A.\nMazzoni, H. Lindén, H. Cuntz, A. Lansner, S. Panzeri, G. T. Einevoll, Computing the Local\nField Potential (LFP) from Integrate-and-Fire Network Models.\nPLOS Computational Biology. 11, e1004584\n(2015).\n\n\n70. S.\nMoldakarimov, M. Bazhenov, D. E. Feldman, T. J. Sejnowski, Structured networks\nsupport sparse traveling waves in rodent somatosensory cortex.\nProceedings of the National Academy of Sciences of the United States\nof America. 115, 5277–5282 (2018).\n\n\n71. E.\nMuller, J. A. Bednar, M. Diesmann, M. O. Gewaltig, M. Hines, A. P.\nDavison, Python in\nneuroscience. Frontiers in Neuroinformatics.\n9, 11 (2015).\n\n\n72. L.\nMuller, F. Chavane, J. Reynolds, T. J. Sejnowski, Cortical travelling waves:\nMechanisms and computational principles. Nature Reviews\nNeuroscience. 19, 255–268 (2018).\n\n\n73. A.\nNandy, J. J. Nassi, M. P. Jadi, J. Reynolds, Optogenetically induced\nlow-frequency correlations impair perception. eLife.\n8 (2019), doi:10.7554/eLife.35123.\n\n\n74. S.\nR. Nason, A. K. Vaskov, M. S. Willsey, E. J. Welle, H. An, P. P. Vu, A.\nJ. Bullard, C. S. Nu, J. C. Kao, K. V. Shenoy, T. Jang, H.-S. Kim, D.\nBlaauw, P. G. Patil, C. A. Chestek, A low-power band of\nneuronal spiking activity dominated by local single units improves the\nperformance of brain–machine interfaces. Nature Biomedical\nEngineering 2020, 1–11 (2020).\n\n\n75. J.\nP. Newman, M. F. Fong, D. C. Millard, C. J. Whitmire, G. B. Stanley, S.\nM. Potter, Optogenetic feedback control of neural activity.\neLife (2015), doi:10.7554/eLife.07192.\n\n\n76. E.\nR. Oby, M. D. Golub, J. A. Hennig, A. D. Degenhart, E. C. Tyler-Kabara,\nB. M. Yu, S. M. Chase, A. P. Batista, New neural activity\npatterns emerge with long-term learning. Proceedings of the\nNational Academy of Sciences. 116, 15210–15215\n(2019).\n\n\n77. A.\nM. Packer, B. Roska, M. Häuser, Targeting neurons and photons for\noptogenetics. Nature Neuroscience. 16,\n805–815 (2013).\n\n\n78. H.\nParasuram, B. Nair, E. D’Angelo, M. Hines, G. Naldi, S. Diwakar, Computational modeling\nof single neuron extracellular electric potentials and network local\nfield potentials using LFPsim. Frontiers in Computational\nNeuroscience. 10, 65 (2016).\n\n\n79. K.\nH. Pettersen, H. Lindén, A. M. Dale, G. T. Einevoll, Extracellular\nspikes and CSD. Handbook of neural activity measurement.\n1, 92–135 (2012).\n\n\n80. S.\nM. Potter, A. El Hady, E. E. Fetz, Closed-loop neuroscience\nand neuroengineering. Frontiers in Neural Circuits.\n0, 115 (2014).\n\n\n81. B.\nL. Roth, DREADDs\nfor Neuroscientists. Neuron. 89, 683–694\n(2016).\n\n\n82. A.\nB. Saleem, A. D. Lien, M. Krumin, B. Haider, M. R. Rosón, A. Ayaz, K.\nReinhold, L. Busse, M. Carandini, K. D. Harris, M. Carandini, Subcortical Source\nand Modulation of the Narrowband Gamma Oscillation in Mouse Visual\nCortex. Neuron. 93, 315–322 (2017).\n\n\n83. O.\nG. Sani, B. Pesaran, M. M. Shanechi, M. Hsieh, Where is all the\nnonlinearity: flexible nonlinear modeling of behaviorally relevant\nneural dynamics using recurrent neural networks. bioRxiv,\n2021.09.03.458628 (2021).\n\n\n84. O.\nG. Sani, H. Abbaspourazad, Y. T. Wong, B. Pesaran, M. M. Shanechi, Modeling behaviorally\nrelevant neural dynamics enabled by preferential subspace\nidentification. Nature Neuroscience. 24,\n140–149 (2021).\n\n\n85. S.\nSaran, N. Gupta, S. Roy, Theoretical analysis of\nlow-power fast optogenetic control of firing of Chronos-expressing\nneurons. Neurophotonics. 5, 1\n(2018).\n\n\n86. L.\nK. Scheffer, C. S. Xu, M. Januszewski, Z. Lu, S. Takemura, K. J.\nHayworth, G. B. Huang, K. Shinomiya, J. Maitlin-Shepard, S. Berg, J.\nClements, P. M. Hubbard, W. T. Katz, L. Umayam, T. Zhao, D. Ackerman, T.\nBlakely, J. Bogovic, T. Dolafi, D. Kainmueller, T. Kawase, K. A. Khairy,\nL. Leavitt, P. H. Li, L. Lindsey, N. Neubarth, D. J. Olbris, H. Otsuna,\nE. T. Trautman, M. Ito, A. S. Bates, J. Goldammer, T. Wolff, R.\nSvirskas, P. Schlegel, E. Neace, C. J. Knecht, C. X. Alvarado, D. A.\nBailey, S. Ballinger, J. A. Borycz, B. S. Canino, N. Cheatham, M. Cook,\nM. Dreher, O. Duclos, B. Eubanks, K. Fairbanks, S. Finley, N. Forknall,\nA. Francis, G. P. Hopkins, E. M. Joyce, S. Kim, N. A. Kirk, J. Kovalyak,\nS. A. Lauchie, A. Lohff, C. Maldonado, E. A. Manley, S. McLin, C.\nMooney, M. Ndama, O. Ogundeyi, N. Okeoma, C. Ordish, N. Padilla, C. M.\nPatrick, T. Paterson, E. E. Phillips, E. M. Phillips, N. Rampally, C.\nRibeiro, M. K. Robertson, J. T. Rymer, S. M. Ryan, M. Sammons, A. K.\nScott, A. L. Scott, A. Shinomiya, C. Smith, K. Smith, N. L. Smith, M. A.\nSobeski, A. Suleiman, J. Swift, S. Takemura, I. Talebi, D. Tarnogorska,\nE. Tenshaw, T. Tokhi, J. J. Walsh, T. Yang, J. A. Horne, F. Li, R.\nParekh, P. K. Rivlin, V. Jayaraman, M. Costa, G. S. Jefferis, K. Ito, S.\nSaalfeld, R. George, I. A. Meinertzhagen, G. M. Rubin, H. F. Hess, V.\nJain, S. M. Plaza, A\nconnectome and analysis of the adult Drosophila central brain.\neLife. 9, e57443 (2020).\n\n\n87. S.\nSchneider, J. H. Lee, M. W. Mathis, Learnable latent embeddings for\njoint behavioral and neural analysis (2022), doi:10.48550/arXiv.2204.00673.\n\n\n88. J.\nH. Siegle, A. C. López, Y. A. Patel, K. Abramov, S. Ohayon, J. Voigts,\nOpen Ephys: an\nopen-source, plugin-based platform for multichannel\nelectrophysiology. J. Neural Eng. 14,\n045003 (2017).\n\n\n89. O.\nSporns, Graph\ntheory methods: applications in brain networks. Dialogues in\nClinical Neuroscience. 20, 111–121 (2018).\n\n\n90. S.\nSridharan, M. A. Gajowa, M. B. Ogando, U. K. Jagadisan, L. Abdeladim, M.\nSadahiro, H. A. Bounds, W. D. Hendricks, T. S. Turney, I. Tayler, K.\nGopakumar, I. A. Oldenburg, S. G. Brohawn, H. Adesnik, High-performance\nmicrobial opsins for spatially and temporally precise perturbations of\nlarge neuronal networks. Neuron. 110,\n1139–1155.e6 (2022).\n\n\n91. N.\nA. Steinmetz, C. Aydin, A. Lebedeva, M. Okun, M. Pachitariu, M. Bauza,\nM. Beau, J. Bhagat, C. Böhm, M. Broux, S. Chen, J. Colonell, R. J.\nGardner, B. Karsh, F. Kloosterman, D. Kostadinov, C. Mora-Lopez, J.\nO’Callaghan, J. Park, J. Putzeys, B. Sauerbrei, R. J. J. van Daal, A. Z.\nVollan, S. Wang, M. Welkenhuysen, Z. Ye, J. T. Dudman, B. Dutta, A. W.\nHantman, K. D. Harris, A. K. Lee, E. I. Moser, J. O’Keefe, A. Renart, K.\nSvoboda, M. Häusser, S. Haesler, M. Carandini, T. D. Harris, Neuropixels\n2.0: A miniaturized high-density probe for stable, long-term brain\nrecordings. Science. 372 (2021), doi:10.1126/science.abf4588.\n\n\n92. M.\nStimberg, R. Brette, D. F. M. Goodman, Brian 2, an intuitive and\nefficient neural simulator. eLife. 8 (2019),\ndoi:10.7554/eLife.47314.\n\n\n93. K.\nSvoboda, R. Yasuda, Principles of\nTwo-Photon Excitation Microscopy and Its Applications to\nNeuroscience. Neuron. 50, 823–839\n(2006).\n\n\n94. B.\nTelenczuk, M. Telenczuk, A. Destexhe, A kernel-based\nmethod to calculate local field potentials from networks of spiking\nneurons. Journal of Neuroscience Methods.\n344, 108871 (2020).\n\n\n95. C.\nThornton, F. Hutchings, M. Kaiser, The virtual electrode recording tool\nfor extracellular potentials (VERTEX) Version 2.0: Modelling in vitro\nelectrical stimulation of brain tissue. Wellcome Open Research.\n4 (2019), doi:10.12688/wellcomeopenres.15058.1.\n\n\n96. R.\nJ. Tomsett, M. Ainsworth, A. Thiele, M. Sanayei, X. Chen, M. A.\nGieselmann, M. A. Whittington, M. O. Cunningham, M. Kaiser, Virtual Electrode\nRecording Tool for EXtracellular potentials (VERTEX): comparing\nmulti-electrode recordings from simulated and biological mammalian\ncortical tissue. Brain Structure and Function.\n220, 2333–2353 (2015).\n\n\n97. A.\nR. Vaidya, M. S. Pujara, M. Petrides, E. A. Murray, L. K. Fellows, Lesion Studies in\nContemporary Neuroscience. Trends in Cognitive Sciences.\n23, 653–671 (2019).\n\n\n98. J.\nVierock, S. Rodriguez-Rozada, A. Dieter, F. Pieper, R. Sims, F.\nTenedini, A. C. F. Bergs, I. Bendifallah, F. Zhou, N. Zeitzschel, J.\nAhlbeck, S. Augustin, K. Sauter, E. Papagiakoumou, A. Gottschalk, P.\nSoba, V. Emiliani, A. K. Engel, P. Hegemann, J. S. Wiegert, BiPOLES is an\noptogenetic tool developed for bidirectional dual-color control of\nneurons. Nature Communications. 12, 1–20\n(2021).\n\n\n99. S.\nVyas, M. D. Golub, D. Sussillo, K. V. Shenoy, Computation\nthrough Neural Population Dynamics. Annual Review of\nNeuroscience. 43, 249–275 (2020).\n\n\n100. Y.\nWang, S. Boyd, Fast\nModel Predictive Control Using Online Optimization. IEEE\nTRANSACTIONS ON CONTROL SYSTEMS TECHNOLOGY. 18,\n267 (2010).\n\n\n101. G.\nWang, D. R. Wyskiel, W. Yang, Y. Wang, L. C. Milbern, T. Lalanne, X.\nJiang, Y. Shen, Q. Q. Sun, J. J. Zhu, An optogenetics- and\nimaging-assisted simultaneous multiple patch-clamp recording system for\ndecoding complex neural circuits. Nature Protocols.\n10, 397–412 (2015).\n\n\n102. J.\nS. Wiegert, M. Mahn, M. Prigge, Y. Printz, O. Yizhar, Silencing Neurons:\nTools, Applications, and Experimental Constraints. Neuron.\n95, 504–529 (2017).\n\n\n103. K.\nA. Wilmes, C. Clopath, Inhibitory\nmicrocircuits for top-down plasticity of sensory representations.\nNat Commun. 10, 5055 (2019).\n\n\n104. A.\nWitt, A. Palmigiano, A. Neef, A. El Hady, F. Wolf, D. Battaglia, Controlling the\noscillation phase through precisely timed closed-loop optogenetic\nstimulation: a computational study. Frontiers in Neural\nCircuits. 7, 1–17 (2013).\n\n\n105. J.\nWu, Y. Liang, S. Chen, C. L. Hsu, M. Chavarha, S. W. Evans, D. Shi, M.\nZ. Lin, K. K. Tsia, N. Ji, Kilohertz two-photon\nfluorescence microscopy imaging of neural activity in vivo.\nNature Methods. 17, 287–290 (2020).\n\n\n106. Y.\nYang, S. Qiao, O. G. Sani, J. I. Sedillo, B. Ferrentino, B. Pesaran, M.\nM. Shanechi, Modelling and\nprediction of the dynamic responses of large-scale brain networks during\ndirect electrical stimulation. Nature Biomedical\nEngineering. 5, 324–345 (2021).\n\n\n107. Z.\nZhang, L. E. Russell, A. M. Packer, O. M. Gauld, M. Häusser, Closed-loop all-optical\ninterrogation of neural circuits in vivo. Nature Methods.\n15, 1037–1040 (2018).\n\n\n108. L.\nZhang, J. Lee, C. Rozell, A. C. Singer, Sub-second dynamics of\ntheta-gamma coupling in hippocampal CA1. eLife.\n8 (2019), doi:10.7554/eLife.44320."
  }
]