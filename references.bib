@misc{acharya22,
  title = {Brain {{Modeling}} for {{Control}}: {{A Review}}},
  shorttitle = {Brain {{Modeling}} for {{Control}}},
  author = {Acharya, Gagan and Ruf, Sebastian F. and Nozari, Erfan},
  year = {2022},
  month = oct,
  number = {arXiv:2210.15957},
  eprint = {2210.15957},
  eprinttype = {arxiv},
  primaryclass = {cs, eess, q-bio},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2210.15957},
  abstract = {Neurostimulation technologies have seen a recent surge in interest from the neuroscience and controls communities alike due to their proven potential to treat conditions such as Parkinson's Disease, and depression. The provided stimulation can be of different types, such as electric, and optogenetic, and is generally applied to a specific region of the brain in order to drive the local and/or global dynamics to a desired state of (in)activity. However, an underlying theoretical understanding of the efficacy of neurostimulation is still lacking. From a control-theoretic perspective, it is important to understand how each stimulus modality interacts with the complex brain network in order to assess the controllability of the system and develop neurophysiologically relevant computational models that can be used to design the stimulation profile in a closed-loop manner. In this paper, we review the computational modeling studies of (i) deep brain stimulation, (ii) transcranial magnetic stimulation, (iii) direct current stimulation, (iv) transcranial electrical stimulation, and (v) optogenetics as five of the most popular neurostimulation technologies in research and clinical settings. For each technology, we split the reviewed studies into (a)theory-driven biophysical models capturing the low-level physics of the interactions between the stimulation source and neuronal tissue, (b) data-driven stimulus-response models which capture the end-to-end effects of stimulation on various biomarkers of interest and (c) data-driven dynamical system models that extract the precise dynamics of the brain's response to neurostimulation from neural data. While our focus is particularly on the latter category due to their greater utility in control design, we review key works in the former two categories as the basis and context in which dynamical system models have been and will be developed.},
  archiveprefix = {arXiv},
  keywords = {Electrical Engineering and Systems Science - Systems and Control,Quantitative Biology - Neurons and Cognition},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Acharya et al_2022_Brain Modeling for Control.pdf}
}

@article{adamantidis15,
  title = {Optogenetics: 10 Years after {{ChR2}} in Neurons\textemdash Views from the Community},
  shorttitle = {Optogenetics},
  author = {Adamantidis, Antoine and Arber, Silvia and Bains, Jaideep S. and Bamberg, Ernst and Bonci, Antonello and Buzs{\'a}ki, Gy{\"o}rgy and Cardin, Jessica A. and Costa, Rui M. and Dan, Yang and Goda, Yukiko and Graybiel, Ann M. and H{\"a}usser, Michael and Hegemann, Peter and Huguenard, John R. and Insel, Thomas R. and Janak, Patricia H. and Johnston, Daniel and Josselyn, Sheena A. and Koch, Christof and Kreitzer, Anatol C. and L{\"u}scher, Christian and Malenka, Robert C. and Miesenb{\"o}ck, Gero and Nagel, Georg and Roska, Botond and Schnitzer, Mark J. and Shenoy, Krishna V. and Soltesz, Ivan and Sternson, Scott M. and Tsien, Richard W. and Tsien, Roger Y. and Turrigiano, Gina G. and Tye, Kay M. and Wilson, Rachel I.},
  year = {2015},
  month = sep,
  journal = {Nature Neuroscience},
  volume = {18},
  number = {9},
  pages = {1202--1212},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/nn.4106},
  abstract = {On the anniversary of the Boyden et al. (2005) paper that introduced the use of channelrhodopsin in neurons, Nature Neuroscience asks selected members of the community to comment on the utility, impact and future of this important technique.},
  copyright = {2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  langid = {english},
  keywords = {Membrane proteins,Molecular neuroscience,Optogenetics},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Adamantidis et al_2015_Optogenetics.pdf}
}

@article{adesnik21,
  title = {Probing Neural Codes with Two-Photon Holographic Optogenetics},
  author = {Adesnik, Hillel and Abdeladim, Lamiae},
  year = {2021},
  month = oct,
  journal = {Nature Neuroscience},
  volume = {24},
  number = {10},
  pages = {1356--1366},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-021-00902-9},
  abstract = {Optogenetics ushered in a revolution in how neuroscientists interrogate brain function. Because of technical limitations, the majority of optogenetic studies have used low spatial resolution activation schemes that limit the types of perturbations that can be made. However, neural activity manipulations at finer spatial scales are likely to be important to more fully understand neural computation. Spatially precise multiphoton holographic optogenetics promises to address this challenge and opens up many new classes of experiments that were not previously possible. More specifically, by offering the ability to recreate extremely specific neural activity patterns in both space and time in functionally defined ensembles of neurons, multiphoton holographic optogenetics could allow neuroscientists to reveal fundamental aspects of the neural codes for sensation, cognition and behavior that have been beyond reach. This Review summarizes recent advances in multiphoton holographic optogenetics that substantially expand its capabilities, highlights outstanding technical challenges and provides an overview of the classes of experiments it can execute to test and validate key theoretical models of brain function. Multiphoton holographic optogenetics could substantially accelerate the pace of neuroscience discovery by helping to close the loop between experimental and theoretical neuroscience, leading to fundamental new insights into nervous system function and disorder.},
  copyright = {2021 Springer Nature America, Inc.},
  langid = {english},
  keywords = {Multiphoton microscopy,Neural circuits,Optogenetics},
  file = {C\:\\Users\\johns\\Zotero\\storage\\9PGU9QR3\\Adesnik_Abdeladim_2021_Probing neural codes with two-photon holographic optogenetics.pdf}
}

@article{akam14,
  title = {Oscillatory Multiplexing of Population Codes for Selective Communication in the Mammalian Brain},
  author = {Akam, Thomas and Kullmann, Dimitri M.},
  year = {2014},
  month = feb,
  journal = {Nature Reviews Neuroscience},
  volume = {15},
  number = {2},
  pages = {111--122},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/nrn3668},
  abstract = {The function of brain oscillations remains unclear, although a role in controlling the flow of signals among anatomically connected networks has been proposed. In this Opinion article, Akam and Kullmann discuss how network oscillations might convey multiplexed information that enables a flexible reconfiguration of effective connectivity among brain areas.},
  copyright = {2014 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  langid = {english},
  keywords = {Computational neuroscience,Hippocampus,Visual system},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Akam_Kullmann_2014_Oscillatory multiplexing of population codes for selective communication in the.pdf}
}

@inproceedings{akar19,
  title = {Arbor - {{A Morphologically-Detailed Neural Network Simulation Library}} for {{Contemporary High-Performance Computing Architectures}}},
  booktitle = {Proceedings - 27th {{Euromicro International Conference}} on {{Parallel}}, {{Distributed}} and {{Network-Based Processing}}, {{PDP}} 2019},
  author = {Akar, Nora Abi and Cumming, Ben and Karakasis, Vasileios and K{\"u}sters, Anne and Klijn, Wouter and Peyser, Alexander and Yates, Stuart},
  year = {2019},
  month = mar,
  eprint = {1901.07454},
  eprinttype = {arxiv},
  pages = {274--282},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  doi = {10.1109/EMPDP.2019.8671560},
  abstract = {We introduce Arbor, a performance portable library for simulation of large networks of multi-compartment neurons on HPC systems. Arbor is open source software, developed under the auspices of the HBP. The performance portability is by virtue of back-end specific optimizations for x86 multicore, Intel KNL, and NVIDIA GPUs. When coupled with low memory overheads, these optimizations make Arbor an order of magnitude faster than the most widely-used comparable simulation software. The single-node performance can be scaled out to run very large models at extreme scale with efficient weak scaling.},
  archiveprefix = {arXiv},
  isbn = {978-1-72811-644-0},
  keywords = {GPU,HPC,neuron,neuroscience,software}
}

@article{alegria20,
  title = {Single Neuron Recording: Progress towards High-Throughput Analysis},
  shorttitle = {Single Neuron Recording},
  author = {Alegria, Andrew and Joshi, Amey and O'Brien, Jacob and Kodandaramaiah, Suhasa B},
  year = {2020},
  journal = {Bioelectronics in Medicine},
  volume = {3},
  number = {3},
  pages = {33--36},
  issn = {2059-1500},
  doi = {10.2217/bem-2020-0011},
  pmcid = {PMC7604670},
  pmid = {33169092},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Alegria et al_Single neuron recording.pdf}
}

@incollection{alessio09,
  title = {A {{Survey}} on {{Explicit Model Predictive Control}}},
  booktitle = {Nonlinear {{Model Predictive Control}}: {{Towards New Challenging Applications}}},
  author = {Alessio, Alessandro and Bemporad, Alberto},
  editor = {Magni, Lalo and Raimondo, Davide Martino and Allg{\"o}wer, Frank},
  year = {2009},
  series = {Lecture {{Notes}} in {{Control}} and {{Information Sciences}}},
  pages = {345--369},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-01094-1_29},
  abstract = {Explicit model predictive control (MPC) addresses the problem of removing one of the main drawbacks of MPC, namely the need to solve a mathematical program on line to compute the control action. This computation prevents the application of MPC in several contexts, either because the computer technology needed to solve the optimization problem within the sampling time is too expensive or simply infeasible, or because the computer code implementing the numerical solver causes software certification concerns,especially in safety critical applications.},
  isbn = {978-3-642-01094-1},
  langid = {english},
  keywords = {explicit solutions,hybrid systems,min-max control,Model predictive control,multiparametric programming,piecewise affine controllers},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Alessio_Bemporad_2009_A Survey on Explicit Model Predictive Control.pdf}
}

@article{andalman19,
  title = {Neuronal {{Dynamics Regulating Brain}} and {{Behavioral State Transitions}}},
  author = {Andalman, Aaron S. and Burns, Vanessa M. and {Lovett-Barron}, Matthew and Broxton, Michael and Poole, Ben and Yang, Samuel J. and Grosenick, Logan and Lerner, Talia N. and Chen, Ritchie and Benster, Tyler and Mourrain, Philippe and Levoy, Marc and Rajan, Kanaka and Deisseroth, Karl},
  year = {2019},
  month = may,
  journal = {Cell},
  volume = {177},
  number = {4},
  pages = {970-985.e20},
  publisher = {{Cell Press}},
  issn = {10974172},
  doi = {10.1016/j.cell.2019.02.037},
  abstract = {Prolonged behavioral challenges can cause animals to switch from active to passive coping strategies to manage effort-expenditure during stress; such normally adaptive behavioral state transitions can become maladaptive in psychiatric disorders such as depression. The underlying neuronal dynamics and brainwide interactions important for passive coping have remained unclear. Here, we develop a paradigm to study these behavioral state transitions at cellular-resolution across the entire vertebrate brain. Using brainwide imaging in zebrafish, we observed that the transition to passive coping is manifested by progressive activation of neurons in the ventral (lateral) habenula. Activation of these ventral-habenula neurons suppressed downstream neurons in the serotonergic raphe nucleus and caused behavioral passivity, whereas inhibition of these neurons prevented passivity. Data-driven recurrent neural network modeling pointed to altered intra-habenula interactions as a contributory mechanism. These results demonstrate ongoing encoding of experience features in the habenula, which guides recruitment of downstream networks and imposes a passive coping behavioral strategy. Brainwide imaging in zebrafish and network modeling reveal that switching from active to passive coping state arises from progressive activation of habenular neurons in response to behavioral challenge.}
}

@article{antolik13,
  title = {Integrated Workflows for Spiking Neuronal Network Simulations},
  author = {Antol{\'i}k, J{\'a}n and Davison, Andrew P.},
  year = {2013},
  month = dec,
  journal = {Frontiers in Neuroinformatics},
  volume = {7},
  pages = {34},
  publisher = {{Frontiers Media S.A.}},
  issn = {16625196},
  doi = {10.3389/fninf.2013.00034},
  abstract = {The increasing availability of computational resources is enabling more detailed, realistic modeling in computational neuroscience, resulting in a shift toward more heterogeneous models of neuronal circuits, and employment of complex experimental protocols. This poses a challenge for existing tool chains, as the set of tools involved in a typical modeler's workflow is expanding concomitantly, with growing complexity in the metadata flowing between them. For many parts of the workflow, a range of tools is available; however, numerous areas lack dedicated tools, while integration of existing tools is limited. This forces modelers to either handle the workflow manually, leading to errors, or to write substantial amounts of code to automate parts of the workflow, in both cases reducing their productivity. To address these issues, we have developed Mozaik: a workflow system for spiking neuronal network simulations written in Python. Mozaik integrates model, experiment and stimulation specification, simulation execution, data storage, data analysis and visualization into a single automated workflow, ensuring that all relevant metadata are available to all workflow components. It is based on several existing tools, including PyNN, Neo, and Matplotlib. It offers a declarative way to specify models and recording configurations using hierarchically organized configuration files. Mozaik automatically records all data together with all relevant metadata about the experimental context, allowing automation of the analysis and visualization stages. Mozaik has a modular architecture, and the existing modules are designed to be extensible with minimal programming effort. Mozaik increases the productivity of running virtual experiments on highly structured neuronal networks by automating the entire experimental cycle, while increasing the reliability of modeling studies by relieving the user from manual handling of the flow of metadata between the individual workflow stages.},
  keywords = {Computational neuroscience,Integration,Large-scale models,Python,Reproducibility,Workflow},
  file = {C\:\\Users\\johns\\Zotero\\storage\\8ZYBIKXK\\Antolík_Davison_2013_Integrated workflows for spiking neuronal network simulations.pdf}
}

@article{antolik21,
  title = {Assessment of Optogenetically-Driven Strategies for Prosthetic Restoration of Cortical Vision in Large-Scale Neural Simulation of {{V1}}},
  author = {Antolik, Jan and Sabatier, Quentin and Galle, Charlie and Fr{\'e}gnac, Yves and Benosman, Ryad},
  year = {2021},
  month = may,
  journal = {Scientific Reports},
  volume = {11},
  number = {1},
  pages = {1--18},
  publisher = {{Nature Publishing Group}},
  issn = {20452322},
  doi = {10.1038/s41598-021-88960-8},
  abstract = {The neural encoding of visual features in primary visual cortex (V1) is well understood, with strong correlates to low-level perception, making V1 a strong candidate for vision restoration through neuroprosthetics. However, the functional relevance of neural dynamics evoked through external stimulation directly imposed at the cortical level is poorly understood. Furthermore, protocols for designing cortical stimulation patterns that would induce a naturalistic perception of the encoded stimuli have not yet been established. Here, we demonstrate a proof of concept by solving these issues through a computational model, combining (1) a large-scale spiking neural network model of cat V1 and (2) a virtual prosthetic system transcoding the visual input into tailored light-stimulation patterns which drive in situ the optogenetically modified cortical tissue. Using such virtual experiments, we design a protocol for translating simple Fourier contrasted stimuli (gratings) into activation patterns of the optogenetic matrix stimulator. We then quantify the relationship between spatial configuration of the imposed light pattern and the induced cortical activity. Our simulations in the absence of visual drive (simulated blindness) show that optogenetic stimulation with a spatial resolution as low as 100 {$\mu$} m, and light intensity as weak as 10 16 photons/s/cm2 is sufficient to evoke activity patterns in V1 close to those evoked by normal vision.},
  isbn = {0123456789},
  pmid = {34031442},
  keywords = {Computer science,Network models},
  file = {C\:\\Users\\johns\\Zotero\\storage\\NDDAFJQ6\\Antolik et al_2021_Assessment of optogenetically-driven strategies for prosthetic restoration of.pdf}
}

@article{anumanchipalli19,
  title = {Speech Synthesis from Neural Decoding of Spoken Sentences},
  author = {Anumanchipalli, Gopala K. and Chartier, Josh and Chang, Edward F.},
  year = {2019},
  month = apr,
  journal = {Nature},
  volume = {568},
  number = {7753},
  pages = {493--498},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-019-1119-1},
  abstract = {Technology that translates neural activity into speech would be transformative for people who are unable to communicate as a result of neurological impairments. Decoding speech from neural activity is challenging because speaking requires very precise and rapid multi-dimensional control of vocal tract articulators. Here we designed a neural decoder that explicitly leverages kinematic and sound representations encoded in human cortical activity to synthesize audible speech. Recurrent neural networks first decoded directly recorded cortical activity into representations of articulatory movement, and then transformed these representations into speech acoustics. In closed vocabulary tests, listeners could readily identify and transcribe speech synthesized from cortical activity. Intermediate articulatory dynamics enhanced performance even with limited data. Decoded articulatory representations were highly conserved across speakers, enabling a component of the decoder to be transferrable across participants. Furthermore, the decoder could synthesize speech when a participant silently mimed sentences. These findings advance the clinical viability of using speech neuroprosthetic technology to restore spoken communication.},
  copyright = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english},
  keywords = {Brain–machine interface,Sensorimotor processing},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Anumanchipalli et al_2019_Speech synthesis from neural decoding of spoken sentences.pdf}
}

@misc{appukuttan22,
  title = {A {{Software Framework}} for {{Validating Neuroscience Models}}},
  author = {Appukuttan, Shailesh and Sharma, Lungsi and {Garcia-Rodriguez}, Pedro and Davison, Andrew},
  year = {2022},
  publisher = {{HAL}},
  file = {C\:\\Users\\johns\\Zotero\\storage\\L93F5HQP\\Appukuttan et al_2022_A Software Framework for Validating Neuroscience Models A Software Frame-work.pdf}
}

@article{arenkiel07,
  title = {In {{Vivo Light-Induced Activation}} of {{Neural Circuitry}} in {{Transgenic Mice Expressing Channelrhodopsin-2}}},
  author = {Arenkiel, Benjamin R. and Peca, Joao and Davison, Ian G. and Feliciano, Catia and Deisseroth, Karl and Augustine, George J J. and Ehlers, Michael D. and Feng, Guoping},
  year = {2007},
  month = apr,
  journal = {Neuron},
  volume = {54},
  number = {2},
  pages = {205--218},
  publisher = {{Cell Press}},
  issn = {08966273},
  doi = {10.1016/j.neuron.2007.03.005},
  abstract = {Channelrhodopsin-2 (ChR2) is a light-gated, cation-selective ion channel isolated from the green algae Chlamydomonas reinhardtii. Here, we report the generation of transgenic mice that express a ChR2-YFP fusion protein in the CNS for in vivo activation and mapping of neural circuits. Using focal illumination of the cerebral cortex and olfactory bulb, we demonstrate a highly reproducible, light-dependent activation of neurons and precise control of firing frequency in vivo. To test the feasibility of mapping neural circuits, we exploited the circuitry formed between the olfactory bulb and the piriform cortex in anesthetized mice. In the olfactory bulb, individual mitral cells fired action potentials in response to light, and their firing rate was not influenced by costimulated glomeruli. However, in piriform cortex, the activity of target neurons increased as larger areas of the bulb were illuminated to recruit additional glomeruli. These results support a model of olfactory processing that is dependent upon mitral cell convergence and integration onto cortical cells. More broadly, these findings demonstrate a system for precise manipulation of neural activity in the intact mammalian brain with light and illustrate the use of ChR2 mice in exploring functional connectivity of complex neural circuits in vivo. \textcopyright{} 2007 Elsevier Inc. All rights reserved.},
  pmid = {17442243},
  keywords = {MOLNEURO,SYSNEURO},
  file = {C\:\\Users\\johns\\Zotero\\storage\\QHP9XKC4\\Arenkiel et al_2007_In Vivo Light-Induced Activation of Neural Circuitry in Transgenic Mice.pdf}
}

@article{aru15,
  title = {Untangling Cross-Frequency Coupling in Neuroscience},
  author = {Aru, Juhan and Aru, Jaan and Priesemann, Viola and Wibral, Michael and Lana, Luiz and Pipa, Gordon and Singer, Wolf and Vicente, Raul},
  year = {2015},
  month = apr,
  journal = {Current Opinion in Neurobiology},
  volume = {31},
  pages = {51--61},
  publisher = {{Elsevier Current Trends}},
  issn = {18736882},
  doi = {10.1016/j.conb.2014.08.002},
  abstract = {Cross-frequency coupling (CFC) has been proposed to coordinate neural dynamics across spatial and temporal scales. Despite its potential relevance for understanding healthy and pathological brain function, the standard CFC analysis and physiological interpretation come with fundamental problems. For example, apparent CFC can appear because of spectral correlations due to common non-stationarities that may arise in the total absence of interactions between neural frequency components. To provide a road map towards an improved mechanistic understanding of CFC, we organize the available and potential novel statistical/modeling approaches according to their biophysical interpretability. While we do not provide solutions for all the problems described, we provide a list of practical recommendations to avoid common errors and to enhance the interpretability of CFC analysis.},
  pmid = {25212583}
}

@article{atallah09,
  title = {Instantaneous {{Modulation}} of {{Gamma Oscillation Frequency}} by {{Balancing Excitation}} with {{Inhibition}}},
  author = {Atallah, Bassam V. and Scanziani, Massimo},
  year = {2009},
  month = may,
  journal = {Neuron},
  volume = {62},
  number = {4},
  pages = {566--577},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2009.04.027},
  abstract = {Neurons recruited for local computations exhibit rhythmic activity at gamma frequencies. The amplitude and frequency of these oscillations are continuously modulated depending on stimulus and behavioral state. This modulation is believed to crucially control information flow across cortical areas. Here we report that in the rat hippocampus gamma oscillation amplitude and frequency vary rapidly, from one cycle to the next. Strikingly, the amplitude of one oscillation predicts the interval to the next. Using in~vivo and in~vitro whole-cell recordings, we identify the underlying mechanism. We show that cycle-by-cycle fluctuations in amplitude reflect changes in synaptic excitation spanning over an order of magnitude. Despite these rapid variations, synaptic excitation is immediately and proportionally counterbalanced by inhibition. These rapid adjustments in inhibition instantaneously modulate oscillation frequency. So, by rapidly balancing excitation with inhibition, the hippocampal network is able to swiftly modulate gamma oscillations over a wide band of frequencies.},
  langid = {english},
  keywords = {SIGNALING,SYSBIO,SYSNEURO},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Atallah_Scanziani_2009_Instantaneous Modulation of Gamma Oscillation Frequency by Balancing Excitation.pdf}
}

@article{aussel18,
  title = {A Detailed Anatomical and Mathematical Model of the Hippocampal Formation for the Generation of Sharp-Wave Ripples and Theta-Nested Gamma Oscillations},
  author = {Aussel, Am{\'e}lie and Buhry, Laure and Tyvaert, Louise and Ranta, Radu},
  year = {2018},
  month = dec,
  journal = {Journal of Computational Neuroscience},
  volume = {45},
  number = {3},
  pages = {207--221},
  issn = {1573-6873},
  doi = {10.1007/s10827-018-0704-x},
  abstract = {The mechanisms underlying the broad variety of oscillatory rhythms measured in the hippocampus during the sleep-wake cycle are not yet fully understood. In this article, we propose a computational model of the hippocampal formation based on a realistic topology and synaptic connectivity, and we analyze the effect of different changes on the network, namely the variation of synaptic conductances, the variations of the CAN channel conductance and the variation of inputs. By using a detailed simulation of intracerebral recordings, we show that this is able to reproduce both the theta-nested gamma oscillations that are seen in awake brains and the sharp-wave ripple complexes measured during slow-wave sleep. The results of our simulations support the idea that the functional connectivity of the hippocampus, modulated by the sleep-wake variations in Acetylcholine concentration, is a key factor in controlling its rhythms.},
  langid = {english},
  keywords = {Acetylcholine,Conductance-based neurons,Hippocampal oscillations,Sharp-wave ripples,Sleep-wake cycle,Theta-nested gamma oscillations},
  file = {C\:\\Users\\johns\\Zotero\\storage\\AGLYJ7G5\\Aussel et al_2018_A detailed anatomical and mathematical model of the hippocampal formation for.pdf}
}

@article{aussel22,
  title = {Cell to Network Computational Model of the Epileptic Human Hippocampus Suggests Specific Roles of Network and Channel Dysfunctions in the Ictal and Interictal Oscillations},
  author = {Aussel, Am{\'e}lie and Ranta, Radu and Aron, Olivier and {Colnat-Coulbois}, Sophie and Maillard, Louise and Buhry, Laure},
  year = {2022},
  month = aug,
  journal = {Journal of Computational Neuroscience},
  issn = {1573-6873},
  doi = {10.1007/s10827-022-00829-5},
  abstract = {The mechanisms underlying the generation of hippocampal epileptic seizures and interictal events and their interactions with the sleep-wake cycle are not yet fully understood. Indeed, medial temporal lobe epilepsy is associated with hippocampal abnormalities both at the neuronal (channelopathies, impaired potassium and chloride dynamics) and network level (neuronal and axonal loss, mossy fiber sprouting), with more frequent seizures during wakefulness compared with slow-wave sleep. In this article, starting from our previous computational modeling work of the hippocampal formation based on realistic topology and synaptic connectivity, we study the role of micro- and mesoscale pathological conditions of the epileptic hippocampus in the generation and maintenance of seizure-like theta and interictal oscillations. We show, through the simulations of hippocampal activity during slow-wave sleep and wakefulness that: (i) both mossy fiber sprouting and sclerosis account for seizure-like theta activity, (ii) but they have antagonist effects (seizure-like activity occurrence increases with sprouting but decreases with sclerosis), (iii) though impaired potassium and chloride dynamics have little influence on the generation of seizure-like activity, they do play a role on the generation of interictal patterns, and (iv) seizure-like activity and fast ripples are more likely to occur during wakefulness and interictal spikes during sleep.},
  langid = {english},
  keywords = {Computational modeling,Epilepsy,Hippocampus,Pathological connectivity,Realistic anatomy,Sleep-wake cycle},
  file = {C\:\\Users\\johns\\Zotero\\storage\\ZMZD7NIX\\Aussel et al_2022_Cell to network computational model of the epileptic human hippocampus suggests.pdf}
}

@article{avitan22,
  title = {Not so Spontaneous: {{Multi-dimensional}} Representations of Behaviors and Context in Sensory Areas},
  shorttitle = {Not so Spontaneous},
  author = {Avitan, Lilach and Stringer, Carsen},
  year = {2022},
  month = jul,
  journal = {Neuron},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2022.06.019},
  abstract = {Sensory areas are spontaneously active in the absence of sensory stimuli. This spontaneous activity has long been studied; however, its functional role remains largely unknown. Recent advances in technology, allowing large-scale neural recordings in the awake and behaving animal, have transformed our understanding of spontaneous activity. Studies using these recordings have discovered high-dimensional spontaneous activity patterns, correlation between spontaneous activity and behavior, and dissimilarity between spontaneous and sensory-driven activity patterns. These findings are supported by evidence from developing animals, where a transition toward these characteristics is observed as the circuit matures, as well as by evidence from mature animals across species. These newly revealed characteristics call for the formulation of a new role for spontaneous activity in neural sensory computation.},
  langid = {english},
  keywords = {behavior,dimensionality,evoked neural activity,multi-dimensional neural activity,neural coding,neural subspace,orthogonal neural subspaces,spontaneous activity},
  file = {C\:\\Users\\johns\\Zotero\\storage\\HLN2I3UD\\Avitan_Stringer_2022_Not so spontaneous.pdf}
}

@article{bansal20,
  title = {Theoretical {{Analysis}} of {{Low-power Bidirectional Optogenetic Control}} of {{High-frequency Neural Codes}} with {{Single Spike Resolution}}},
  author = {Bansal, Himanshu and Gupta, Neha and Roy, Sukhdev},
  year = {2020},
  month = nov,
  journal = {Neuroscience},
  volume = {449},
  pages = {165--188},
  publisher = {{Pergamon}},
  issn = {18737544},
  doi = {10.1016/j.neuroscience.2020.09.022},
  abstract = {Low-power and high-frequency bidirectional control of spatiotemporal patterns of neural spiking is one of the major challenges in optogenetics. A detailed theoretical analysis and optimization with ChR2-NpHR, ChR2(H134R)-eNpHR3.0, Chrimson-GtACR2 and also with prospective opsin pairs namely, Chronos-Jaws, Chronos-eNpHR3.0, CheRiff-Jaws and vf-Chrimson-GtACR2 has been presented. Biophysical circuit models of bidirectional optogenetic control in above opsin pairs expressing hippocampal neurons and fast-spiking neocortical interneurons have been formulated. The models include the important rebound effect of chloride ions and overlapping of absorption spectra. Blue light absorption by red-shifted opsins not only affects the photocurrent, but also its turn-off kinetics. Under continuous illumination, bidirectional control of spiking around 40 Hz in hippocampal neurons requires very low blue and orange light intensities of 0.014 mW/mm2 and 0.8 mW/mm2 with CheRiff-Jaws and 0.04 mW/mm2, and 0.02 mW/mm2 with Chrimson-GtACR2, respectively. Under optimal photostimulation and expression density, high-frequency limit of bidirectional control is 60 Hz and 100 Hz with ChR2-NpHR, 60 Hz and 20 Hz with ChR2(H134R)-eNpHR3.0, 90 Hz and 180 Hz with Chronos-Jaws, and 90 Hz and 250 Hz with Chronos-eNpHR3.0 in neurons and interneurons, respectively. Although, Chrimson-GtACR2 enables bidirectional control at very low-power, vf-Chrimson-GtACR2 provides control with reduced cross-talk. The theoretical analysis highlights the usefulness of computational methods to virtually optimize stimulation protocols for optogenetic tool combinations. The study is useful to generate neural codes with desired spatiotemporal resolution and to design optogenetic neuroprosthetic devices and circuits.},
  pmid = {32941934},
  keywords = {bidirectional optogenetic control,CheRiff,Chronos,computational optogenetics,Jaws,vf-Chrimson-GtACR2},
  file = {C\:\\Users\\johns\\Zotero\\storage\\V6TVI63W\\full-text.pdf}
}

@article{bansal20b,
  title = {Comparison of Low-Power, High-Frequency and Temporally Precise Optogenetic Inhibition of Spiking in {{NpHR}}, {{eNpHR3}}.0 and {{Jaws-expressing}} Neurons},
  author = {Bansal, Himanshu and Gupta, Neha and Roy, Sukhdev},
  year = {2020},
  month = may,
  journal = {Biomedical Physics and Engineering Express},
  volume = {6},
  number = {4},
  pages = {045011},
  publisher = {{IOP Publishing}},
  issn = {20571976},
  doi = {10.1088/2057-1976/ab90a1},
  abstract = {A detailed theoretical analysis of low-power, high-frequency and temporally precise optogenetic inhibition of neuronal spiking, with red-shifted opsins namely, NpHR, eNpHR3.0 and Jaws, has been presented. An accurate model for inhibition of spiking in these opsins expressed hippocampal neurons that includes the important rebound activity of chloride ions across the membrane has been formulated. The effect of various parameters including irradiance, pulse width, frequency, opsin-expression density and chloride concentration has been studied in detail. Theoretical simulations are in very good agreement with reported experimental results. The chloride concentration gradient directly affects the photocurrent and inhibition capacity in all three variants. eNpHR3.0 shows smallest inhibitory post-synaptic potential plateau at higher frequencies. The time delay between light stimulus and target spike is crucial to minimize irradiance and expression density thresholds for suppressing individual spike. Good practical values of photostimulation parameters have been obtained empirically for peak photocurrent, time delay and 100\% spiking inhibition, at continuous and pulsed illumination. Under continuous illumination, complete inhibition of neural activity in Jaws-expressing neurons takes place at minimum irradiance of 0.2 mW mm-2 and expression density of 0.2 mS cm-2, whereas for pulsed stimulation, it is at minimum irradiance of 0.6 mW mm-2 and 5 ms pulse width, at 10 Hz. It is shown that Jaws and eNpHR3.0 are able to invoke single spike precise inhibition up to 160 and 200 Hz, respectively. The study is useful in designing new experiments, understanding temporal spike coding and bidirectional control, and curing neurological disorders.},
  pmid = {33444272},
  keywords = {Computational optogenetics,halorhodopsin,jaws,optogenetic inhibition,red-shifted opsins},
  file = {C\:\\Users\\johns\\Zotero\\storage\\VFJE44JE\\Bansal et al_2020_Comparison of low-power, high-frequency and temporally precise optogenetic.pdf}
}

@article{bansal21a,
  title = {Theoretical Analysis of Optogenetic Spiking with {{ChRmine}}, {{bReaChES}} and {{CsChrimson-expressing}} Neurons for Retinal Prostheses},
  author = {Bansal, Himanshu and Gupta, Neha and Roy, Sukhdev},
  year = {2021},
  month = jul,
  journal = {Journal of Neural Engineering},
  volume = {18},
  number = {4},
  pages = {0460b8},
  publisher = {{IOP Publishing}},
  issn = {17412552},
  doi = {10.1088/1741-2552/ac1175},
  abstract = {Objective. Optogenetics has emerged as a promising technique for neural prosthetics, especially retinal prostheses, with unprecedented spatiotemporal resolution. Newly discovered opsins with high light sensitivity and fast temporal kinetics can provide sufficient temporal resolution at safe light powers and overcome the limitations of presently used opsins. It is also important to formulate accurate mathematical models for optogenetic retinal prostheses, which can facilitate optimization of photostimulation factors to improve the performance. Approach. A detailed theoretical analysis of optogenetic excitation of model retinal ganglion neurons (RGNs) and hippocampal neurons expressed with already tested opsins for retinal prostheses, namely, ChR2, ReaChR and ChrimsonR, and also with recently discovered potent opsins CsChrimson, bReaChES and ChRmine, was carried out. Main results. Under continuous illumination, ChRmine-expressing RGNs begin to respond at very low irradiances {$\sim$}10-4 mW mm-2, and evoke firing upto {$\sim$}280 Hz, highest among other opsin-expressing RGNs, at 10-2 mW mm-2. Under pulsed illumination at randomized photon fluxes, ChRmine-expressing RGNs respond to changes in pulse to pulse irradiances upto four logs, although very bright pulses {$>$}1014 photons mm-2 s-1 block firing in these neurons. The minimum irradiance threshold for ChRmine-expressing RGNs is lower by two orders of magnitude, whereas, the first spike latency in ChRmine-expressing RGNs is shorter by an order of magnitude, alongwith stable latency of subsequest spikes compared to others. Further, a good set of photostimulation parameters were determined to achieve high-frequency control with single spike resolution at minimal power. Although ChrimsonR enables spiking upto 100 Hz in RGNs, it requires very high irradiances. ChRmine provides control at light powers that are two orders of magnitude smaller than that required with experimentally studied opsins, while maintaining single spike temporal resolution upto 40 Hz. Significance. The present study highlights the importance of ChRmine as a potential opsin for optogenetic retinal prostheses.},
  pmid = {34229315},
  keywords = {ChRmine,neurophotonics,optogenetics,retinal prosthetics}
}

@article{barack21,
  title = {Two Views on the Cognitive Brain},
  author = {Barack, David L. and Krakauer, John W.},
  year = {2021},
  month = jun,
  journal = {Nature Reviews Neuroscience},
  volume = {22},
  number = {6},
  pages = {359--371},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/s41583-021-00448-6},
  abstract = {Cognition can be defined as computation over meaningful representations in the brain to produce adaptive behaviour. There are two views on the relationship between cognition and the brain that are largely implicit in the literature. The Sherringtonian view seeks to explain cognition as the result of operations on signals performed at nodes in a network and passed between them that are implemented by specific neurons and their connections in circuits in the brain. The contrasting Hopfieldian view explains cognition as the result of transformations between or movement within representational spaces that are implemented by neural populations. Thus, the Hopfieldian view relegates details regarding the identity of and connections between specific neurons to the status of secondary explainers. Only the Hopfieldian approach has the representational and computational resources needed to develop novel neurofunctional objects that can serve as primary explainers of cognition.},
  copyright = {2021 Springer Nature Limited},
  langid = {english},
  keywords = {Intelligence,Philosophy},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Barack_Krakauer_2021_Two views on the cognitive brain.pdf}
}

@incollection{bedard12,
  title = {Local Field Potentials},
  booktitle = {Handbook of {{Neural Measurement}}},
  author = {B{\'e}dard, Claude and Destexhe, Alain},
  year = {2012},
  pages = {136--191},
  file = {C\:\\Users\\johns\\Zotero\\storage\\6EHRAT9M\\Bédard_Destexhe_2012_Local field potentials.pdf}
}

@article{bellec20,
  title = {A Solution to the Learning Dilemma for Recurrent Networks of Spiking Neurons},
  author = {Bellec, Guillaume and Scherr, Franz and Subramoney, Anand and Hajek, Elias and Salaj, Darjan and Legenstein, Robert and Maass, Wolfgang},
  year = {2020},
  journal = {Nature Communications},
  volume = {11},
  number = {3625},
  doi = {10.1101/738385},
  abstract = {Recurrently connected networks of spiking neurons underlie the astounding information processing capabilities of the brain. Yet in spite of extensive research, how they can learn through synaptic plasticity to carry out complex network computations remains unclear. We argue that two pieces of this puzzle were provided by experimental data from neuroscience. A mathematical result tells us how these pieces need to be combined to enable biologically plausible online network learning through gradient descent, in particular deep reinforcement learning. This learning method\textendash called e-prop\textendash approaches the performance of back propagation through time (BPTT), the best-known method for training recurrent neural networks in machine learning. In addition, it suggests a method for powerful on-chip learning in energy-efficient spike-based hardware for artificial intelligence.},
  file = {C\:\\Users\\johns\\Zotero\\storage\\B2DCBEHE\\s41467-020-17236-y.pdf;C\:\\Users\\johns\\Zotero\\storage\\NKXLTWIL\\Bellec et al_2020_A solution to the learning dilemma for recurrent networks of spiking neurons.pdf}
}

@techreport{bemporad,
  title = {Robust {{Model Predictive Control}}: {{A Survey}}},
  author = {Bemporad, Albert ( ) and Morari, Manfred},
  abstract = {This paper gives an overview of robustness in Model Predictive Control (MPC). After reviewing the basic concepts of MPC, we survey the uncertainty descriptions considered in the MPC literature, and the techniques proposed for robust constraint handling, stability, and performance. The key concept of "closed-loop prediction" is discussed at length. The paper concludes with some comments on future research directions.},
  file = {C\:\\Users\\johns\\Zotero\\storage\\ULKLBV9D\\Bemporad_Morari_Robust Model Predictive Control.pdf}
}

@article{bemporad02,
  title = {The Explicit Linear Quadratic Regulator for Constrained Systems},
  author = {Bemporad, Alberto and Morari, Manfred and Dua, Vivek and Pistikopoulos, Efstratios N.},
  year = {2002},
  month = jan,
  journal = {Automatica},
  volume = {38},
  number = {1},
  pages = {3--20},
  publisher = {{Pergamon}},
  issn = {00051098},
  doi = {10.1016/S0005-1098(01)00174-1},
  abstract = {For discrete-time linear time invariant systems with constraints on inputs and states, we develop an algorithm to determine explicitly, the state feedback control law which minimizes a quadratic performance criterion. We show that the control law is piece-wise linear and continuous for both the finite horizon problem (model predictive control) and the usual infinite time measure (constrained linear quadratic regulation). Thus, the on-line control computation reduces to the simple evaluation of an explicitly defined piecewise linear function. By computing the inherent underlying controller structure, we also solve the equivalent of the Hamilton-Jacobi-Bellman equation for discrete-time linear constrained systems. Control based on on-line optimization has long been recognized as a superior alternative for constrained systems. The technique proposed in this paper is attractive fora wide range of practical problems where the computational complexity of on-line optimization is prohibitive. It also provides an insight into the structure underlying optimization-based controllers. \textcopyright{} 2001 Elsevier Science Ltd. All rights reserved.},
  keywords = {Constraints,Linear quadratic regulators,Piecewise linear controllers,Predictive control},
  file = {C\:\\Users\\johns\\Zotero\\storage\\J8MFL84R\\Bemporad et al_2002_The explicit linear quadratic regulator for constrained systems.pdf}
}

@misc{bergs22,
  title = {All-Optical Closed-Loop Voltage Clamp for Precise Control of Muscles and Neurons in Live Animals},
  author = {Bergs, Amelie C. F. and Liewald, Jana F. and {Rodriguez-Rozada}, Silvia and Liu, Qiang and Wirt, Christin and Bessel, Artur and Zeitzschel, Nadja and Durmaz, Hilal and Nozownik, Adrianna and Vierock, Johannes and Bargmann, Cornelia I. and Hegemann, Peter and Wiegert, J. Simon and Gottschalk, Alexander},
  year = {2022},
  month = jun,
  pages = {2022.06.03.494532},
  publisher = {{bioRxiv}},
  doi = {10.1101/2022.06.03.494532},
  abstract = {Optogenetics are used stimulate or inhibit neurons. Because optogenetic stimulation is typically static, neurons and circuits can quickly adapt, allowing perturbation, but not true control. To overcome this, we established an optogenetic voltage-clamp (OVC). The genetically encoded voltage-indicator QuasAr2 provides for fast, closed-loop optical to the bidirectional optogenetic actuator BiPOLES. Voltage-dependent fluorescence is held within tight margins, clamping at a distinct potential. We established the OVC in muscles and neurons of Caenorhabditis elegans, and transferred it to hippocampal neurons in rat brain slices. We calibrated fluorescence signals to electrically measured membrane potentials, showed that the OVC reports on homeostatically altered cellular physiology in mutants affecting neurotransmission, and that it can dynamically clamp spiking. The OVC combines non-invasive imaging with the control capabilities of electrophysiology. Its applicability to individual cells facilitates high-throughput contact-less electrophysiology and paves the way for true optogenetic control in behaving . One-Sentence Summary Next generation optogenetic control of neuron function via optical for non-invasive substitution of electrophysiology.},
  chapter = {New Results},
  copyright = {\textcopyright{} 2022, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
  langid = {english},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Bergs et al_2022_All-optical closed-loop voltage clamp for precise control of muscles and.pdf}
}

@article{berman14,
  title = {Mapping the Stereotyped Behaviour of Freely Moving Fruit Flies},
  author = {Berman, Gordon J. and Choi, Daniel M. and Bialek, William and Shaevitz, Joshua W.},
  year = {2014},
  month = oct,
  journal = {Journal of The Royal Society Interface},
  volume = {11},
  number = {99},
  pages = {20140672},
  publisher = {{Royal Society}},
  doi = {10.1098/rsif.2014.0672},
  abstract = {A frequent assumption in behavioural science is that most of an animal's activities can be described in terms of a small set of stereotyped motifs. Here, we introduce a method for mapping an animal's actions, relying only upon the underlying structure of postural movement data to organize and classify behaviours. Applying this method to the ground-based behaviour of the fruit fly, Drosophila melanogaster, we find that flies perform stereotyped actions roughly 50\% of the time, discovering over 100 distinguishable, stereotyped behavioural states. These include multiple modes of locomotion and grooming. We use the resulting measurements as the basis for identifying subtle sex-specific behavioural differences and revealing the low-dimensional nature of animal motions.},
  keywords = {behaviour,Drosophila,phase reconstruction,stereotypy,unsupervised learning},
  file = {C\:\\Users\\johns\\Zotero\\storage\\IXRHQQV5\\Berman et al_2014_Mapping the stereotyped behaviour of freely moving fruit flies.pdf}
}

@article{berndt16,
  title = {Structural Foundations of Optogenetics: {{Determinants}} of Channelrhodopsin Ion Selectivity},
  author = {Berndt, Andre and Lee, Soo Yeun and Wietek, Jonas and Ramakrishnan, Charu and Steinberg, Elizabeth E. and Rashid, Asim J. and Kim, Hoseok and Park, Sungmo and Santoro, Adam and Frankland, Paul W. and Iyer, Shrivats M. and Pak, Sally and {\"A}hrlund-Richter, Sofie and Delp, Scott L. and Malenka, Robert C. and Josselyn, Sheena A. and Carl{\'e}n, Marie and Hegemann, Peter and Deisseroth, Karl},
  year = {2016},
  month = jan,
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  volume = {113},
  number = {4},
  pages = {822--829},
  publisher = {{National Academy of Sciences}},
  issn = {10916490},
  doi = {10.1073/pnas.1523341113},
  abstract = {The structure-guided design of chloride-conducting channelrhodopsins has illuminated mechanisms underlying ion selectivity of this remarkable family of light-activated ion channels. The first generation of chloride-conducting channelrhodopsins, guided in part by development of a structure-informed electrostatic model for pore selectivity, included both the introduction of amino acids with positively charged side chains into the ion conduction pathway and the removal of residues hypothesized to support negatively charged binding sites for cations. Engineered channels indeed became chloride selective, reversing near -65 mV and enabling a new kind of optogenetic inhibition; however, these first-generation chloride-conducting channels displayed small photocurrents and were not tested for optogenetic inhibition of behavior. Here we report the validation and further development of the channelrhodopsin pore model via crystal structure-guided engineering of next-generation light-activated chloride channels (iC++) and a bistable variant (SwiChR++) with net photocurrents increased more than 15-fold under physiological conditions, reversal potential further decreased by another \textasciitilde 15 mV, inhibition of spiking faithfully tracking chloride gradients and intrinsic cell properties, strong expression in vivo, and the initial microbial opsin channel-inhibitor-based control of freely moving behavior. We further show that inhibition by light-gated chloride channels is mediated mainly by shunting effects, which exert optogenetic control much more efficiently than the hyperpolarization induced by light-activated chloride pumps. The design and functional features of these next-generation chloride-conducting channelrhodopsins provide both chronic and acute timescale tools for reversible optogenetic inhibition, confirm fundamental predictions of the ion selectivity model, and further elucidate electrostatic and steric structure- function relationships of the light-gated pore.},
  pmid = {26699459},
  keywords = {Channelrhodopsin,Chloride,Neuronal inhibition,Optogenetics,Structure},
  file = {C\:\\Users\\johns\\Zotero\\storage\\PWAYF7TU\\Berndt et al_2016_Structural foundations of optogenetics.pdf}
}

@article{bettencourt08,
  title = {Effects of Imperfect Dynamic Clamp: {{Computational}} and Experimental Results},
  author = {Bettencourt, Jonathan C. and Lillis, Kyle P. and Stupin, Laura R. and White, John A.},
  year = {2008},
  month = apr,
  journal = {Journal of Neuroscience Methods},
  volume = {169},
  number = {2},
  pages = {282--289},
  publisher = {{Elsevier}},
  issn = {01650270},
  doi = {10.1016/j.jneumeth.2007.10.009},
  abstract = {In the dynamic clamp technique, a typically nonlinear feedback system delivers electrical current to an excitable cell that represents the actions of "virtual" ion channels (e.g., channels that are gated by local membrane potential or by electrical activity in neighboring biological or virtual neurons). Since the conception of this technique, there have been a number of different implementations of dynamic clamp systems, each with differing levels of flexibility and performance. Embedded hardware-based systems typically offer feedback that is very fast and precisely timed, but these systems are often expensive and sometimes inflexible. PC-based systems, on the other hand, allow the user to write software that defines an arbitrarily complex feedback system, but real-time performance in PC-based systems can be deteriorated by imperfect real-time performance. Here, we systematically evaluate the performance requirements for artificial dynamic clamp knock-in of transient sodium and delayed rectifier potassium conductances. Specifically, we examine the effects of controller time step duration, differential equation integration method, jitter (variability in time step), and latency (the time lag from reading inputs to updating outputs). Each of these control system flaws is artificially introduced in both simulated and real dynamic clamp experiments. We demonstrate that each of these errors affect dynamic clamp accuracy in a way that depends on the time constants and stiffness of the differential equations being solved. In simulations, time steps above 0.2 ms lead to catastrophic alteration of spike shape, but the frequency-current relationship is much more robust. Latency (the part of the time step that occurs between measuring membrane potential and injecting re-calculated membrane current) is a crucial factor as well. Experimental data are substantially more sensitive to inaccuracies than simulated data. \textcopyright{} 2007 Elsevier B.V. All rights reserved.},
  pmid = {18076999},
  keywords = {Computational neuroscience,Dynamic clamp}
}

@inproceedings{bogdanchikov13,
  title = {Python to Learn Programming},
  booktitle = {Journal of {{Physics}}: {{Conference Series}}},
  author = {Bogdanchikov, A. and Zhaparov, M. and Suliyev, R.},
  year = {2013},
  month = apr,
  volume = {423},
  pages = {012027},
  publisher = {{IOP Publishing}},
  issn = {17426596},
  doi = {10.1088/1742-6596/423/1/012027},
  abstract = {Today we have a lot of programming languages that can realize our needs, but the most important question is how to teach programming to beginner students. In this paper we suggest using Python for this purpose, because it is a programming language that has neatly organized syntax and powerful tools to solve any task. Moreover it is very close to simple math thinking. Python is chosen as a primary programming language for freshmen in most of leading universities. Writing code in python is easy. In this paper we give some examples of program codes written in Java, C++ and Python language, and we make a comparison between them. Firstly, this paper proposes advantages of Python language in relation to C++ and JAVA. Then it shows the results of a comparison of short program codes written in three different languages, followed by a discussion on how students understand programming. Finally experimental results of students' success in programming courses are shown. \textcopyright{} IOP Publishing Ltd 2013.},
  file = {C\:\\Users\\johns\\Zotero\\storage\\2DQ42M29\\Bogdanchikov et al_2013_Python to learn programming.pdf}
}

@article{bolus18,
  title = {Design Strategies for Dynamic Closed-Loop Optogenetic Neurocontrol in Vivo},
  author = {Bolus, M F and Willats, A A and Whitmire, C J and Rozell, C J and Stanley, G B},
  year = {2018},
  month = apr,
  journal = {Journal of Neural Engineering},
  volume = {15},
  number = {2},
  pages = {026011},
  issn = {1741-2560},
  doi = {10.1088/1741-2552/aaa506},
  file = {C\:\\Users\\johns\\Zotero\\storage\\BQZEQ5JA\\Bolus et al_2018_Design strategies for dynamic closed-loop optogenetic neurocontrol in vivo.pdf}
}

@article{bolus21,
  title = {State-Space Optimal Feedback Control of Optogenetically Driven Neural Activity},
  author = {Bolus, M F and Willats, A A and Rozell, C J and Stanley, G B},
  year = {2021},
  month = jun,
  journal = {Journal of neural engineering},
  volume = {18},
  number = {3},
  pages = {036006},
  publisher = {{Cold Spring Harbor Laboratory}},
  doi = {10.1101/2020.06.25.171785},
  abstract = {Objective. The rapid acceleration of tools for recording neuronal populations and targeted optogenetic manipulation has enabled real-time, feedback control of neuronal circuits in the brain. Continuously-graded control of measured neuronal activity poses a wide range of technical challenges, which we address through a combination of optogenetic stimulation and a state-space optimal control framework implemented in the thalamocortical circuit of the awake mouse. Approach. Closed-loop optogenetic control of neurons was performed in real-time via stimulation of channelrhodopsin-2 expressed in the somatosensory thalamus of the head-fixed mouse. A state-space linear dynamical system model structure was used to approximate the light-to-spiking input-output relationship in both single-neuron as well as multi-neuron scenarios when recording from multielectrode arrays. These models were utilized to design state feedback controller gains by way of linear quadratic optimal control and were also used online for estimation of state feedback, where a parameter-adaptive Kalman filter provided robustness to model-mismatch. Main results. This model-based control scheme proved effective for feedback control of single-neuron firing rate in the thalamus of awake animals. Notably, the graded optical actuation utilized here did not synchronize simultaneously recorded neurons, State-space optogenetic control 2 but heterogeneity across the neuronal population resulted in a varied response to stimulation. Simulated multi-output feedback control provided better control of a heterogeneous population and demonstrated how the approach generalizes beyond single-neuron applications. Significance. To our knowledge, this work represents the first experimental application of state space model-based feedback control for optogenetic stimulation. In combination with linear quadratic optimal control, the approaches laid out and tested here generalize to the multi-input/multi-output control problems necessitated by highly complex neural circuits. More generally, feedback control of neuronal circuits opens the door to adaptively interacting with the dynamics underlying sensory, motor, and cognitive signaling, enabling a deeper understanding of circuit function and ultimately the control of function in the face of injury or disease.},
  keywords = {closed-loop,control,estimation,firing rate,in vivo,optogenetics,state space,thalamus},
  file = {C\:\\Users\\johns\\Zotero\\storage\\5RHH3L7D\\Bolus et al_2021_State-space optimal feedback control of optogenetically driven neural activity.pdf}
}

@article{brunel03,
  title = {What Determines the Frequency of Fast Network Oscillations with Irregular Neural Discharges? {{I}}. {{Synaptic}} Dynamics and Excitation-Inhibition Balance},
  shorttitle = {What Determines the Frequency of Fast Network Oscillations with Irregular Neural Discharges?},
  author = {Brunel, Nicolas and Wang, Xiao-Jing},
  year = {2003},
  journal = {Journal of neurophysiology},
  volume = {90},
  number = {1},
  pages = {415--430},
  publisher = {{American Physiological Society}}
}

@article{buffalo11,
  title = {Laminar Differences in Gamma and Alpha Coherence in the Ventral Stream},
  author = {Buffalo, Elizabeth A. and Fries, Pascal and Landman, Rogier and Buschman, Timothy J. and Desimone, Robert},
  year = {2011},
  month = jul,
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  volume = {108},
  number = {27},
  pages = {11262--11267},
  issn = {00278424},
  doi = {10.1073/pnas.1011284108},
  abstract = {Attention to a stimulus enhances both neuronal responses and gamma frequency synchrony in visual area V4, both ofwhich should increase the impact of attended information on downstream neurons. To determine whether gamma synchrony is common throughout the ventral stream, we recorded from neurons in the superficial and deep layers of V1, V2, and V4 in two rhesusmonkeys.We found an unexpected striking difference in gamma synchrony in the superficial vs. deep layers. In all three areas, spike-field coherence in the gamma (40-60 Hz) frequency range was largely confined to the superficial layers,whereas the deep layers showedmaximal coherence at low frequencies (6-16 Hz), which included the alpha range. In the superficial layers of V2 and V4, gamma synchrony was enhanced by attention, whereas in the deep layers, alpha synchrony was reduced by attention. Unlike these major differences in synchrony, attentional effects on firing rates and noise correlation did not differ substantially between the superficial and deep layers. The results suggest that synchrony plays very different roles in feedback and feedforward projections.},
  pmid = {21690410},
  keywords = {Electrophysiology,Macaque,Oscillation},
  file = {C\:\\Users\\johns\\Zotero\\storage\\7EH9B6BL\\Buffalo et al_2011_Laminar differences in gamma and alpha coherence in the ventral stream.pdf}
}

@article{buschman12,
  title = {Synchronous {{Oscillatory Neural Ensembles}} for {{Rules}} in the {{Prefrontal Cortex}}},
  author = {Buschman, Timothy J. and Denovellis, Eric L. and Diogo, Cinira and Bullock, Daniel and Miller, Earl K.},
  year = {2012},
  month = nov,
  journal = {Neuron},
  volume = {76},
  number = {4},
  pages = {838--846},
  publisher = {{Cell Press}},
  issn = {08966273},
  doi = {10.1016/j.neuron.2012.09.029},
  abstract = {Intelligent behavior requires acquiring and following rules. Rules define how our behavior should fit different situations. To understand its neural mechanisms, we simultaneously recorded from multiple electrodes in dorsolateral prefrontal cortex (PFC) while monkeys switched between two rules (respond to color versus orientation). We found evidence that oscillatory synchronization of local field potentials (LFPs) formed neural ensembles representing the rules: there were rule-specific increases in synchrony at " beta" (19-40 Hz) frequencies between electrodes. In addition, individual PFC neurons synchronized to the LFP ensemble corresponding to the current rule (color versus orientation). Furthermore, the ensemble encoding the behaviorally dominant orientation rule showed increased " alpha" (6-16 Hz) synchrony when preparing to apply the alternative (weaker) color rule. This suggests that beta-frequency synchrony selects the relevant rule ensemble, while alpha-frequency synchrony deselects a stronger, but currently irrelevant, ensemble. Synchrony may act to dynamically shape task-relevant neural ensembles out of larger, overlapping circuits.},
  pmid = {23177967},
  file = {C\:\\Users\\johns\\Zotero\\storage\\S6DK7SYG\\Buschman et al_2012_Synchronous Oscillatory Neural Ensembles for Rules in the Prefrontal Cortex.pdf}
}

@article{buzsaki04,
  title = {Neuronal Oscillations in Cortical Networks},
  author = {Buzs{\'a}ki, Gy{\"o}rgy and Draguhn, Andreas},
  year = {2004},
  month = jun,
  journal = {Science},
  volume = {304},
  number = {5679},
  pages = {1926--1929},
  publisher = {{American Association for the Advancement of Science}},
  issn = {00368075},
  doi = {10.1126/science.1099745},
  abstract = {Clocks tick, bridges and skyscrapers vibrate, neuronal networks oscillate. Are neuronal oscillations an inevitable by-product, similar to bridge vibrations, or an essential part of the brain's design? Mammalian cortical neurons form behavior-dependent oscillating networks of various sizes, which span five orders of magnitude in frequency. These oscillations are phylogenetically preserved, suggesting that they are functionally relevant. Recent findings indicate that network oscillations bias input selection, temporally link neurons into assemblies, and facilitate synaptic plasticity, mechanisms that cooperatively support temporal representation and long-term consolidation of information.},
  pmid = {15218136},
  file = {C\:\\Users\\johns\\Zotero\\storage\\ER4UM6NU\\Buzsáki_Draguhn_2004_Neuronal oscillations in cortical networks.pdf}
}

@article{buzsaki12,
  title = {The Origin of Extracellular Fields and Currents \textemdash{} {{EEG}}, {{ECoG}}, {{LFP}} and Spikes},
  author = {Buzs{\'a}ki, Gy{\"o}rgy and Anastassiou, Costas A. and Koch, Christof},
  year = {2012},
  month = may,
  journal = {Nature Reviews Neuroscience 2012 13:6},
  volume = {13},
  number = {6},
  pages = {407--420},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/nrn3241},
  abstract = {Neuronal activity in the brain gives rise to transmembrane and extracellular electromagnetic fields that can be measured in the extracellular medium using several approaches. In this Review, Buzs\'aki and colleagues provide an overview of the mechanisms that underlie the generation of extracellular currents and fields. Neuronal activity in the brain gives rise to transmembrane currents that can be measured in the extracellular medium. Although the major contributor of the extracellular signal is the synaptic transmembrane current, other sources \textemdash{} including Na+ and Ca2+ spikes, ionic fluxes through voltage- and ligand-gated channels, and intrinsic membrane oscillations \textemdash{} can substantially shape the extracellular field. High-density recordings of field activity in animals and subdural grid recordings in humans, combined with recently developed data processing tools and computational modelling, can provide insight into the cooperative behaviour of neurons, their average synaptic input and their spiking output, and can increase our understanding of how these processes contribute to the extracellular signal.},
  keywords = {Cellular neuroscience,Computational neuroscience,Extracellular signalling molecules,Ion channels,Synaptic transmission},
  file = {C\:\\Users\\johns\\Zotero\\storage\\88IX6AP5\\Buzsáki et al_2012_The origin of extracellular fields and currents — EEG, ECoG, LFP and spikes.pdf}
}

@article{buzsaki12a,
  title = {Mechanisms of {{Gamma Oscillations}}},
  author = {Buzs{\'a}ki, Gy{\"o}rgy and Wang, Xiao-Jing},
  year = {2012},
  journal = {Annual Review of Neuroscience},
  volume = {35},
  number = {1},
  pages = {203--225},
  doi = {10.1146/annurev-neuro-062111-150444},
  abstract = {Gamma rhythms are commonly observed in many brain regions during both waking and sleep states, yet their functions and mechanisms remain a matter of debate. Here we review the cellular and synaptic mechanisms underlying gamma oscillations and outline empirical questions and controversial conceptual issues. Our main points are as follows: First, gamma-band rhythmogenesis is inextricably tied to perisomatic inhibition. Second, gamma oscillations are short-lived and typically emerge from the coordinated interaction of excitation and inhibition, which can be detected as local field potentials. Third, gamma rhythm typically concurs with irregular firing of single neurons, and the network frequency of gamma oscillations varies extensively depending on the underlying mechanism. To document gamma oscillations, efforts should be made to distinguish them from mere increases of gamma-band power and/or increased spiking activity. Fourth, the magnitude of gamma oscillation is modulated by slower rhythms. Such cross-frequency coupling may serve to couple active patches of cortical circuits. Because of their ubiquitous nature and strong correlation with the ``operational modes'' of local circuits, gamma oscillations continue to provide important clues about neuronal population dynamics in health and disease.},
  pmid = {22443509},
  annotation = {\_eprint: https://doi.org/10.1146/annurev-neuro-062111-150444},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Buzsáki_Wang_2012_Mechanisms of Gamma Oscillations.pdf}
}

@article{buzsaki15,
  title = {Hippocampal Sharp Wave-Ripple: {{A}} Cognitive Biomarker for Episodic Memory and Planning},
  author = {Buzs{\'a}ki, Gy{\"o}rgy},
  year = {2015},
  month = oct,
  journal = {Hippocampus},
  volume = {25},
  number = {10},
  pages = {1073--1188},
  publisher = {{John Wiley and Sons Inc.}},
  issn = {10981063},
  doi = {10.1002/hipo.22488},
  abstract = {Sharp wave ripples (SPW-Rs) represent the most synchronous population pattern in the mammalian brain. Their excitatory output affects a wide area of the cortex and several subcortical nuclei. SPW-Rs occur during "off-line" states of the brain, associated with consummatory behaviors and non-REM sleep, and are influenced by numerous neurotransmitters and neuromodulators. They arise from the excitatory recurrent system of the CA3 region and the SPW-induced excitation brings about a fast network oscillation (ripple) in CA1. The spike content of SPW-Rs is temporally and spatially coordinated by a consortium of interneurons to replay fragments of waking neuronal sequences in a compressed format. SPW-Rs assist in transferring this compressed hippocampal representation to distributed circuits to support memory consolidation; selective disruption of SPW-Rs interferes with memory. Recently acquired and pre-existing information are combined during SPW-R replay to influence decisions, plan actions and, potentially, allow for creative thoughts. In addition to the widely studied contribution to memory, SPW-Rs may also affect endocrine function via activation of hypothalamic circuits. Alteration of the physiological mechanisms supporting SPW-Rs leads to their pathological conversion, "p-ripples," which are a marker of epileptogenic tissue and can be observed in rodent models of schizophrenia and Alzheimer's Disease. Mechanisms for SPW-R genesis and function are discussed in this review.},
  pmid = {26135716},
  keywords = {Epilepsy,Imagining,Learning,Memory,Planning}
}

@article{cannon14,
  title = {{{LEMS}}: {{A}} Language for Expressing Complex Biological Models in Concise and Hierarchical Form and Its Use in Underpinning {{NeuroML}} 2},
  author = {Cannon, Robert C. and Gleeson, Padraig and Crook, Sharon and Ganapathy, Gautham and Marin, Boris and Piasini, Eugenio and Silver, R. Angus},
  year = {2014},
  month = sep,
  journal = {Frontiers in Neuroinformatics},
  volume = {8},
  number = {SEP},
  pages = {79},
  publisher = {{Frontiers Media S.A.}},
  issn = {16625196},
  doi = {10.3389/fninf.2014.00079},
  abstract = {Computational models are increasingly important for studying complex neurophysiological systems. As scientific tools, it is essential that such models can be reproduced and critically evaluated by a range of scientists. However, published models are currently implemented using a diverse set of modeling approaches, simulation tools, and computer languages making them inaccessible and difficult to reproduce. Models also typically contain concepts that are tightly linked to domain-specific simulators, or depend on knowledge that is described exclusively in text-based documentation. To address these issues we have developed a compact, hierarchical, XML-based language called LEMS (Low Entropy Model Specification), that can define the structure and dynamics of a wide range of biological models in a fully machine readable format. We describe how LEMS underpins the latest version of NeuroML and show that this framework can define models of ion channels, synapses, neurons and networks. Unit handling, often a source of error when reusing models, is built into the core of the language by specifying physical quantities in models in terms of the base dimensions. We show how LEMS, together with the open source Java and Python based libraries we have developed, facilitates the generation of scripts for multiple neuronal simulators and provides a route for simulator free code generation. We establish that LEMS can be used to define models from systems biology and map them to neuroscience-domain specific simulators, enabling models to be shared between these traditionally separate disciplines. LEMS and NeuroML 2 provide a new, comprehensive framework for defining computational models of neuronal and other biological systems in a machine readable format, making them more reproducible and increasing the transparency and accessibility of their underlying structure and properties.},
  keywords = {Model description language,Model sharing,Simulation,Spiking neural networks,Standardization},
  file = {C\:\\Users\\johns\\Zotero\\storage\\EQWS9LFY\\Cannon et al_2014_LEMS.pdf}
}

@article{cardin10,
  title = {Targeted Optogenetic Stimulation and Recording of Neurons in Vivo Using Cell-Type-Specific Expression of {{Channelrhodopsin-2}}},
  author = {Cardin, Jessica A. and Carl{\'e}n, Marie and Meletis, Konstantinos and Knoblich, Ulf and Zhang, Feng and Deisseroth, Karl and Tsai, Li Huei and Moore, Christopher I.},
  year = {2010},
  month = jan,
  journal = {Nature Protocols},
  volume = {5},
  number = {2},
  pages = {247--254},
  publisher = {{Nature Publishing Group}},
  issn = {17542189},
  doi = {10.1038/nprot.2009.228},
  abstract = {A major long-term goal of systems neuroscience is to identify the different roles of neural subtypes in brain circuit function. The ability to causally manipulate selective cell types is critical to meeting this goal. This protocol describes techniques for optically stimulating specific populations of excitatory neurons and inhibitory interneurons in vivo in combination with electrophysiology. Cell type selectivity is obtained using Cre-dependent expression of the light-activated channel Channelrhodopsin-2. We also describe approaches for minimizing optical interference with simultaneous extracellular and intracellular recording. These optogenetic techniques provide a spatially and temporally precise means of studying neural activity in the intact brain and allow a detailed examination of the effect of evoked activity on the surrounding local neural network. Injection of viral vectors requires 30-45 min, and in vivo electrophysiology with optogenetic stimulation requires 1-4 h. \textcopyright{} 2010 Nature Publishing Group.},
  pmid = {20134425},
  keywords = {Electrophysiology,Neuronal physiology,Optogenetics},
  file = {C\:\\Users\\johns\\Zotero\\storage\\36TYSFUG\\full-text.pdf}
}

@article{chaudhuri19,
  title = {The Intrinsic Attractor Manifold and Population Dynamics of a Canonical Cognitive Circuit across Waking and Sleep},
  author = {Chaudhuri, Rishidev and Ger{\c c}ek, Berk and Pandey, Biraj and Peyrache, Adrien and Fiete, Ila},
  year = {2019},
  month = sep,
  journal = {Nature Neuroscience},
  volume = {22},
  number = {9},
  pages = {1512--1520},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-019-0460-x},
  abstract = {Neural circuits construct distributed representations of key variables\textemdash external stimuli or internal constructs of quantities relevant for survival, such as an estimate of one's location in the world\textemdash as vectors of population activity. Although population activity vectors may have thousands of entries (dimensions), we consider that they trace out a low-dimensional manifold whose dimension and topology match the represented variable. This manifold perspective enables blind discovery and decoding of the represented variable using only neural population activity (without knowledge of the input, output, behavior or topography). We characterize and directly visualize manifold structure in the mammalian head direction circuit, revealing that the states form a topologically nontrivial one-dimensional ring. The ring exhibits isometry and is invariant across waking and rapid eye movement sleep. This result directly demonstrates that there are continuous attractor dynamics and enables powerful inference about mechanism. Finally, external rather than internal noise limits memory fidelity, and the manifold approach reveals new dynamical trajectories during sleep.},
  copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  keywords = {Neural circuits,Neural decoding,Sleep,Spatial memory},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Chaudhuri et al_2019_The intrinsic attractor manifold and population dynamics of a canonical.pdf}
}

@article{chen18a,
  title = {Near-Infrared Deep Brain Stimulation via Upconversion Nanoparticle\textendash Mediated Optogenetics},
  author = {Chen, Shuo and Weitemier, Adam Z. and Zeng, Xiao and He, Linmeng and Wang, Xiyu and Tao, Yanqiu and Huang, Arthur J.Y. and Hashimotodani, Yuki and Kano, Masanobu and Iwasaki, Hirohide and Parajuli, Laxmi Kumar and Okabe, Shigeo and Loong Teh, Daniel B. and All, Angelo H. and {Tsutsui-Kimura}, Iku and Tanaka, Kenji F. and Liu, Xiaogang and McHugh, Thomas J.},
  year = {2018},
  month = feb,
  journal = {Science},
  volume = {359},
  number = {6376},
  pages = {679--684},
  publisher = {{American Association for the Advancement of Science}},
  issn = {10959203},
  doi = {10.1126/science.aaq1144},
  abstract = {Optogenetics has revolutionized the experimental interrogation of neural circuits and holds promise for the treatment of neurological disorders. It is limited, however, because visible light cannot penetrate deep inside brain tissue. Upconversion nanoparticles (UCNPs) absorb tissue-penetrating near-infrared (NIR) light and emit wavelength-specific visible light. Here, we demonstrate that molecularly tailored UCNPs can serve as optogenetic actuators of transcranial NIR light to stimulate deep brain neurons. Transcranial NIR UCNP-mediated optogenetics evoked dopamine release from genetically tagged neurons in the ventral tegmental area, induced brain oscillations through activation of inhibitory neurons in the medial septum, silenced seizure by inhibition of hippocampal excitatory cells, and triggered memory recall. UCNP technology will enable less-invasive optical neuronal activity manipulation with the potential for remote therapy.},
  isbn = {9781510623880},
  pmid = {29439241},
  file = {C\:\\Users\\johns\\Zotero\\storage\\74D6NKH9\\Chen et al_2018_Near-infrared deep brain stimulation via upconversion nanoparticle–mediated.pdf}
}

@article{chen18b,
  title = {Towards Circuit Optogenetics},
  author = {Chen, I-Wen and Papagiakoumou, Eirini and Emiliani, Valentina},
  year = {2018},
  month = jun,
  journal = {Current Opinion in Neurobiology},
  series = {Neurotechnologies},
  volume = {50},
  pages = {179--189},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2018.03.008},
  abstract = {Optogenetics neuronal targeting combined with single-photon wide-field illumination has already proved its enormous potential in neuroscience, enabling the optical control of entire neuronal networks and disentangling their role in the control of specific behaviors. However, establishing how a single or a sub-set of neurons controls a specific behavior, or how functionally identical neurons are connected in a particular task, or yet how behaviors can be modified in real-time by the complex wiring diagram of neuronal connections requires more sophisticated approaches enabling to drive neuronal circuits activity with single-cell precision and millisecond temporal resolution. This has motivated on one side the development of flexible optical methods for two-photon (2P) optogenetic activation using either, or a hybrid of two approaches: scanning and parallel illumination. On the other side, it has stimulated the engineering of new opsins with modified spectral characteristics, channel kinetics and spatial distribution of expression, offering the necessary flexibility of choosing the appropriate opsin for each application. The need for optical manipulation of multiple targets with millisecond temporal resolution has imposed three-dimension (3D) parallel holographic illumination as the technique of choice for optical control of neuronal circuits organized in 3D. Today 3D parallel illumination exists in several complementary variants, each with a different degree of simplicity, light uniformity, temporal precision and axial resolution. In parallel, the possibility to reach hundreds of targets in 3D volumes has prompted the development of low-repetition rate amplified laser sources enabling high peak power, while keeping low average power for stimulating each cell. All together those progresses open the way for a precise optical manipulation of neuronal circuits with unprecedented precision and flexibility.},
  langid = {english},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Chen et al_2018_Towards circuit optogenetics.pdf}
}

@article{chuong14,
  title = {Noninvasive Optical Inhibition with a Red-Shifted Microbial Rhodopsin},
  author = {Chuong, Amy S. and Miri, Mitra L. and Busskamp, Volker and Matthews, Gillian A.C. and Acker, Leah C. and S{\o}rensen, Andreas T. and Young, Andrew and Klapoetke, Nathan C. and Henninger, Mike A. and Kodandaramaiah, Suhasa B. and Ogawa, Masaaki and Ramanlal, Shreshtha B. and Bandler, Rachel C. and Allen, Brian D. and Forest, Craig R. and Chow, Brian Y. and Han, Xue and Lin, Yingxi and Tye, Kay M. and Roska, Botond and Cardin, Jessica A. and Boyden, Edward S.},
  year = {2014},
  month = jul,
  journal = {Nature Neuroscience},
  volume = {17},
  number = {8},
  pages = {1123--1129},
  publisher = {{Nature Publishing Group}},
  issn = {15461726},
  doi = {10.1038/nn.3752},
  abstract = {Optogenetic inhibition of the electrical activity of neurons enables the causal assessment of their contributions to brain functions. Red light penetrates deeper into tissue than other visible wavelengths. We present a red-shifted cruxhalorhodopsin, Jaws, derived from Haloarcula (Halobacterium) salinarum (strain Shark) and engineered to result in red light-induced photocurrents three times those of earlier silencers. Jaws exhibits robust inhibition of sensory-evoked neural activity in the cortex and results in strong light responses when used in retinas of retinitis pigmentosa model mice. We also demonstrate that Jaws can noninvasively mediate transcranial optical inhibition of neurons deep in the brains of awake mice. The noninvasive optogenetic inhibition opened up by Jaws enables a variety of important neuroscience experiments and offers a powerful general-use chloride pump for basic and applied neuroscience. \textcopyright{} 2014 Nature America, Inc.},
  pmid = {24997763},
  keywords = {Optogenetics},
  file = {C\:\\Users\\johns\\Zotero\\storage\\CJAT4KDK\\Chuong et al_2014_Noninvasive optical inhibition with a red-shifted microbial rhodopsin.pdf}
}

@article{churchland10,
  title = {Cortical {{Preparatory Activity}}: {{Representation}} of~{{Movement}} or {{First Cog}} in a {{Dynamical Machine}}?},
  shorttitle = {Cortical {{Preparatory Activity}}},
  author = {Churchland, Mark M. and Cunningham, John P. and Kaufman, Matthew T. and Ryu, Stephen I. and Shenoy, Krishna V.},
  year = {2010},
  month = nov,
  journal = {Neuron},
  volume = {68},
  number = {3},
  pages = {387--400},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2010.09.015},
  abstract = {The motor cortices are active during both movement and movement preparation. A common assumption is that preparatory activity constitutes a subthreshold form of movement activity: a neuron active during rightward movements becomes modestly active during preparation of a rightward movement. We asked whether this pattern of activity is, in fact, observed. We found that it was not: at the level of a single neuron, preparatory tuning was weakly correlated with movement-period tuning. Yet, somewhat paradoxically, preparatory tuning could be captured by a preferred direction in an abstract ``space'' that described the population-level pattern of movement activity. In fact, this relationship accounted for preparatory responses better than did traditional tuning models. These results are expected if preparatory activity provides the initial state of a dynamical system whose evolution produces movement activity. Our results thus suggest that preparatory activity may not represent specific factors, and may instead play a more mechanistic role.},
  langid = {english},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Churchland et al_2010_Cortical Preparatory Activity.pdf}
}

@article{churchland12,
  title = {Neural Population Dynamics during Reaching},
  author = {Churchland, Mark M. and Cunningham, John P. and Kaufman, Matthew T. and Foster, Justin D. and Nuyujukian, Paul and Ryu, Stephen I. and Shenoy, Krishna V. and Shenoy, Krishna V.},
  year = {2012},
  journal = {Nature},
  volume = {487},
  number = {7405},
  pages = {51--56},
  issn = {00280836},
  doi = {10.1038/nature11129},
  abstract = {Most theories of motor cortex have assumed that neural activity represents movement parameters. This view derives from what is known about primary visual cortex, where neural activity represents patterns of light. Yet it is unclear how well the analogy between motor and visual cortex holds. Single-neuron responses in motor cortex are complex, and there is marked disagreement regarding which movement parameters are represented. A better analogy might be with other motor systems, where a common principle is rhythmic neural activity. Here we find that motor cortex responses during reaching contain a brief but strong oscillatory component, something quite unexpected for a non-periodic behaviour. Oscillation amplitude and phase followed naturally from the preparatory state, suggesting a mechanistic role for preparatory neural activity. These results demonstrate an unexpected yet surprisingly simple structure in the population response. This underlying structure explains many of the confusing features of individual neural responses. \textcopyright{} 2012 Macmillan Publishers Limited.},
  pmid = {22722855},
  file = {C\:\\Users\\johns\\Zotero\\storage\\M4D8M2P7\\Churchland et al_2012_Neural population dynamics during reaching.pdf}
}

@article{cole17,
  title = {Brain {{Oscillations}} and the {{Importance}} of {{Waveform Shape}}},
  author = {Cole, Scott R. and Voytek, Bradley},
  year = {2017},
  month = feb,
  journal = {Trends in Cognitive Sciences},
  volume = {21},
  number = {2},
  pages = {137--149},
  publisher = {{Elsevier Current Trends}},
  issn = {1879307X},
  doi = {10.1016/j.tics.2016.12.008},
  abstract = {Oscillations are a prevalent feature of brain recordings. They are believed to play key roles in neural communication and computation. Current analysis methods for studying neural oscillations often implicitly assume that the oscillations are sinusoidal. While these approaches have proven fruitful, we show here that there are numerous instances in which neural oscillations are nonsinusoidal. We highlight approaches to characterize nonsinusoidal features and account for them in traditional spectral analysis. Instead of being a nuisance, we discuss how these nonsinusoidal features may provide crucial and so far overlooked physiological information related to neural communication, computation, and cognition.},
  pmid = {28063662},
  keywords = {nonsinusoidal,oscillation,phase–amplitude coupling,shape,waveform}
}

@article{cole19,
  title = {Cycle-by-Cycle Analysis of Neural Oscillations},
  author = {Cole, Scott and Voytek, Bradley},
  year = {2019},
  month = aug,
  journal = {Journal of Neurophysiology},
  volume = {122},
  number = {2},
  pages = {849--861},
  publisher = {{American Physiological Society}},
  issn = {15221598},
  doi = {10.1152/JN.00273.2019},
  abstract = {Neural oscillations are widely studied using methods based on the Fourier transform, which models data as sums of sinusoids. This has successfully uncovered numerous links between oscillations and cognition or disease. However, neural data are nonsinusoidal, and these nonsinusoidal features are increasingly linked to a variety of behavioral and cognitive states, pathophysiology, and underlying neuronal circuit properties. We present a new analysis framework, one that is complementary to existing Fourier and Hilbert transform-based approaches, that quantifies oscillatory features in the time domain on a cycle-by-cycle basis. We have released this cycle-by-cycle analysis suite as ``bycycle,'' a fully documented, open-source Python package with detailed tutorials and troubleshooting cases. This approach performs tests to assess whether an oscillation is present at any given moment and, if so, quantifies each oscillatory cycle by its amplitude, period, and waveform symmetry, the latter of which is missed with the use of conventional approaches. In a series of simulated event-related studies, we show how conventional Fourier and Hilbert transform approaches can conflate event-related changes in oscillation burst duration as increased oscillatory amplitude and as a change in the oscillation frequency, even though those features were unchanged in simulation. Our approach avoids these errors. Furthermore, we validate this approach in simulation and against experimental recordings of patients with Parkinson's disease, who are known to have nonsinusoidal beta (12\textendash 30 Hz) oscillations.},
  pmid = {31268801},
  keywords = {Fourier transform,Hilbert transform,neural oscillations,nonsinusoidal},
  file = {C\:\\Users\\johns\\Zotero\\storage\\GYE2BLP7\\Cole_Voytek_2019_Cycle-by-cycle analysis of neural oscillations.pdf}
}

@article{cowley20,
  title = {Slow {{Drift}} of {{Neural Activity}} as a {{Signature}} of {{Impulsivity}} in {{Macaque Visual}} and {{Prefrontal Cortex}}},
  author = {Cowley, Benjamin R. and Snyder, Adam C. and Acar, Katerina and Williamson, Ryan C. and Yu, Byron M. and Smith, Matthew A.},
  year = {2020},
  month = nov,
  journal = {Neuron},
  volume = {108},
  number = {3},
  pages = {551-567.e8},
  publisher = {{Cell Press}},
  issn = {10974199},
  doi = {10.1016/j.neuron.2020.07.021},
  abstract = {The ability to make a perceptual decision depends both on sensory inputs and on internal cognitive state. Cowley et al. find a slow drift embedded in populations of neurons in visual and prefrontal cortex. Rather than biasing sensory evidence, the slow drift reflects the likelihood of an impulsive decision.},
  pmid = {32810433},
  keywords = {arousal,decision making,impulsivity,neural fluctuation,neural population,PFC,prefrontal cortex,slow drift,stimulus encoding,vision,visual area V4},
  file = {C\:\\Users\\johns\\Zotero\\storage\\2Q2ZGJG2\\Cowley et al_2020_Slow Drift of Neural Activity as a Signature of Impulsivity in Macaque Visual.pdf}
}

@article{cruzado20,
  title = {Conjunctive Representation of What and When in Monkey Hippocampus and Lateral Prefrontal Cortex during an Associative Memory Task},
  author = {Cruzado, Nathanael A. and Tiganj, Zoran and Brincat, Scott L. and Miller, Earl K. and Howard, Marc W.},
  year = {2020},
  journal = {Hippocampus},
  volume = {30},
  number = {12},
  pages = {1332--1346},
  issn = {1098-1063},
  doi = {10.1002/hipo.23282},
  abstract = {Adaptive memory requires the organism to form associations that bridge between events separated in time. Many studies show interactions between hippocampus (HPC) and prefrontal cortex (PFC) during formation of such associations. We analyze neural recording from monkey HPC and PFC during a memory task that requires the monkey to associate stimuli separated by about a second in time. After the first stimulus was presented, large numbers of units in both HPC and PFC fired in sequence. Many units fired only when a particular stimulus was presented at a particular time in the past. These results indicate that both HPC and PFC maintain a temporal record of events that could be used to form associations across time. This temporal record of the past is a key component of the temporal coding hypothesis, a hypothesis in psychology that memory not only encodes what happened, but when it happened.},
  langid = {english},
  keywords = {hippocampus,paired associate,prefrontal cortex,time cells,working memory},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/hipo.23282},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Cruzado et al_2020_Conjunctive representation of what and when in monkey hippocampus and lateral.pdf}
}

@article{cunningham14,
  title = {Dimensionality Reduction for Large-Scale Neural Recordings.},
  author = {Cunningham, John P and Yu, Byron M},
  year = {2014},
  month = nov,
  journal = {Nature neuroscience},
  volume = {17},
  number = {11},
  pages = {1500--9},
  publisher = {{NIH Public Access}},
  issn = {1546-1726},
  doi = {10.1038/nn.3776},
  abstract = {Most sensory, cognitive and motor functions depend on the interactions of many neurons. In recent years, there has been rapid development and increasing use of technologies for recording from large numbers of neurons, either sequentially or simultaneously. A key question is what scientific insight can be gained by studying a population of recorded neurons beyond studying each neuron individually. Here, we examine three important motivations for population studies: single-trial hypotheses requiring statistical power, hypotheses of population response structure and exploratory analyses of large data sets. Many recent studies have adopted dimensionality reduction to analyze these populations and to find features that are not apparent at the level of individual neurons. We describe the dimensionality reduction methods commonly applied to population activity and offer practical advice about selecting methods and interpreting their outputs. This review is intended for experimental and computational researchers who seek to understand the role dimensionality reduction has had and can have in systems neuroscience, and who seek to apply these methods to their own data.},
  pmid = {25151264},
  file = {C\:\\Users\\johns\\Zotero\\storage\\72QERSBK\\Cunningham_Yu_2014_Dimensionality reduction for large-scale neural recordings.pdf}
}

@article{dai20,
  title = {Brain {{Modeling ToolKit}}: {{An}} Open Source Software Suite for Multiscale Modeling of Brain Circuits},
  author = {Dai, Kael and Gratiy, Sergey L. and Billeh, Yazan N. and Xu, Richard and Cai, Binghuang and Cain, Nicholas and Rimehaug, Atle E. and Stasik, Alexander J. and Einevoll, Gaute T. and Mihalas, Stefan and Koch, Christof and Arkhipov, Anton},
  year = {2020},
  month = nov,
  journal = {PLoS Computational Biology},
  volume = {16},
  number = {11},
  pages = {e1008386},
  publisher = {{Public Library of Science}},
  issn = {15537358},
  doi = {10.1371/journal.pcbi.1008386},
  abstract = {Experimental studies in neuroscience are producing data at a rapidly increasing rate, providing exciting opportunities and formidable challenges to existing theoretical and modeling approaches. To turn massive datasets into predictive quantitative frameworks, the field needs software solutions for systematic integration of data into realistic, multiscale models. Here we describe the Brain Modeling ToolKit (BMTK), a software suite for building models and performing simulations at multiple levels of resolution, from biophysically detailed multi-compartmental, to point-neuron, to population-statistical approaches. Leveraging the SONATA file format and existing software such as NEURON, NEST, and others, BMTK offers a consistent user experience across multiple levels of resolution. It permits highly sophisticated simulations to be set up with little coding required, thus lowering entry barriers to new users. We illustrate successful applications of BMTK to large-scale simulations of a cortical area. BMTK is an open-source package provided as a resource supporting modeling-based discovery in the community.},
  pmid = {33253147},
  keywords = {Biophysical simulations,Biophysics,Network analysis,Neural networks,Neurons,Simulation and modeling,Soil perturbation,Vision},
  file = {C\:\\Users\\johns\\Zotero\\storage\\3AI8E5IM\\Dai et al_2020_Brain Modeling ToolKit.pdf}
}

@article{davie06,
  title = {Dendritic Patch-Clamp Recording},
  author = {Davie, Jenny T. and Kole, Maarten H.P. and Letzkus, Johannes J. and Rancz, Ede A. and Spruston, Nelson and Stuart, Greg J. and H{\"a}usser, Michael},
  year = {2006},
  month = sep,
  journal = {Nature Protocols},
  volume = {1},
  number = {3},
  pages = {1235--1247},
  publisher = {{Nature Publishing Group}},
  issn = {17502799},
  doi = {10.1038/nprot.2006.164},
  abstract = {The patch-clamp technique allows investigation of the electrical excitability of neurons and the functional properties and densities of ion channels. Most patch-clamp recordings from neurons have been made from the soma, the largest structure of individual neurons, while their dendrites, which form the majority of the surface area and receive most of the synaptic input, have been relatively neglected. This protocol describes techniques for recording from the dendrites of neurons in brain slices under direct visual control. Although the basic technique is similar to that used for somatic patching, we describe refinements and optimizations of slice quality, microscope optics, setup stability and electrode approach that are required for maximizing the success rate for dendritic recordings. Using this approach, all configurations of the patch-clamp technique (cell-attached, inside-out, whole-cell, outside-out and perforated patch) can be achieved, even for relatively distal dendrites, and simultaneous multiple-electrode dendritic recordings are also possible. The protocol - from the beginning of slice preparation to the end of the first successful recording - can be completed in 3 h.},
  pmid = {17406407},
  keywords = {Analytical Chemistry,Biological Techniques,Computational Biology/Bioinformatics,general,Life Sciences,Microarrays,Organic Chemistry},
  file = {C\:\\Users\\johns\\Zotero\\storage\\JGNB5PRY\\Davie et al_2006_Dendritic patch-clamp recording.pdf}
}

@article{davis20,
  title = {Spontaneous Travelling Cortical Waves Gate Perception in Behaving Primates},
  author = {Davis, Zachary W. and Muller, Lyle and {Martinez-Trujillo}, Julio and Sejnowski, Terrence and Reynolds, John H.},
  year = {2020},
  month = nov,
  journal = {Nature},
  volume = {587},
  number = {7834},
  pages = {432--436},
  publisher = {{Nature Research}},
  issn = {14764687},
  doi = {10.1038/s41586-020-2802-y},
  abstract = {Perceptual sensitivity varies from moment to moment. One potential source of this variability is spontaneous fluctuations in cortical activity that can travel as waves1. Spontaneous travelling waves have been reported during anaesthesia2\textendash 7, but it is not known whether they have a role during waking perception. Here, using newly developed analytic techniques to characterize the moment-to-moment dynamics of noisy multielectrode data, we identify spontaneous waves of activity in the extrastriate visual cortex of awake, behaving marmosets (Callithrix jacchus). In monkeys trained to detect faint visual targets, the timing and position of spontaneous travelling waves before target onset predicted the magnitude of target-evoked activity and the likelihood of target detection. By contrast, spatially disorganized fluctuations of neural activity were much less predictive. These results reveal an important role for spontaneous travelling waves in sensory processing through the modulation of neural and perceptual sensitivity.},
  pmid = {33029013},
  keywords = {Extrastriate cortex,Neural circuits,Sensory processing},
  file = {C\:\\Users\\johns\\Zotero\\storage\\FXUMMD2J\\Davis et al_2020_Spontaneous travelling cortical waves gate perception in behaving primates.pdf}
}

@article{davison09,
  title = {Trends in Programming Languages for Neuroscience Simulations},
  author = {Davison, Andrew P. and Hines, Michael L. and Muller, Eilif},
  year = {2009},
  journal = {Frontiers in Neuroscience},
  volume = {3},
  number = {DEC},
  pages = {374--380},
  publisher = {{Frontiers}},
  issn = {16624548},
  doi = {10.3389/neuro.01.036.2009},
  abstract = {Neuroscience simulators allow scientists to express models in terms of biological concepts, without having to concern themselves with low-level computational details of their implementation. The expressiveness, power and ease-of-use of the simulator interface is critical in efficiently and accurately translating ideas into a working simulation. We review long-term trends in the development of programmable simulator interfaces, and examine the benefits of moving from proprietary, domain-specific languages to modern dynamic general-purpose languages, in particular Python, which provide neuroscientists with an interactive and expressive simulation development environment and easy access to state-of-the-art general-purpose tools for scientific computing. \textcopyright{} 2009 Davison, Hines and Muller.},
  keywords = {Computational neuroscience,Python,Simulation},
  file = {C\:\\Users\\johns\\Zotero\\storage\\RL4KFNA9\\Davison et al_2009_Trends in programming languages for neuroscience simulations.pdf}
}

@article{davison09a,
  title = {{{PyNN}}: {{A}} Common Interface for Neuronal Network Simulators},
  author = {Davison, Andrew P. and Br{\"u}derle, Daniel and Eppler, Jochen and Kremkow, Jens and Muller, Eilif and Pecevski, Dejan and Perrinet, Laurent and Yger, Pierre},
  year = {2009},
  month = jan,
  journal = {Frontiers in Neuroinformatics},
  volume = {2},
  number = {JAN},
  pages = {11},
  publisher = {{Frontiers Media S.A.}},
  issn = {16625196},
  doi = {10.3389/neuro.11.011.2008},
  abstract = {Computational neuroscience has produced a diversity of software for simulations of networks of spiking neurons, with both negative and positive consequences. On the one hand, each simulator uses its own programming or confi guration language, leading to considerable diffi culty in porting models from one simulator to another. This impedes communication between investigators and makes it harder to reproduce and build on the work of others. On the other hand, simulation results can be cross-checked between different simulators, giving greater confi dence in their correctness, and each simulator has different optimizations, so the most appropriate simulator can be chosen for a given modelling task. A common programming interface to multiple simulators would reduce or eliminate the problems of simulator diversity while retaining the benefi ts. PyNN is such an interface, making it possible to write a simulation script once, using the Python programming language, and run it without modifi cation on any supported simulator (currently NEURON, NEST, PCSIM, Brian and the Heidelberg VLSI neuromorphic hardware). PyNN increases the productivity of neuronal network modelling by providing high-level abstraction, by promoting code sharing and reuse, and by providing a foundation for simulator-agnostic analysis, visualization and data-management tools. PyNN increases the reliability of modelling studies by making it much easier to check results on multiple simulators. \textcopyright{} 2009 Davison, Br\"uderle, Eppler, Kremkow, Muller, Pecevski, Perrinet and Yger.},
  keywords = {Computational neuroscience,Interoperability,Large-scale models,Parallel computing,Python,Reproducibility,Simulation,Translation},
  file = {C\:\\Users\\johns\\Zotero\\storage\\XPUCENWE\\Davison et al_2009_PyNN.pdf}
}

@misc{doerig22,
  title = {The Neuroconnectionist Research Programme},
  author = {Doerig, Adrien and Sommers, Rowan and Seeliger, Katja and Richards, Blake and Ismael, Jenann and Lindsay, Grace and Kording, Konrad and Konkle, Talia and Van Gerven, Marcel A. J. and Kriegeskorte, Nikolaus and Kietzmann, Tim C.},
  year = {2022},
  month = sep,
  number = {arXiv:2209.03718},
  eprint = {2209.03718},
  eprinttype = {arxiv},
  primaryclass = {q-bio},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2209.03718},
  abstract = {Artificial Neural Networks (ANNs) inspired by biology are beginning to be widely used to model behavioral and neural data, an approach we call neuroconnectionism. ANNs have been lauded as the current best models of information processing in the brain, but also criticized for failing to account for basic cognitive functions. We propose that arguing about the successes and failures of a restricted set of current ANNs is the wrong approach to assess the promise of neuroconnectionism. Instead, we take inspiration from the philosophy of science, and in particular from Lakatos, who showed that the core of scientific research programmes is often not directly falsifiable, but should be assessed by its capacity to generate novel insights. Following this view, we present neuroconnectionism as a cohesive large-scale research programme centered around ANNs as a computational language for expressing falsifiable theories about brain computation. We describe the core of the programme, the underlying computational framework and its tools for testing specific neuroscientific hypotheses. Taking a longitudinal view, we review past and present neuroconnectionist projects and their responses to challenges, and argue that the research programme is highly progressive, generating new and otherwise unreachable insights into the workings of the brain.},
  archiveprefix = {arXiv},
  keywords = {Quantitative Biology - Neurons and Cognition},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Doerig et al_2022_The neuroconnectionist research programme.pdf}
}

@misc{driscoll22,
  title = {Flexible Multitask Computation in Recurrent Networks Utilizes Shared Dynamical Motifs},
  author = {Driscoll, Laura and Shenoy, Krishna and Sussillo, David},
  year = {2022},
  month = aug,
  pages = {2022.08.15.503870},
  publisher = {{bioRxiv}},
  doi = {10.1101/2022.08.15.503870},
  abstract = {Flexible computation is a hallmark of intelligent behavior. Yet, little is known about how neural networks contextually reconfigure for different computations. Humans are able to perform a new task without extensive training, presumably through the composition of elementary processes that were previously learned. Cognitive scientists have long hypothesized the possibility of a compositional neural code, where complex neural computations are made up of constituent components; however, the neural substrate underlying this structure remains elusive in biological and artificial neural networks. Here we identified an algorithmic neural substrate for compositional computation through the study of multitasking artificial recurrent neural networks. Dynamical systems analyses of networks revealed learned computational strategies that mirrored the modular subtask structure of the task-set used for training. Dynamical motifs such as attractors, decision boundaries and rotations were reused across different task computations. For example, tasks that required memory of a continuous circular variable repurposed the same ring attractor. We show that dynamical motifs are implemented by clusters of units and are reused across different contexts, allowing for flexibility and generalization of previously learned computation. Lesioning these clusters resulted in modular effects on network performance: a lesion that destroyed one dynamical motif only minimally perturbed the structure of other dynamical motifs. Finally, modular dynamical motifs could be reconfigured for fast transfer learning. After slow initial learning of dynamical motifs, a subsequent faster stage of learning reconfigured motifs to perform novel tasks. This work contributes to a more fundamental understanding of compositional computation underlying flexible general intelligence in neural systems. We present a conceptual framework that establishes dynamical motifs as a fundamental unit of computation, intermediate between the neuron and the network. As more whole brain imaging studies record neural activity from multiple specialized systems simultaneously, the framework of dynamical motifs will guide questions about specialization and generalization across brain regions.},
  chapter = {New Results},
  copyright = {\textcopyright{} 2022, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
  langid = {english},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Driscoll et al_2022_Flexible multitask computation in recurrent networks utilizes shared dynamical.pdf}
}

@article{dubreuil22,
  title = {The Role of Population Structure in Computations through Neural Dynamics},
  author = {Dubreuil, Alexis and Valente, Adrian and Beiran, Manuel and Mastrogiuseppe, Francesca and Ostojic, Srdjan},
  year = {2022},
  month = jun,
  journal = {Nature Neuroscience},
  volume = {25},
  number = {6},
  pages = {783--794},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-022-01088-4},
  abstract = {Neural computations are currently investigated using two separate approaches: sorting neurons into functional subpopulations or examining the low-dimensional dynamics of collective activity. Whether and how these two aspects interact to shape computations is currently unclear. Using a novel approach to extract computational mechanisms from networks trained on neuroscience tasks, here we show that the dimensionality of the dynamics and subpopulation structure play fundamentally complementary roles. Although various tasks can be implemented by increasing the dimensionality in networks with fully random population structure, flexible input\textendash output mappings instead require a non-random population structure that can be described in terms of multiple subpopulations. Our analyses revealed that such a subpopulation structure enables flexible computations through a mechanism based on gain-controlled modulations that flexibly shape the collective dynamics. Our results lead to task-specific predictions for the structure of neural selectivity, for inactivation experiments and for the implication of different neurons in multi-tasking.},
  copyright = {2022 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  keywords = {Dynamical systems,Network models},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Dubreuil et al_2022_The role of population structure in computations through neural dynamics.pdf}
}

@article{dufour15,
  title = {Optrodes for Combined Optogenetics and Electrophysiology in Live Animals},
  author = {Dufour, Suzie and Koninck, Yves De},
  year = {2015},
  month = jul,
  journal = {Neurophotonics},
  volume = {2},
  number = {3},
  pages = {031205},
  publisher = {{SPIE}},
  issn = {2329-423X, 2329-4248},
  doi = {10.1117/1.NPh.2.3.031205},
  abstract = {Optical tissue properties limit visible light depth penetration in tissue. Because of this, the recent development of optogenetic tools was quickly followed by the development of light delivery devices for in vivo optogenetics applications. We summarize the efforts made in the last decade to design neural probes that combine conventional electrophysiological recordings and optical channel(s) for optogenetic activation, often referred to as optodes or optrodes. Several aspects including challenges for light delivery in living brain tissue, the combination of light delivery with electrophysiological recordings, probe designs, multimodality, wireless implantable system, and practical considerations guiding the choice of configuration depending on the questions one seeks to address are presented.},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Dufour_Koninck_2015_Optrodes for combined optogenetics and electrophysiology in live animals.pdf}
}

@article{duncker21,
  title = {Dynamics on the Manifold: {{Identifying}} Computational Dynamical Activity from Neural Population Recordings},
  shorttitle = {Dynamics on the Manifold},
  author = {Duncker, Lea and Sahani, Maneesh},
  year = {2021},
  month = oct,
  journal = {Current Opinion in Neurobiology},
  series = {Computational {{Neuroscience}}},
  volume = {70},
  pages = {163--170},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2021.10.014},
  abstract = {The question of how the collective activity of neural populations gives rise to complex behaviour is fundamental to neuroscience. At the core of this question lie considerations about how neural circuits can perform computations that enable sensory perception, decision making, and motor control. It is thought that such computations are implemented through the dynamical evolution of distributed activity in recurrent circuits. Thus, identifying dynamical structure in neural population activity is a key challenge towards a better understanding of neural computation. At the same time, interpreting this structure in light of the computation of interest is essential for linking the time-varying activity patterns of the neural population to ongoing computational processes. Here, we review methods that aim to quantify structure in neural population recordings through a dynamical system defined in a low-dimensional latent variable space. We discuss advantages and limitations of different modelling approaches and address future challenges for the field.},
  langid = {english},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Duncker_Sahani_2021_Dynamics on the manifold.pdf}
}

@article{dura-bernal19,
  title = {{{NetpyNE}}, a Tool for Data-Driven Multiscale Modeling of Brain Circuits},
  author = {{Dura-Bernal}, Salvador and Suter, Benjamin A. and Gleeson, Padraig and Cantarelli, Matteo and Quintana, Adrian and Rodriguez, Facundo and Kedziora, David J. and Chadderdon, George L. and Kerr, Cliff C. and Neymotin, Samuel A. and McDougal, Robert A. and Hines, Michael and Shepherd, Gordon M.G. and Lytton, William W.},
  year = {2019},
  month = apr,
  journal = {eLife},
  volume = {8},
  publisher = {{eLife Sciences Publications Ltd}},
  issn = {2050084X},
  doi = {10.7554/eLife.44494},
  abstract = {Biophysical modeling of neuronal networks helps to integrate and interpret rapidly growing and disparate experimental datasets at multiple scales. The NetPyNE tool (www.netpyne. org) provides both programmatic and graphical interfaces to develop data-driven multiscale network models in NEURON. NetPyNE clearly separates model parameters from implementation code. Users provide specifications at a high level via a standardized declarative language, for example connectivity rules, to create millions of cell-to-cell connections. NetPyNE then enables users to generate the NEURON network, run efficiently parallelized simulations, optimize and explore network parameters through automated batch runs, and use built-in functions for visualization and analysis \textendash{} connectivity matrices, voltage traces, spike raster plots, local field potentials, and information theoretic measures. NetPyNE also facilitates model sharing by exporting and importing standardized formats (NeuroML and SONATA). NetPyNE is already being used to teach computational neuroscience students and by modelers to investigate brain regions and phenomena.},
  pmid = {31025934},
  file = {C\:\\Users\\johns\\Zotero\\storage\\S4GM6MUH\\Dura-Bernal et al_2019_NetpyNE, a tool for data-driven multiscale modeling of brain circuits.pdf}
}

@article{dutta19,
  title = {Analysis of an Open Source, Closed-Loop, Realtime System for Hippocampal Sharp-Wave Ripple Disruption},
  author = {Dutta, Shayok and Ackermann, Etienne and Kemere, Caleb},
  year = {2019},
  month = dec,
  journal = {Journal of Neural Engineering},
  volume = {16},
  number = {1},
  pages = {016009},
  publisher = {{IOP Publishing}},
  issn = {17412552},
  doi = {10.1088/1741-2552/aae90e},
  abstract = {Objective. The ability to modulate neural activity in a closed-loop fashion enables causal tests of hypotheses which link dynamically-changing neural circuits to specific behavioral functions. One such dynamically-changing neural circuit is the hippocampus, in which momentary sharp-wave ripple (SWR) events - {$\approx$} 100 ms periods of large 150-250 Hz oscillations - have been linked to specific mnemonic functions via selective closed-loop perturbation. The limited duration of SWR means that the latency in systems used for closed-loop interaction is of significant consequence compared to other longer-lasting circuit states. While closed-loop SWR perturbation is becoming more wide-spread, the performance trade-offs involved in building a SWR disruption system have not been explored, limiting the design and interpretation of paradigms involving ripple disruption. Approach. We developed and evaluated a low-latency closed-loop SWR detection system implemented as a module to an open-source neural data acquisition software suite capable of interfacing with two separate data acquisition hardware platforms. We first use synthetic data to explore the parameter space of our detection algorithm, then proceed to quantify the realtime in vivo performance and limitations of our system. Main results. We evaluate the realtime system performance of two data acquisition platforms, one using USB and one using ethernet for communication. We report that signal detection latency decomposes into a data acquisition component of 7.5-13.8 ms and 1.35-2.6 ms for USB and ethernet hardware respectively, and an algorithmic component which varies depending on the threshold parameter. Using ethernet acquisition hardware, we report that an algorithmic latency in the range of {$\approx$}20-66 ms can be achieved while maintaining {$<$}10 false detections per minute, and that these values are highly dependent upon algorithmic parameter space trade-offs. Significance. By characterizing this system in detail, we establish a framework for analyzing other closed-loop neural interfacing systems. Thus, we anticipate this modular, open-source, realtime system will facilitate a wide range of carefully-designed causal closed-loop experiments.},
  pmid = {30507556},
  keywords = {closed-loop,open source,realtime,sharp-wave ripple},
  file = {C\:\\Users\\johns\\Zotero\\storage\\7DDKQW4E\\Dutta et al_2019_Analysis of an open source, closed-loop, realtime system for hippocampal.pdf}
}

@article{einevoll13,
  title = {Modelling and Analysis of Local Field Potentials for Studying the Function of Cortical Circuits},
  author = {Einevoll, Gaute T. and Kayser, Christoph and Logothetis, Nikos K. and Panzeri, Stefano},
  year = {2013},
  month = oct,
  journal = {Nature Reviews Neuroscience},
  volume = {14},
  number = {11},
  pages = {770--785},
  publisher = {{Nature Publishing Group}},
  issn = {1471003X},
  doi = {10.1038/nrn3599},
  abstract = {The past decade has witnessed a renewed interest in cortical local field potentials (LFPs)-that is, extracellularly recorded potentials with frequencies of up to \textasciitilde 500 Hz. This is due to both the advent of multielectrodes, which has enabled recording of LFPs at tens to hundreds of sites simultaneously, and the insight that LFPs offer a unique window into key integrative synaptic processes in cortical populations. However, owing to its numerous potential neural sources, the LFP is more difficult to interpret than are spikes. Careful mathematical modelling and analysis are needed to take full advantage of the opportunities that this signal offers in understanding signal processing in cortical circuits and, ultimately, the neural basis of perception and cognition. \textcopyright{} 2013 Macmillan Publishers Limited.},
  pmid = {24135696},
  keywords = {Computational models,Computational neuroscience,Electrophysiology,Sensory systems},
  file = {C\:\\Users\\johns\\Zotero\\storage\\QPLR7CCB\\full-text.pdf}
}

@article{emiliani15,
  title = {All-Optical Interrogation of Neural Circuits},
  author = {Emiliani, Valentina and Cohen, Adam E. and Deisseroth, Karl and H{\"a}usser, Michael},
  year = {2015},
  month = oct,
  journal = {Journal of Neuroscience},
  volume = {35},
  number = {41},
  pages = {13917--13926},
  publisher = {{Society for Neuroscience}},
  issn = {15292401},
  doi = {10.1523/JNEUROSCI.2916-15.2015},
  abstract = {There have been two recent revolutionary advances in neuroscience: First, genetically encoded activity sensors have brought the goal of optical detection of single action potentials in vivo within reach. Second, optogenetic actuators now allow the activity of neurons to be controlled with millisecond precision. These revolutions have now been combined, together with advanced microscopies, to allow ``all-optical'' readout and manipulation of activity in neural circuits with single-spike and single-neuron precision. This is a transformational advance that will open new frontiers inneuroscience research. Harnessing the power of light in the all-optical approach require scoexpression of genetic allyen code dactivity sensors and optogenetic probesin thes a meneurons, as well as the ability to simultaneously target and record the light from the selected neurons. It has recently become possible to combine sensors and optical strategies that are sufficiently sensitiveandcross talk free to enable single-actionpotential sensitivity and precision for both readout and manipulation in the intact brain. The combination of simultaneous readout and manipulation from the same geneticallyde fined cells will enable awiderange of new experiments as well as inspire new technologies forinter acting with the brain. The advances described in this review herald a future where the traditional tools used for generations by physiologists to study and interact with the brain\textemdash stimulation and recording electrodes\textemdash can largely be replaced by light. We outline potential future developments in this field and discuss how the all-optical strategy can be applied to solve fundamental problems in neuroscience.},
  pmid = {26468193},
  keywords = {Calcium imaging,Genetically encoded calcium sensor,Genetically encoded voltage sensor,Optogenetics,Two-photon microscopy,Wavefront shaping},
  file = {C\:\\Users\\johns\\Zotero\\storage\\IPWFGL2I\\Emiliani et al_2015_All-optical interrogation of neural circuits.pdf}
}

@article{engel16,
  title = {Subcellular Patch-Clamp Recordings from the Somatodendritic Domain of Nigral Dopamine Neurons},
  author = {Engel, Dominique},
  year = {2016},
  month = nov,
  journal = {Journal of Visualized Experiments},
  volume = {2016},
  number = {117},
  pages = {e54601},
  publisher = {{Journal of Visualized Experiments}},
  issn = {1940087X},
  doi = {10.3791/54601},
  abstract = {Dendrites of dopaminergic neurons receive and convey synaptic input, support action potential back-propagation and neurotransmitter release. Understanding these fundamental functions will shed light on the information transfer in these neurons. Dendritic patch-clamp recordings provide the possibility to directly examine the electrical properties of dendrites and underlying voltage-gated ion channels. However, these fine structures are not easily accessible to patch pipettes because of their small diameter. This report describes a step-by-step procedure to collect stable and reliable recordings from the dendrites of dopaminergic neurons in acute slices. Electrophysiological measurements are combined with post hoc recovery of cell morphology. Successful experiments rely on improved preparation of slices, solutions and pipettes, adequate adjustment of the optics and stability of the pipette in contact with the recorded structure. Standard principles of somatic patch-clamp recording are applied to dendrites but with a gentler approach of the pipette. These versatile techniques can be implemented to address various questions concerning the excitable properties of dendrites.},
  pmid = {27842379},
  keywords = {Biocytin labeling,Cell-attached,Dendrite,Dopaminergic neuron,Dual recordings,Ion channel,Issue 117,Neuronal morphology,Neuroscience,Patch-clamp,Substantia nigra},
  file = {C\:\\Users\\johns\\Zotero\\storage\\MRHPYJV8\\Engel_2016_Subcellular patch-clamp recordings from the somatodendritic domain of nigral.pdf}
}

@article{eriksson22,
  title = {Multichannel Optogenetics Combined with Laminar Recordings for Ultra-Controlled Neuronal Interrogation},
  author = {Eriksson, David and Schneider, Artur and Thirumalai, Anupriya and Alyahyay, Mansour and {de la Crompe}, Brice and Sharma, Kirti and Ruther, Patrick and Diester, Ilka},
  year = {2022},
  month = feb,
  journal = {Nature Communications},
  volume = {13},
  number = {1},
  pages = {985},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-28629-6},
  abstract = {Simultaneous large-scale recordings and optogenetic interventions may hold the key to deciphering the fast-paced and multifaceted dialogue between neurons that sustains brain function. Here we have taken advantage of thin, cell-sized, optical fibers for minimally invasive optogenetics and flexible implantations. We describe a simple procedure for making those fibers side-emitting with a Lambertian emission distribution. Here we combined those fibers with silicon probes to achieve high-quality recordings and ultrafast multichannel optogenetic inhibition. Furthermore, we developed a multi-channel optical commutator and general-purpose patch-cord for flexible experiments. We demonstrate that our framework allows to conduct simultaneous laminar recordings and multifiber stimulations, 3D optogenetic stimulation, connectivity inference, and behavioral quantification in freely moving animals. Our framework paves the way for large-scale photo tagging and controlled interrogation of rapid neuronal communication in any combination of brain areas.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Neural circuits,Neuronal physiology,Optical imaging},
  file = {C\:\\Users\\johns\\Zotero\\storage\\8HNV7LV7\\Eriksson et al_2022_Multichannel optogenetics combined with laminar recordings for ultra-controlled.pdf}
}

@article{evans16,
  title = {{{PyRhO}}: {{A Multiscale Optogenetics Simulation Platform}}},
  author = {Evans, Benjamin D. and Jarvis, Sarah and Schultz, Simon R. and Nikolic, Konstantin},
  year = {2016},
  month = mar,
  journal = {Frontiers in Neuroinformatics},
  volume = {10},
  number = {MAR},
  pages = {8},
  publisher = {{Frontiers Media S.A.}},
  issn = {1662-5196},
  doi = {10.3389/fninf.2016.00008},
  abstract = {Optogenetics has become a key tool for understanding the function of neural circuits and controlling their behavior. An array of directly light driven opsins have been genetically isolated from several families of organisms, with a wide range of temporal and spectral properties. In order to characterize, understand and apply these opsins, we present an integrated suite of open-source, multi-scale computational tools called PyRhO. The purpose of developing PyRhO is three-fold: (i) to characterize new (and existing) opsins by automatically fitting a minimal set of experimental data to three-, four-, or six-state kinetic models, (ii) to simulate these models at the channel, neuron and network levels, and (iii) provide functional insights through model selection and virtual experiments in silico. The module is written in Python with an additional IPython/Jupyter notebook based GUI, allowing models to be fit, simulations to be run and results to be shared through simply interacting with a webpage. The seamless integration of model fitting algorithms with simulation environments (including NEURON and Brian2) for these virtual opsins will enable neuroscientists to gain a comprehensive understanding of their behavior and rapidly identify the most suitable variant for application in a particular biological system. This process may thereby guide not only experimental design and opsin choice but also alterations of the opsin genetic code in a neuro-engineering feed-back loop. In this way, we expect PyRhO will help to significantly advance optogenetics as a tool for transforming biological sciences.},
  keywords = {Brian simulator,Jupyter,NEURON simulator,Opsin,Optogenetics,PyRhO,Python,Spiking neurons},
  file = {C\:\\Users\\johns\\Zotero\\storage\\6BTZUJ2L\\Evans et al_2016_PyRhO.pdf}
}

@article{fabus21,
  title = {Automatic Decomposition of Electrophysiological Data into Distinct Nonsinusoidal Oscillatory Modes},
  author = {Fabus, Marco S. and Quinn, Andrew J. and Warnaby, Catherine E. and Woolrich, Mark W.},
  year = {2021},
  month = nov,
  journal = {Journal of Neurophysiology},
  volume = {126},
  number = {5},
  pages = {1670--1684},
  publisher = {{American Physiological Society}},
  issn = {15221598},
  doi = {10.1152/jn.00315.2021},
  abstract = {Neurophysiological signals are often noisy, nonsinusoidal, and consist of transient bursts. Extraction and analysis of oscillatory features (such as waveform shape and cross-frequency coupling) in such data sets remains difficult. This limits our understanding of brain dynamics and its functional importance. Here, we develop iterated masking empirical mode decomposition (itEMD), a method designed to decompose noisy and transient single-channel data into relevant oscillatory modes in a flexible, fully data-driven way without the need for manual tuning. Based on empirical mode decomposition (EMD), this technique can extract single-cycle waveform dynamics through phase-aligned instantaneous frequency. We test our method by extensive simulations across different noise, sparsity, and nonsinusoidality conditions. We find itEMD significantly improves the separation of data into distinct nonsinusoidal oscillatory components and robustly reproduces waveform shape across a wide range of relevant parameters. We further validate the technique on multimodal, multispecies electrophysiological data. Our itEMD extracts known rat hippocampal h waveform asymmetry and identifies subject-specific human occipital a without any prior assumptions about the frequencies contained in the signal. Notably, it does so with significantly less mode mixing compared with existing EMD-based methods. By reducing mode mixing and simplifying interpretation of EMD results, itEMD will enable new analyses into functional roles of neural signals in behavior and disease.},
  pmid = {34614377},
  file = {C\:\\Users\\johns\\Zotero\\storage\\S6JX23GU\\Fabus et al_2021_Automatic decomposition of electrophysiological data into distinct.pdf}
}

@article{faini21,
  title = {Ultrafast {{Light Targeting}} for {{High-Throughput Precise Control}} of {{Neuronal Networks}}},
  author = {Faini, Giulia and Molinier, Cl{\'e}ment and Telliez, C{\'e}cile and Tourain, Christophe and Forget, Beno{\^i}t C. and Ronzitti, Emiliano and Emiliani, Valentina},
  year = {2021},
  month = jun,
  journal = {bioRxiv},
  pages = {2021.06.14.448315},
  publisher = {{Cold Spring Harbor Laboratory}},
  doi = {10.1101/2021.06.14.448315},
  abstract = {Understanding how specific sets of neurons fire and wire together during cognitive-relevant activity is one of the most pressing questions in neuroscience. Two-photon, single-cell resolution optogenetics based on holographic light-targeting approaches enables accurate spatio-temporal control of individual or multiple neurons. Yet, currently, the ability to drive asynchronous activity in distinct cells is critically limited to a few milliseconds and the achievable number of targets to several dozens. In order to expand the capability of single-cell optogenetics, we introduce an approach capable of ultra-fast sequential light targeting (FLiT), based on switching temporally focused beams between holograms at kHz rates. We demonstrate serial-parallel photostimulation strategies capable of multi-cell sub-millisecond temporal control and many-fold expansion of the number of activated cells. This approach will be important for experiments that require rapid and precise cell stimulation with defined spatio-temporal activity patterns and optical control of large neuronal ensembles. \#\#\# Competing Interest Statement The authors have declared no competing interest.},
  file = {C\:\\Users\\johns\\Zotero\\storage\\RNHB8SQD\\Faini et al_2021_Ultrafast Light Targeting for High-Throughput Precise Control of Neuronal.pdf}
}

@article{fenno11,
  title = {The Development and Application of Optogenetics},
  author = {Fenno, Lief and Yizhar, Ofer and Deisseroth, Karl},
  year = {2011},
  month = jul,
  journal = {Annual Review of Neuroscience},
  volume = {34},
  pages = {389--412},
  publisher = {{Annual Reviews}},
  issn = {0147006X},
  doi = {10.1146/annurev-neuro-061010-113817},
  abstract = {Genetically encoded, single-component optogenetic tools have made a significant impact on neuroscience, enabling specific modulation of selected cells within complex neural tissues. As the optogenetic toolbox contents grow and diversify, the opportunities for neuroscience continue to grow. In this review, we outline the development of currently available single-component optogenetic tools and summarize the application of various optogenetic tools in diverse model organisms. \textcopyright{} 2011 by Annual Reviews. All rights reserved.},
  pmid = {21692661},
  keywords = {Bacteriorhodopsin,Channelrhodopsin,Electrophysiology,Halorhodopsin}
}

@article{fernandez20,
  title = {Sleep {{Spindles}}: {{Mechanisms}} and {{Functions}}},
  shorttitle = {Sleep {{Spindles}}},
  author = {Fernandez, Laura M. J. and L{\"u}thi, Anita},
  year = {2020},
  month = apr,
  journal = {Physiological Reviews},
  volume = {100},
  number = {2},
  pages = {805--868},
  publisher = {{American Physiological Society}},
  issn = {0031-9333},
  doi = {10.1152/physrev.00042.2018},
  abstract = {Download figureDownload PowerPoint},
  keywords = {ion channel,schizophrenia,sleep disorders,sleep regulation,thalamus},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Fernandez_Lüthi_2020_Sleep Spindles.pdf}
}

@article{flytzanis14,
  title = {Archaerhodopsin Variants with Enhanced Voltage-Sensitive Fluorescence in Mammalian and {{Caenorhabditis}} Elegans Neurons},
  author = {Flytzanis, Nicholas C. and Bedbrook, Claire N. and Chiu, Hui and Engqvist, Martin K. M. and Xiao, Cheng and Chan, Ken Y. and Sternberg, Paul W. and Arnold, Frances H. and Gradinaru, Viviana},
  year = {2014},
  month = sep,
  journal = {Nature Communications},
  volume = {5},
  number = {1},
  pages = {4894},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/ncomms5894},
  abstract = {Probing the neural circuit dynamics underlying behaviour would benefit greatly from improved genetically encoded voltage indicators. The proton pump Archaerhodopsin-3 (Arch), an optogenetic tool commonly used for neuronal inhibition, has been shown to emit voltage-sensitive fluorescence. Here we report two Arch variants with enhanced radiance (Archers) that in response to 655\,nm light have 3\textendash 5 times increased fluorescence and 55\textendash 99 times reduced photocurrents compared with Arch WT. The most fluorescent variant, Archer1, has 25\textendash 40\% fluorescence change in response to action potentials while using 9 times lower light intensity compared with other Arch-based voltage sensors. Archer1 is capable of wavelength-specific functionality as a voltage sensor under red light and as an inhibitory actuator under green light. As a proof-of-concept for the application of Arch-based sensors in vivo, we show fluorescence voltage sensing in behaving Caenorhabditis elegans. Archer1's characteristics contribute to the goal of all-optical detection and modulation of activity in neuronal networks in vivo.},
  copyright = {2014 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  langid = {english},
  keywords = {Biochemistry,Neuronal physiology},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Flytzanis et al_2014_Archaerhodopsin variants with enhanced voltage-sensitive fluorescence in.pdf}
}

@article{fourcaud-trocme03,
  title = {How {{Spike Generation Mechanisms Determine}} the {{Neuronal Response}} to {{Fluctuating Inputs}}},
  author = {{Fourcaud-Trocm{\'e}}, Nicolas and Hansel, David and Van Vreeswijk, Carl and Brunel, Nicolas},
  year = {2003},
  month = dec,
  journal = {Journal of Neuroscience},
  volume = {23},
  number = {37},
  pages = {11628--11640},
  publisher = {{Society for Neuroscience}},
  issn = {02706474},
  doi = {10.1523/jneurosci.23-37-11628.2003},
  abstract = {This study examines the ability of neurons to track temporally varying inputs, namely by investigating how the instantaneous firing rate of a neuron is modulated by a noisy input with a small sinusoidal component with frequency (f). Using numerical simulations of conductance-based neurons and analytical calculations of one-variable nonlinear integrate-and-fire neurons, we characterized the dependence of this modulation on f. For sufficiently high noise, the neuron acts as a low-pass filter. The modulation amplitude is approximately constant for frequencies up to a cutoff frequency, fc, after which it decays. The cutoff frequency increases almost linearly with the firing rate. For higher frequencies, the modulation amplitude decays as C/f {$\alpha$}, where the power {$\alpha$} depends on the spike initiation mechanism. For conductance-based models, {$\alpha$} = 1, and the prefactor C depends solely on the average firing rate and a spike "slope factor," which determines the sharpness of the spike initiation. These results are attributable to the fact that near threshold, the sodium activation variable can be approximated by an exponential function. Using this feature, we propose a simplified one-variable model, the "exponential integrate-and-fire neuron," as an approximation of a conductance-based model. We show that this model reproduces the dynamics of a simple conductance-based model extremely well. Our study shows how an intrinsic neuronal property (the characteristics of fast sodium channels) determines the speed with which neurons can track changes in input.},
  pmid = {14684865},
  keywords = {Conductance-based model,Dynamics,Integrate-and-fire model,Noise,Populations of spiking neurons,Sodium channel},
  file = {C\:\\Users\\johns\\Zotero\\storage\\GM7FYWV2\\Fourcaud-Trocmé et al_2003_How Spike Generation Mechanisms Determine the Neuronal Response to Fluctuating.pdf}
}

@article{foutz12,
  title = {Theoretical Principles Underlying Optical Stimulation of a Channelrhodopsin-2 Positive Pyramidal Neuron},
  author = {Foutz, Thomas J and Arlow, Richard L and Mcintyre, Cameron C},
  year = {2012},
  journal = {J Neurophysiol},
  volume = {107},
  pages = {3235--3245},
  doi = {10.1152/jn.00501.2011.-Optogenetics},
  abstract = {Foutz TJ, Arlow RL, McIntyre CC. Theoretical principles underlying optical stimulation of a channelrhodopsin-2 positive pyrami-dal neuron.},
  file = {C\:\\Users\\johns\\Zotero\\storage\\X6KWRMAN\\Foutz et al_2012_Theoretical principles underlying optical stimulation of a channelrhodopsin-2.pdf}
}

@article{gallego17,
  title = {Neural {{Manifolds}} for the {{Control}} of {{Movement}}.},
  author = {Gallego, Juan A and Perich, Matthew G and Miller, Lee E and Solla, Sara A},
  year = {2017},
  month = jun,
  journal = {Neuron},
  volume = {94},
  number = {5},
  pages = {978--984},
  publisher = {{Elsevier}},
  issn = {1097-4199},
  doi = {10.1016/j.neuron.2017.05.025},
  abstract = {The analysis of neural dynamics in several brain cortices has consistently uncovered low-dimensional manifolds that capture a significant fraction of neural variability. These neural manifolds are spanned by specific patterns of correlated neural activity, the "neural modes." We discuss a model for neural control of movement in which the time-dependent activation of these neural modes is the generator of motor behavior. This manifold-based view of motor cortex may lead to a better understanding of how the brain controls movement.},
  pmid = {28595054},
  file = {C\:\\Users\\johns\\Zotero\\storage\\E3TPC74U\\Gallego et al_2017_Neural Manifolds for the Control of Movement.pdf}
}

@article{gao17,
  title = {A Theory of Multineuronal Dimensionality, Dynamics and Measurement},
  author = {Gao, Peiran and Trautmann, Eric and Yu, Byron and Santhanam, Gopal and Ryu, Stephen and Shenoy, Krishna and Ganguli, Surya},
  year = {2017},
  month = nov,
  journal = {bioRxiv},
  pages = {214262},
  publisher = {{bioRxiv}},
  issn = {2692-8205},
  doi = {10.1101/214262},
  abstract = {In many experiments, neuroscientists tightly control behavior, record many trials, and obtain trial-averaged firing rates from hundreds of neurons in circuits containing billions of behaviorally relevant neurons. Di-mensionality reduction methods reveal a striking simplicity underlying such multi-neuronal data: they can be reduced to a low-dimensional space, and the resulting neural trajectories in this space yield a remarkably insightful dynamical portrait of circuit computation. This simplicity raises profound and timely conceptual questions. What are its origins and its implications for the complexity of neural dynamics? How would the situation change if we recorded more neurons? When, if at all, can we trust dynamical portraits obtained from measuring an infinitesimal fraction of task relevant neurons? We present a theory that answers these questions, and test it using physiological recordings from reaching monkeys. This theory reveals conceptual insights into how task complexity governs both neural dimensionality and accurate recovery of dynamic portraits, thereby providing quantitative guidelines for future large-scale experimental design.},
  keywords = {artificial intelligence,bioinformatics,computation,computer science,curse of dimensionality,dimensionality reduction,infinitesimal,machine learning}
}

@article{gerkin19,
  title = {{{NeuronUnit}}: {{A}} Package for Data-Driven Validation of Neuron Models Using {{SciUnit}}},
  author = {Gerkin, Richard C. and Birgiolas, Justas and Jarvis, Russell J. and Omar, Cyrus and Crook, Sharon M.},
  year = {2019},
  month = jun,
  journal = {bioRxiv},
  pages = {665331},
  publisher = {{Cold Spring Harbor Laboratory}},
  doi = {10.1101/665331},
  abstract = {Validating a quantitative scientific model requires comparing its predictions against many experimental observations, ideally from many labs, using transparent, robust, statistical comparisons. Unfortunately, in rapidly-growing fields like neuroscience, this is becoming increasingly untenable, even for the most conscientious scientists. Thus the merits and limitations of existing models, or whether a new model is an improvement on the state-of-the-art, is often unclear. Software engineers seeking to verify, validate and contribute to a complex software project rely on suites of simple executable tests, called ``unit tests''. Drawing inspiration from this practice, we previously developed SciUnit , an easy-to-use framework for developing data-driven ``model validation tests'' \textendash{} executable functions, here written in Python. Each such test generates and statistically validates predictions from a model against one relevant feature of empirical data to produce a score indicating agreement between the model and the data. Suites of such validation tests can be used to clearly identify the merits and limitations of existing models and developmental progress on new models. Here we describe NeuronUnit , a library that builds upon SciUnit and integrates with several existing neuroinformatics resources to support the validation of single-neuron models using data gathered by neurophysiologists and neuroanatomists. NeuronUnit integrates with existing technologies like Jupyter, Pandas, NeuroML and resources such as NeuroElectro, The Allen Institute, and The Human Brain Project in order to make neuron model validation as easy as possible for computational neuroscientists.},
  keywords = {Electrophysiology,Modeling,Neuroinformatics,Simulation,Software,Validation},
  file = {C\:\\Users\\johns\\Zotero\\storage\\FPGI37LB\\Gerkin et al_2019_NeuronUnit.pdf}
}

@book{gerstner14,
  title = {Neuronal Dynamics: {{From}} Single Neurons to Networks and Models of Cognition},
  author = {Gerstner, Wulfram and Kistler, Werner M. and Naud, Richard and Paninski, Liam},
  year = {2014},
  journal = {Neuronal Dynamics: From Single Neurons to Networks and Models of Cognition},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/CBO9781107447615},
  abstract = {What happens in our brain when we make a decision? What triggers a neuron to send out a signal? What is the neural code? This textbook for advanced undergraduate and beginning graduate students provides a thorough and up-to-date introduction to the fields of computational and theoretical neuroscience. It covers classical topics, including the Hodgkin-Huxley equations and Hopfield model, as well as modern developments in the field such as Generalized Linear Models and decision theory. Concepts are introduced using clear step-by-step explanations suitable for readers with only a basic knowledge of differential equations and probabilities, and are richly illustrated by figures and worked-out examples. End-of-chapter summaries and classroom-tested exercises make the book ideal for courses or for self-study. The authors also give pointers to the literature and an extensive bibliography, which will prove invaluable to readers interested in further study.},
  isbn = {978-1-107-44761-5}
}

@article{gewaltig07,
  title = {{{NEST}} ({{NEural Simulation Tool}})},
  author = {Gewaltig, Marc-Oliver and Diesmann, Markus},
  year = {2007},
  month = apr,
  journal = {Scholarpedia},
  volume = {2},
  number = {4},
  pages = {1430},
  issn = {1941-6016},
  doi = {10.4249/scholarpedia.1430},
  langid = {english}
}

@article{gobel07,
  title = {In {{Vivo Calcium Imaging}} of {{Neural Network Function}}},
  author = {G{\"o}bel, Werner and Helmchen, Fritjof},
  year = {2007},
  month = dec,
  journal = {Physiology},
  volume = {22},
  number = {6},
  pages = {358--365},
  publisher = {{American Physiological Society}},
  issn = {1548-9213},
  doi = {10.1152/physiol.00032.2007},
  abstract = {Spatiotemporal activity patterns in local neural networks are fundamental to brain function. Network activity can now be measured in vivo using two-photon imaging of cell populations that are labeled with fluorescent calcium indicators. In this review, we discuss basic aspects of in vivo calcium imaging and highlight recent developments that will help to uncover operating principles of neural circuits.},
  file = {C\:\\Users\\johns\\Zotero\\storage\\758YQ4QY\\Göbel_Helmchen_2007_In Vivo Calcium Imaging of Neural Network Function.pdf}
}

@article{govorunova15,
  title = {Natural Light-Gated Anion Channels: {{A}} Family of Microbial Rhodopsins for Advanced Optogenetics},
  author = {Govorunova, Elena G. and Sineshchekov, Oleg A. and Janz, Roger and Liu, Xiaoqin and Spudich, John L.},
  year = {2015},
  month = aug,
  journal = {Science},
  volume = {349},
  number = {6248},
  pages = {647--650},
  publisher = {{American Association for the Advancement of Science}},
  issn = {10959203},
  doi = {10.1126/science.aaa7484},
  abstract = {Light-gated rhodopsin cation channels from chlorophyte algae have transformed neuroscience research through their use as membrane-depolarizing optogenetic tools for targeted photoactivation of neuron firing. Photosuppression of neuronal action potentials has been limited by the lack of equally efficient tools for membrane hyperpolarization. We describe anion channel rhodopsins (ACRs), a family of light-gated anion channels from cryptophyte algae that provide highly sensitive and efficient membrane hyperpolarization and neuronal silencing through light-gated chloride conduction. ACRs strictly conducted anions, completely excluding protons and larger cations, and hyperpolarized the membrane of cultured animal cells with much faster kinetics at less than one-thousandth of the light intensity required by the most efficient currently available optogenetic proteins. Natural ACRs provide optogenetic inhibition tools with unprecedented light sensitivity and temporal precision.},
  pmid = {26113638},
  file = {C\:\\Users\\johns\\Zotero\\storage\\BXAMRCCH\\Govorunova et al_2015_Natural light-gated anion channels.pdf}
}

@article{govorunova17,
  title = {The {{Expanding Family}} of {{Natural Anion Channelrhodopsins Reveals Large Variations}} in {{Kinetics}}, {{Conductance}}, and {{Spectral Sensitivity}}},
  author = {Govorunova, Elena G. and Sineshchekov, Oleg A. and Rodarte, Elsa M. and Janz, Roger and Morelle, Olivier and Melkonian, Michael and Wong, Gane K.S. and Spudich, John L.},
  year = {2017},
  month = mar,
  journal = {Scientific Reports},
  volume = {7},
  number = {1},
  pages = {1--10},
  publisher = {{Nature Publishing Group}},
  issn = {20452322},
  doi = {10.1038/srep43358},
  abstract = {Natural anion channelrhodopsins (ACRs) discovered in the cryptophyte alga Guillardia theta generate large hyperpolarizing currents at membrane potentials above the Nernst equilibrium potential for Cl- and thus can be used as efficient inhibitory tools for optogenetics. We have identified and characterized new ACR homologs in different cryptophyte species, showing that all of them are anion-selective, and thus expanded this protein family to 20 functionally confirmed members. Sequence comparison of natural ACRs and engineered Cl- conducting mutants of cation channelrhodopsins (CCRs) showed radical differences in their anion selectivity filters. In particular, the Glu90 residue in channelrhodopsin 2, which needed to be mutated to a neutral or alkaline residue to confer anion selectivity to CCRs, is nevertheless conserved in all of the ACRs identified. The new ACRs showed a large variation of the amplitude, kinetics, and spectral sensitivity of their photocurrents. A notable variant, designated "ZipACR", is particularly promising for inhibitory optogenetics because of its combination of larger current amplitudes than those of previously reported ACRs and an unprecedentedly fast conductance cycle (current half-decay time 2-4 ms depending on voltage). ZipACR expressed in cultured mouse hippocampal neurons enabled precise photoinhibition of individual spikes in trains of up to 50 Hz frequency.},
  isbn = {0021218439},
  pmid = {28256618},
  keywords = {Membrane proteins,Neuroscience},
  file = {C\:\\Users\\johns\\Zotero\\storage\\VTL97C7Y\\Govorunova et al_2017_The Expanding Family of Natural Anion Channelrhodopsins Reveals Large.pdf}
}

@article{gradinaru10,
  title = {Molecular and {{Cellular Approaches}} for {{Diversifying}} and {{Extending Optogenetics}}},
  author = {Gradinaru, Viviana and Zhang, Feng and Ramakrishnan, Charu and Mattis, Joanna and Prakash, Rohit and Diester, Ilka and Goshen, Inbal and Thompson, Kimberly R. and Deisseroth, Karl},
  year = {2010},
  month = apr,
  journal = {Cell},
  volume = {141},
  number = {1},
  pages = {154--165},
  issn = {0092-8674},
  doi = {10.1016/j.cell.2010.02.037},
  abstract = {Optogenetic technologies employ light to control biological processes within targeted cells in~vivo with high temporal precision. Here, we show that application of molecular trafficking principles can expand the optogenetic repertoire along several long-sought dimensions. Subcellular and transcellular trafficking strategies now permit (1) optical regulation at the far-red/infrared border and extension of optogenetic control across the entire visible spectrum, (2) increased potency of optical inhibition without increased light power requirement (nanoampere-scale chloride-mediated photocurrents that maintain the light sensitivity and reversible, step-like kinetic stability of earlier tools), and (3) generalizable strategies for targeting cells based not only on genetic identity, but also on morphology and tissue topology, to allow versatile targeting when promoters are not known or in genetically intractable organisms. Together, these results illustrate use of cell-biological principles to enable expansion of the versatile fast optogenetic technologies suitable for intact-systems biology and behavior.},
  langid = {english},
  keywords = {MOLNEURO,SYSNEURO},
  file = {C\:\\Users\\johns\\Zotero\\storage\\R8RZ2Q2R\\Gradinaru et al_2010_Molecular and Cellular Approaches for Diversifying and Extending Optogenetics.pdf}
}

@article{gratiy18,
  title = {{{BioNet}}: {{A Python}} Interface to {{NEURON}} for Modeling Large-Scale Networks},
  author = {Gratiy, Sergey L. and Billeh, Yazan N. and Dai, Kael and Mitelut, Catalin and Feng, David and Gouwens, Nathan W. and Cain, Nicholas and Koch, Christof and Anastassiou, Costas A. and Arkhipov, Anton},
  year = {2018},
  month = aug,
  journal = {PLoS ONE},
  volume = {13},
  number = {8},
  pages = {e0201630},
  publisher = {{Public Library of Science}},
  issn = {19326203},
  doi = {10.1371/journal.pone.0201630},
  abstract = {There is a significant interest in the neuroscience community in the development of large-scale network models that would integrate diverse sets of experimental data to help elucidate mechanisms underlying neuronal activity and computations. Although powerful numerical simulators (e.g., NEURON, NEST) exist, data-driven large-scale modeling remains challenging due to difficulties involved in setting up and running network simulations. We developed a high-level application programming interface (API) in Python that facilitates building large-scale biophysically detailed networks and simulating them with NEURON on parallel computer architecture. This tool, termed ``BioNet'', is designed to support a modular workflow whereby the description of a constructed model is saved as files that could be subsequently loaded for further refinement and/or simulation. The API supports both NEURON's built-in as well as user-defined models of cells and synapses. It is capable of simulating a variety of observables directly supported by NEURON (e.g., spikes, membrane voltage, intracellular [Ca++]), as well as plugging in modules for computing additional observables (e.g. extracellular potential). The high-level API platform obviates the time-consuming development of custom code for implementing individual models, and enables easy model sharing via standardized files. This tool will help refocus neuroscientists on addressing outstanding scientific questions rather than developing narrow-purpose modeling code.},
  pmid = {30071069},
  keywords = {Biophysical simulations,Biophysics,Electrode potentials,Membrane potential,Network analysis,Neural networks,Neurons,Simulation and modeling},
  file = {C\:\\Users\\johns\\Zotero\\storage\\9YEQUKYM\\Gratiy et al_2018_BioNet.pdf}
}

@article{grosenick15,
  title = {Review {{Closed-Loop}} and {{Activity-Guided Optogenetic Control}}},
  author = {Grosenick, Logan and Marshel, James H and Deisseroth, Karl},
  year = {2015},
  journal = {Neuron},
  volume = {86},
  pages = {106--139},
  doi = {10.1016/j.neuron.2015.03.034},
  file = {C\:\\Users\\johns\\Zotero\\storage\\TIQ5QBBW\\Grosenick et al_2015_Review Closed-Loop and Activity-Guided Optogenetic Control.pdf}
}

@article{gunaydin10,
  title = {Ultrafast Optogenetic Control},
  author = {Gunaydin, Lisa A. and Yizhar, Ofer and Berndt, Andr{\'e} and Sohal, Vikaas S. and Deisseroth, Karl and Hegemann, Peter},
  year = {2010},
  month = mar,
  journal = {Nature Neuroscience},
  volume = {13},
  number = {3},
  pages = {387--392},
  publisher = {{Nature Publishing Group}},
  issn = {10976256},
  doi = {10.1038/nn.2495},
  abstract = {Channelrhodopsins such as channelrhodopsin-2 (ChR2) can drive spiking with millisecond precision in a wide variety of cells, tissues and animal species. However, several properties of this protein have limited the precision of optogenetic control. First, when ChR2 is expressed at high levels, extra spikes (for example, doublets) can occur in response to a single light pulse, with potential implications as doublets may be important for neural coding. Second, many cells cannot follow ChR2-driven spiking above the gamma ({$\sim$}40 Hz) range in sustained trains, preventing temporally stationary optogenetic access to a broad and important neural signaling band. Finally, rapid optically driven spike trains can result in plateau potentials of 10 mV or more, causing incidental upstates with information-processing implications. We designed and validated an engineered opsin gene (ChETA) that addresses all of these limitations (profoundly reducing extra spikes, eliminating plateau potentials and allowing temporally stationary, sustained spike trains up to at least 200 Hz). \textcopyright{} 2010 Nature America, Inc. All rights reserved.},
  pmid = {20081849},
  keywords = {Neuronal development,Optogenetics},
  file = {C\:\\Users\\johns\\Zotero\\storage\\67XFWS3U\\Gunaydin et al_2010_Ultrafast optogenetic control.pdf}
}

@article{gupta19a,
  title = {Theoretical Optimization of High-Frequency Optogenetic Spiking of Red-Shifted Very Fast-{{Chrimson-expressing}} Neurons},
  author = {Gupta, Neha and Bansal, Himanshu and Roy, Sukhdev},
  year = {2019},
  month = apr,
  journal = {Neurophotonics},
  volume = {6},
  number = {02},
  pages = {1},
  publisher = {{SPIE}},
  issn = {23294248},
  doi = {10.1117/1.nph.6.2.025002},
  abstract = {A detailed theoretical analysis and optimization of high-fidelity, high-frequency firing of the red-shifted very-fast-Chrimson (vf-Chrimson) expressing neurons is presented. A four-state model for vf-Chrimson photocycle has been formulated and incorporated in Hodgkin-Huxley and Wang-Buzsaki spiking neuron circuit models. The effect of various parameters that include irradiance, pulse width, frequency, expression level, and membrane capacitance has been studied in detail. Theoretical simulations are in excellent agreement with recently reported experimental results. The analysis and optimization bring out additional interesting features. A minimal pulse width of 1.7 ms at 23 mW/mm2 induces a peak photocurrent of 1250 pA. Optimal irradiance (0.1 mW/mm2) and pulse width (50 us) to trigger action potential have been determined. At frequencies beyond 200 Hz, higher values of expression level and irradiance result in spike failure. Singlet and doublet spiking fidelity can be maintained up to 400 and 150 Hz, respectively. The combination of expression level and membrane capacitance is a crucial factor to achieve high-frequency firing above 500 Hz. Its optimization enables 100\% spike probability of up to 1 kHz. The study is useful in designing new high-frequency optogenetic neural spiking experiments with desired spatiotemporal resolution, by providing insights into the temporal spike coding, plasticity, and curing neurodegenerative diseases.},
  keywords = {Action potentials,Brain,Capacitance,Circuit switching,Molecules,Neurons,Neurophotonics,Optogenetics,Photons,Sodium},
  file = {C\:\\Users\\johns\\Zotero\\storage\\34USTWJ6\\Gupta et al_2019_Theoretical optimization of high-frequency optogenetic spiking of red-shifted.pdf}
}

@article{gutruf18,
  title = {Implantable, Wireless Device Platforms for Neuroscience Research},
  author = {Gutruf, Philipp and Rogers, John A},
  year = {2018},
  month = jun,
  journal = {Current Opinion in Neurobiology},
  series = {Neurotechnologies},
  volume = {50},
  pages = {42--49},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2017.12.007},
  abstract = {Recently developed classes of ultraminiaturized wireless devices provide powerful capabilities in neuroscience research, as implantable light sources for simulation/inhibition via optogenetics, as integrated microfluidic systems for programmed pharmacological delivery and as multimodal sensors for physiological measurements. These platforms leverage basic advances in biocompatible materials, semiconductor device designs and systems engineering concepts to afford modes of operation that are qualitatively distinct from those of conventional approaches that tether animals to external hardware by means of optical fibers, electrical cables and/or fluidic tubing. Neuroscience studies that exploit the unique features of these technologies enable insights into neural function through targeted stimulation, inhibition and recording, with spatially and genetically precise manipulation of neural circuit activity. Experimental possibilities include studies in naturalistic, three dimensional environments, investigations of pair-wise or group related social interactions and many other scenarios of interest that cannot be addressed using traditional hardware.},
  langid = {english}
}

@article{gutzen18,
  title = {Reproducible Neural Network Simulations: {{Statistical}} Methods for Model Validation on the Level of Network Activity Data},
  author = {Gutzen, Robin and {von Papen}, Michael and Trensch, Guido and Quaglio, Pietro and Gr{\"u}n, Sonja and Denker, Michael},
  year = {2018},
  month = dec,
  journal = {Frontiers in Neuroinformatics},
  volume = {12},
  pages = {90},
  publisher = {{Frontiers Media S.A.}},
  issn = {16625196},
  doi = {10.3389/fninf.2018.00090},
  abstract = {Computational neuroscience relies on simulations of neural network models to bridge the gap between the theory of neural networks and the experimentally observed activity dynamics in the brain. The rigorous validation of simulation results against reference data is thus an indispensable part of any simulation workflow. Moreover, the availability of different simulation environments and levels of model description require also validation of model implementations against each other to evaluate their equivalence. Despite rapid advances in the formalized description of models, data, and analysis workflows, there is no accepted consensus regarding the terminology and practical implementation of validation workflows in the context of neural simulations. This situation prevents the generic, unbiased comparison between published models, which is a key element of enhancing reproducibility of computational research in neuroscience. In this study, we argue for the establishment of standardized statistical test metrics that enable the quantitative validation of network models on the level of the population dynamics. Despite the importance of validating the elementary components of a simulation, such as single cell dynamics, building networks from validated building blocks does not entail the validity of the simulation on the network scale. Therefore, we introduce a corresponding set of validation tests and present an example workflow that practically demonstrates the iterative model validation of a spiking neural network model against its reproduction on the SpiNNaker neuromorphic hardware system. We formally implement the workflow using a generic Python library that we introduce for validation tests on neural network activity data. Together with the companion study (Trensch et al., 2018), the work presents a consistent definition, formalization, and implementation of the verification and validation process for neural network simulations.},
  keywords = {Reproducibility,Simulation,Spiking neural network,SpiNNaker,Statistical analysis,Validation},
  file = {C\:\\Users\\johns\\Zotero\\storage\\L3DN6JKD\\full-text.pdf}
}

@article{gysbrechts16,
  title = {Light Distribution and Thermal Effects in the Rat Brain under Optogenetic Stimulation},
  author = {Gysbrechts, Barbara and Wang, Ling and Trong, Nghia Nguyen Do and Cabral, Henrique and Navratilova, Zaneta and Battaglia, Francesco and Saeys, Wouter and Bartic, Carmen},
  year = {2016},
  month = jun,
  journal = {Journal of Biophotonics},
  volume = {9},
  number = {6},
  pages = {576--585},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {18640648},
  doi = {10.1002/jbio.201500106},
  abstract = {Optical brain stimulation gained a lot of attention in neuroscience due to its superior cell-type specificity. In the design of illumination strategies, predicting the light propagation in a specific tissue is essential and requires knowledge of the optical properties of that tissue. We present the estimated absorption and reduced scattering in rodent brain tissue using non-destructive contact spatially resolved spectroscopy (cSRS). The obtained absorption and scattering in the cortex, hippocampus and striatum are similar, but lower than in the thalamus, leading to a less deep but broader light penetration profile in the thalamus. Next, the light distribution was investigated for different stimulation protocols relevant for fiber-optic based optogenetic experiments, using Monte Carlo simulation. A protocol specific analysis is proposed to evaluate the potential of thermally induced side effects.},
  pmid = {26192551},
  keywords = {Light propagation in tissues,Optogenetics,Photothermal effects,Spectroscopy,Tissue characterization}
}

@article{hagen16,
  title = {Hybrid Scheme for Modeling Local Field Potentials from Point-Neuron Networks},
  author = {Hagen, Espen and Dahmen, David and Stavrinou, Maria L. and Lind{\'e}n, Henrik and Tetzlaff, Tom and Van Albada, Sacha J. and Gr{\"u}n, Sonja and Diesmann, Markus and Einevoll, Gaute T.},
  year = {2016},
  month = dec,
  journal = {Cerebral Cortex},
  volume = {26},
  number = {12},
  eprint = {1511.01681},
  eprinttype = {arxiv},
  pages = {4461--4496},
  publisher = {{Oxford University Press}},
  issn = {14602199},
  doi = {10.1093/cercor/bhw237},
  abstract = {With rapidly advancing multi-electrode recording technology, the local field potential (LFP) has again become a popular measure of neuronal activity in both research and clinical applications. Proper understanding of the LFP requires detailed mathematical modeling incorporating the anatomical and electrophysiological features of neurons near the recording electrode, as well as synaptic inputs from the entire network. Here we propose a hybrid modeling scheme combining efficient point-neuron network models with biophysical principles underlying LFP generation by real neurons. The LFP predictions rely on populations of network-equivalent multicompartment neuron models with layer-specific synaptic connectivity, can be used with an arbitrary number of point-neuron network populations, and allows for a full separation of simulated network dynamics and LFPs. We apply the scheme to a full-scale cortical network model for a {$\sim$}1mm2 patch of primary visual cortex, predict laminar LFPs for different network states, assess the relative LFP contribution from different laminar populations, and investigate effects of input correlations and neuron density on the LFP. The generic nature of the hybrid scheme and its public implementation in hybridLFPy form the basis for LFP predictions from other and larger pointneuron network models, as well as extensions of the current application with additional biological detail.},
  archiveprefix = {arXiv},
  pmid = {27797828},
  keywords = {Cortical microcircuit,Electrostatic forward modeling,Extracellular potential,Multicompartment neuron modeling,Point-neuron network models},
  file = {C\:\\Users\\johns\\Zotero\\storage\\NFV587EH\\Hagen et al_2016_Hybrid scheme for modeling local field potentials from point-neuron networks.pdf}
}

@article{hagen18,
  title = {Multimodal Modeling of Neural Network Activity: {{Computing LFP}}, {{ECoG}}, {{EEG}}, and {{MEG}} Signals with {{LFPy}} 2.0},
  author = {Hagen, Espen and N{\ae}ss, Solveig and Ness, Torbj{\o}rn V. and Einevoll, Gaute T.},
  year = {2018},
  month = dec,
  journal = {Frontiers in Neuroinformatics},
  volume = {12},
  pages = {92},
  publisher = {{Frontiers Media S.A.}},
  issn = {16625196},
  doi = {10.3389/fninf.2018.00092},
  abstract = {Recordings of extracellular electrical, and later also magnetic, brain signals have been the dominant technique for measuring brain activity for decades. The interpretation of such signals is however nontrivial, as the measured signals result from both local and distant neuronal activity. In volume-conductor theory the extracellular potentials can be calculated from a distance-weighted sum of contributions from transmembrane currents of neurons. Given the same transmembrane currents, the contributions to the magnetic field recorded both inside and outside the brain can also be computed. This allows for the development of computational tools implementing forward models grounded in the biophysics underlying electrical and magnetic measurement modalities. LFPy (LFPy.readthedocs.io) incorporated a well-established scheme for predicting extracellular potentials of individual neurons with arbitrary levels of biological detail. It relies on NEURON (neuron.yale.edu) to compute transmembrane currents of multicompartment neurons which is then used in combination with an electrostatic forward model. Its functionality is now extended to allow for modeling of networks of multicompartment neurons with concurrent calculations of extracellular potentials and current dipole moments. The current dipole moments are then, in combination with suitable volume-conductor head models, used to compute non-invasive measures of neuronal activity, like scalp potentials (electroencephalographic recordings; EEG) and magnetic fields outside the head (magnetoencephalographic recordings; MEG). One such built-in head model is the four-sphere head model incorporating the different electric conductivities of brain, cerebrospinal fluid, skull and scalp. We demonstrate the new functionality of the software by constructing a network of biophysically detailed multicompartment neuron models from the Neocortical Microcircuit Collaboration (NMC) Portal (bbp.epfl.ch/nmc-portal) with corresponding statistics of connections and synapses, and compute in vivo-like extracellular potentials (local field potentials, LFP; electrocorticographical signals, ECoG) and corresponding current dipole moments. From the current dipole moments we estimate corresponding EEG and MEG signals using the four-sphere head model. We also show strong scaling performance of LFPy with different numbers of message-passing interface (MPI) processes, and for different network sizes with different density of connections. The open-source software LFPy is equally suitable for execution on laptops and in parallel on high-performance computing (HPC) facilities and is publicly available on GitHub.com.},
  keywords = {ECoG,EEG,LFP,Local field potential,MEG,Modeling,Neuron,Neuronal network},
  file = {C\:\\Users\\johns\\Zotero\\storage\\N54CCXRJ\\full-text.pdf}
}

@article{hasani22,
  title = {Closed-Form Continuous-Time Neural Networks},
  author = {Hasani, Ramin and Lechner, Mathias and Amini, Alexander and Liebenwein, Lucas and Ray, Aaron and Tschaikowski, Max and Teschl, Gerald and Rus, Daniela},
  year = {2022},
  month = nov,
  journal = {Nature Machine Intelligence},
  volume = {4},
  number = {11},
  pages = {992--1003},
  publisher = {{Nature Publishing Group}},
  issn = {2522-5839},
  doi = {10.1038/s42256-022-00556-7},
  abstract = {Continuous-time neural networks are a class of machine learning systems that can tackle representation learning on spatiotemporal decision-making tasks. These models are typically represented by continuous differential equations. However, their expressive power when they are deployed on computers is bottlenecked by numerical differential equation solvers. This limitation has notably slowed down the scaling and understanding of numerous natural physical phenomena such as the dynamics of nervous systems. Ideally, we would circumvent this bottleneck by solving the given dynamical system in closed form. This is known to be intractable in general. Here, we show that it is possible to closely approximate the interaction between neurons and synapses\textemdash the building blocks of natural and artificial neural networks\textemdash constructed by liquid time-constant networks efficiently in closed form. To this end, we compute a tightly bounded approximation of the solution of an integral appearing in liquid time-constant dynamics that has had no known closed-form solution so far. This closed-form solution impacts the design of continuous-time and continuous-depth neural models. For instance, since time appears explicitly in closed form, the formulation relaxes the need for complex numerical solvers. Consequently, we obtain models that are between one and five orders of magnitude faster in training and inference compared with differential equation-based counterparts. More importantly, in contrast to ordinary differential equation-based continuous networks, closed-form networks can scale remarkably well compared with other deep learning instances. Lastly, as these models are derived from liquid networks, they show good performance in time-series modelling compared with advanced recurrent neural network models.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Computer science,Software,Statistics},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Hasani et al_2022_Closed-form continuous-time neural networks.pdf}
}

@article{hines97,
  title = {The {{NEURON Simulation Environment}}},
  author = {Hines, M. L. and Carnevale, N. T.},
  year = {1997},
  month = aug,
  journal = {Neural Computation},
  volume = {9},
  number = {6},
  pages = {1179--1209},
  issn = {0899-7667},
  doi = {10.1162/neco.1997.9.6.1179},
  abstract = {The moment-to-moment processing of information by the nervous system involves the propagation and interaction of electrical and chemical signals that are distributed in space and time. Biologically realistic modeling is needed to test hypotheses about the mechanisms that govern these signals and how nervous system function emerges from the operation of these mechanisms. The NEURON simulation program provides a powerful and flexible environment for implementing such models of individual neurons and small networks of neurons. It is particularly useful when membrane potential is nonuniform and membrane currents are complex. We present the basic ideas that would help informed users make the most efficient use of NEURON.}
}

@article{hochbaum14,
  title = {All-Optical Electrophysiology in Mammalian Neurons Using Engineered Microbial Rhodopsins},
  author = {Hochbaum, Daniel R. and Zhao, Yongxin and Farhi, Samouil L. and Klapoetke, Nathan and Werley, Christopher A. and Kapoor, Vikrant and Zou, Peng and Kralj, Joel M. and MacLaurin, Dougal and {Smedemark-Margulies}, Niklas and Saulnier, Jessica L. and Boulting, Gabriella L. and Straub, Christoph and Cho, Yong Ku and Melkonian, Michael and Wong, Gane Ka Shu and Harrison, D. Jed and Murthy, Venkatesh N. and Sabatini, Bernardo L. and Boyden, Edward S. and Campbell, Robert E. and Cohen, Adam E.},
  year = {2014},
  month = jun,
  journal = {Nature Methods},
  volume = {11},
  number = {8},
  pages = {825--833},
  publisher = {{Nature Publishing Group}},
  issn = {15487105},
  doi = {10.1038/NMETH.3000},
  abstract = {All-optical electrophysiology-spatially resolved simultaneous optical perturbation and measurement of membrane voltage-would open new vistas in neuroscience research. We evolved two archaerhodopsin-based voltage indicators, QuasAr1 and QuasAr2, which show improved brightness and voltage sensitivity, have microsecond response times and produce no photocurrent. We engineered a channelrhodopsin actuator, cheriff, which shows high light sensitivity and rapid kinetics and is spectrally orthogonal to the QuasArs. A coexpression vector, optopatch, enabled cross-talk-free genetically targeted all-optical electrophysiology. in cultured rat neurons, we combined optopatch with patterned optical excitation to probe back-propagating action potentials (APs) in dendritic spines, synaptic transmission, subcellular microsecond-timescale details of AP propagation, and simultaneous fring of many neurons in a network. optopatch measurements revealed homeostatic tuning of intrinsic excitability in human stem cell-derived neurons. in rat brain slices, optopatch induced and reported APs and subthreshold events with high signal-to-noise ratios. the optopatch platform enables high-throughput, spatially resolved electrophysiology without the use of conventional electrodes. \textcopyright{} 2014 Nature America, Inc. All rights reserved.},
  pmid = {24952910},
  keywords = {Fluorescence imaging,Fluorescent proteins,Optogenetics},
  file = {C\:\\Users\\johns\\Zotero\\storage\\NRCHJFBH\\Hochbaum et al_2014_All-optical electrophysiology in mammalian neurons using engineered microbial.pdf}
}

@article{hodgkin52,
  title = {A Quantitative Description of Membrane Current and Its Application to Conduction and Excitation in Nerve},
  author = {Hodgkin, A. L. and Huxley, A. F.},
  year = {1952},
  month = aug,
  journal = {The Journal of Physiology},
  volume = {117},
  number = {4},
  pages = {500--544},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {14697793},
  doi = {10.1113/jphysiol.1952.sp004764},
  pmid = {12991237}
}

@article{hodgkin52a,
  title = {Measurement of Current-Voltage Relations in the Membrane of the Giant Axon of {{Loligo}}},
  author = {Hodgkin, A. L. and Huxley, A. F. and Katz, B.},
  year = {1952},
  month = apr,
  journal = {The Journal of Physiology},
  volume = {116},
  number = {4},
  pages = {424--448},
  issn = {0022-3751},
  abstract = {Images null},
  pmcid = {PMC1392219},
  pmid = {14946712},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Hodgkin et al_1952_Measurement of current-voltage relations in the membrane of the giant axon of.pdf}
}

@article{holt99,
  title = {Electrical Interactions via the Extracellular Potential near Cell Bodies},
  author = {Holt, Gary R and Koch, Christof},
  year = {1999},
  journal = {Journal of Computational Neuroscience},
  volume = {6},
  number = {2},
  pages = {169--184},
  issn = {09295313},
  doi = {10.1023/A:1008832702585},
  abstract = {Ephaptic interactions between a neuron and axons or dendrites passing by its cell body can be, in principle, more significant than ephaptic interactions among axons in a fiber tract. Extracellular action potentials outside axons are small in amplitude and spatially spread out, while they are larger in amplitude and much more spatially confined near cell bodies. We estimated the extracellular potentials associated with an action potential in a cortical pyramidal cell using standard one-dimensional cable theory and volume conductor theory. Their spatial and temporal pattern reveal much about the location and timing of currents in the cell, especially in combination with a known morphology, and simple experiments could resolve questions about spike initiation. From the extracellular potential we compute the ephaptically induced polarization in a nearby passive cable. The magnitude of this induced voltage can be several mV, does not spread electrotonically, and depends only weakly on the passive properties of the cable. We discuss their possible functional relevance.},
  pmid = {10333161},
  keywords = {Axon hillock,Branch point failure,Extracellular field potential,initial segment,Volume conduction},
  file = {C\:\\Users\\johns\\Zotero\\storage\\X37HLTZA\\Holt_Koch_1999_Electrical interactions via the extracellular potential near cell bodies.pdf}
}

@inproceedings{hong11,
  title = {Hammerstein-{{Wiener Model Predictive Control}} of {{Continuous Stirred Tank Reactor}}},
  booktitle = {Electronics and {{Signal Processing}}},
  author = {Hong, Man and Cheng, Shao},
  editor = {Hu, Wensong},
  year = {2011},
  series = {Lecture {{Notes}} in {{Electrical Engineering}}},
  pages = {235--242},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-21697-8_30},
  abstract = {A nonlinear Hammerstein-Wiener model predictive controller based on LSSVM is built to describe the dynamic characteristic of a continuous stirred tank reactor (CSTR), which is made up by a linear optimal component and radial basis function neural networks in series, using BP neural network to train the input sequences of the predictive control, solving the nonlinear predictive control laws by the quasi-Newton algorithm, and a neural network predictive control algorithm is achieved based on LSSVM Hammerstein-Wiener model. The simulation results of CSTR show that this approach is effective tracking and controlling product concentration.},
  isbn = {978-3-642-21697-8},
  langid = {english},
  keywords = {BP neural,Hammerstein-Wiener model,Least squares support vector machines,Nonlinear predictive control},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Hong_Cheng_2011_Hammerstein-Wiener Model Predictive Control of Continuous Stirred Tank Reactor.pdf}
}

@inproceedings{hurwitz21,
  title = {Targeted {{Neural Dynamical Modeling}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Hurwitz, Cole and Srivastava, Akash and Xu, Kai and Jude, Justin and Perich, Matthew G and Miller, Lee E and Hennig, Matthias H},
  year = {2021},
  volume = {35},
  eprint = {2110.14853},
  eprinttype = {arxiv},
  pages = {29379--29392},
  issn = {10495258},
  abstract = {Latent dynamics models have emerged as powerful tools for modeling and interpreting neural population activity. Recently, there has been a focus on incorporating simultaneously measured behaviour into these models to further disentangle sources of neural variability in their latent space. These approaches, however, are limited in their ability to capture the underlying neural dynamics (e.g. linear) and in their ability to relate the learned dynamics back to the observed behaviour (e.g. no time lag). To this end, we introduce Targeted Neural Dynamical Modeling (TNDM), a nonlinear state-space model that jointly models the neural activity and external behavioural variables. TNDM decomposes neural dynamics into behaviourally relevant and behaviourally irrelevant dynamics; the relevant dynamics are used to reconstruct the behaviour through a flexible linear decoder and both sets of dynamics are used to reconstruct the neural activity through a linear decoder with no time lag. We implement TNDM as a sequential variational autoencoder and validate it on simulated recordings and recordings taken from the premotor and motor cortex of a monkey performing a center-out reaching task. We show that TNDM is able to learn low-dimensional latent dynamics that are highly predictive of behaviour without sacrificing its fit to the neural data.},
  archiveprefix = {arXiv},
  isbn = {978-1-71384-539-3},
  file = {C\:\\Users\\johns\\Zotero\\storage\\7HUCUT5Q\\Hurwitz et al_2021_Targeted Neural Dynamical Modeling.pdf}
}

@article{inoue21,
  title = {Genetically Encoded Calcium Indicators to Probe Complex Brain Circuit Dynamics in Vivo},
  author = {Inoue, Masatoshi},
  year = {2021},
  month = aug,
  journal = {Neuroscience Research},
  volume = {169},
  pages = {2--8},
  issn = {0168-0102},
  doi = {10.1016/j.neures.2020.05.013},
  abstract = {Over the past two decades, genetically encoded calcium indicators (GECIs) have been used extensively to report intracellular calcium (Ca2+) dynamics in order to readout neuronal and network activity in living tissue. Single wavelength GECIs, such as GCaMP, have been widely adapted due to advances in dynamic range, sensitivity, and kinetics. Additionally, recent efforts in protein engineering have expanded the GECI color palette to enable direct optical interrogation of more complex circuit dynamics. Here, I discuss the engineering, application, and future directions of the most recently developed GECIs for in vivo neuroscience research.},
  langid = {english},
  keywords = {All-optical experiments,Calcium indicator,Genetically encoded fluorescent indicators,Multiplex imaging,Neuronal activity recording,Protein engineering,R-CaMP2,XCaMP}
}

@article{izhikevich03,
  title = {Simple Model of Spiking Neurons},
  author = {Izhikevich, Eugene M.},
  year = {2003},
  journal = {IEEE Transactions on neural networks},
  volume = {14},
  number = {6},
  pages = {1569--1572},
  publisher = {{IEEE}}
}

@article{jazayeri21,
  title = {Interpreting Neural Computations by Examining Intrinsic and Embedding Dimensionality of Neural Activity},
  author = {Jazayeri, Mehrdad and Ostojic, Srdjan},
  year = {2021},
  month = oct,
  journal = {Current Opinion in Neurobiology},
  volume = {70},
  eprint = {2107.04084},
  eprinttype = {arxiv},
  pages = {113--120},
  publisher = {{Elsevier Current Trends}},
  issn = {18736882},
  doi = {10.1016/j.conb.2021.08.002},
  abstract = {The ongoing exponential rise in recording capacity calls for new approaches for analysing and interpreting neural data. Effective dimensionality has emerged as an important property of neural activity across populations of neurons, yet different studies rely on different definitions and interpretations of this quantity. Here, we focus on intrinsic and embedding dimensionality, and discuss how they might reveal computational principles from data. Reviewing recent works, we propose that the intrinsic dimensionality reflects information about the latent variables encoded in collective activity while embedding dimensionality reveals the manner in which this information is processed. We conclude by highlighting the role of network models as an ideal substrate for testing more specifically various hypotheses on the computational principles reflected through intrinsic and embedding dimensionality.},
  archiveprefix = {arXiv},
  pmid = {34537579}
}

@article{jazayeri21a,
  title = {Interpreting Neural Computations by Examining Intrinsic and Embedding Dimensionality of Neural Activity},
  author = {Jazayeri, Mehrdad and Ostojic, Srdjan},
  year = {2021},
  month = oct,
  journal = {Current Opinion in Neurobiology},
  series = {Computational {{Neuroscience}}},
  volume = {70},
  pages = {113--120},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2021.08.002},
  abstract = {The ongoing exponential rise in recording capacity calls for new approaches for analysing and interpreting neural data. Effective dimensionality has emerged as an important property of neural activity across populations of neurons, yet different studies rely on different definitions and interpretations of this quantity. Here, we focus on intrinsic and embedding dimensionality, and discuss how they might reveal computational principles from data. Reviewing recent works, we propose that the intrinsic dimensionality reflects information about the latent variables encoded in collective activity~while embedding dimensionality reveals the manner in which this information is processed. We conclude by highlighting the role of network models as an ideal substrate for testing more specifically various hypotheses on the computational principles reflected through intrinsic and embedding dimensionality.},
  langid = {english},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Jazayeri_Ostojic_2021_Interpreting neural computations by examining intrinsic and embedding.pdf}
}

@inproceedings{jensen20,
  title = {Manifold {{GPLVMs}} for Discovering Non-{{Euclidean}} Latent Structure in Neural Data},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Jensen, Kristopher and Kao, Ta-Chu and Tripodi, Marco and Hennequin, Guillaume},
  year = {2020},
  volume = {33},
  pages = {22580--22592},
  publisher = {{Curran Associates, Inc.}},
  abstract = {A common problem in neuroscience is to elucidate the collective neural representations of behaviorally important variables such as head direction, spatial location, upcoming movements, or mental spatial transformations. Often, these latent variables are internal constructs not directly accessible to the experimenter. Here, we propose a new probabilistic latent variable model to simultaneously identify the latent state and the way each neuron contributes to its representation in an unsupervised way. In contrast to previous models which assume Euclidean latent spaces, we embrace the fact that latent states often belong to symmetric manifolds such as spheres, tori, or rotation groups of various dimensions. We therefore propose the manifold Gaussian process latent variable model (mGPLVM), where neural responses arise from (i) a shared latent variable living on a specific manifold, and (ii) a set of non-parametric tuning curves determining how each neuron contributes to the representation. Cross-validated comparisons of models with different topologies can be used to distinguish between candidate manifolds, and variational inference enables quantification of uncertainty. We demonstrate the validity of the approach on several synthetic datasets, as well as on calcium recordings from the ellipsoid body of Drosophila melanogaster and extracellular recordings from the mouse anterodorsal thalamic nucleus. These circuits are both known to encode head direction, and mGPLVM correctly recovers the ring topology expected from neural populations representing a single angular variable.},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Jensen et al_2020_Manifold GPLVMs for discovering non-Euclidean latent structure in neural data.pdf}
}

@article{jeon21,
  title = {Implantable {{Optrode Array}} for {{Optogenetic Modulation}} and {{Electrical Neural Recording}}},
  author = {Jeon, Saeyeong and Lee, Youjin and Ryu, Daeho and Cho, Yoon Kyung and Lee, Yena and Jun, Sang Beom and Ji, Chang-Hyeon},
  year = {2021},
  month = jun,
  journal = {Micromachines},
  volume = {12},
  number = {6},
  pages = {725},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2072-666X},
  doi = {10.3390/mi12060725},
  abstract = {During the last decade, optogenetics has become an essential tool for neuroscience research due to its unrivaled feature of cell-type-specific neuromodulation. There have been several technological advances in light delivery devices. Among them, the combination of optogenetics and electrophysiology provides an opportunity for facilitating optogenetic approaches. In this study, a novel design of an optrode array was proposed for realizing optical modulation and electrophysiological recording. A 4 \texttimes{} 4 optrode array and five-channel recording electrodes were assembled as a disposable part, while a reusable part comprised an LED (light-emitting diode) source and a power line. After the characterization of the intensity of the light delivered at the fiber tips, in vivo animal experiment was performed with transgenic mice expressing channelrhodopsin, showing the effectiveness of optical activation and neural recording.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {channelrhodopsin,electrode,electrophysiology,optogenetics,optrode},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Jeon et al_2021_Implantable Optrode Array for Optogenetic Modulation and Electrical Neural.pdf}
}

@misc{jglaser222,
  title = {{{SSA}}: {{Sparse Subspace Analysis}}},
  shorttitle = {{{SSA}}},
  author = {{jglaser2}},
  year = {2022},
  month = jun,
  abstract = {Sparse subspace analysis},
  copyright = {BSD-3-Clause}
}

@article{jha22,
  title = {Bayesian {{Active Learning}} for {{Discrete Latent Variable Models}}},
  author = {Jha, Aditi and Ashwood, Zoe C. and Pillow, Jonathan W.},
  year = {2022},
  month = feb,
  journal = {arXiv},
  eprint = {2202.13426},
  eprinttype = {arxiv},
  doi = {10.48550/arxiv.2202.13426},
  abstract = {Active learning seeks to reduce the number of samples required to estimate the parameters of a model, thus forming an important class of techniques in modern machine learning. However, past work on active learning has largely overlooked latent variable models, which play a vital role in neuroscience, psychology, and a variety of other engineering and scientific disciplines. Here we address this gap in the literature and propose a novel framework for maximum-mutual-information input selection for learning discrete latent variable regression models. We first examine a class of models known as "mixtures of linear regressions" (MLR). This example is striking because it is well known that active learning confers no advantage for standard least-squares regression. However, we show -- both in simulations and analytically using Fisher information -- that optimal input selection can nevertheless provide dramatic gains for mixtures of regression models; we also validate this on a real-world application of MLRs. We then consider a powerful class of temporally structured latent variable models known as Input-Output Hidden Markov Models (IO-HMMs), which have recently gained prominence in neuroscience. We show that our method substantially speeds up learning, and outperforms a variety of approximate methods based on variational and amortized inference.},
  archiveprefix = {arXiv},
  file = {C\:\\Users\\johns\\Zotero\\storage\\9Q67SRQN\\Jha et al_2022_Bayesian Active Learning for Discrete Latent Variable Models.pdf}
}

@article{joglekar21,
  title = {A Spatially Resolved Brain Region- and Cell Type-Specific Isoform Atlas of the Postnatal Mouse Brain},
  author = {Joglekar, Anoushka and Prjibelski, Andrey and Mahfouz, Ahmed and Collier, Paul and Lin, Susan and Schlusche, Anna Katharina and Marrocco, Jordan and Williams, Stephen R. and Haase, Bettina and Hayes, Ashley and Chew, Jennifer G. and Weisenfeld, Neil I. and Wong, Man Ying and Stein, Alexander N. and Hardwick, Simon A. and Hunt, Toby and Wang, Qi and Dieterich, Christoph and Bent, Zachary and Fedrigo, Olivier and Sloan, Steven A. and Risso, Davide and Jarvis, Erich D. and Flicek, Paul and Luo, Wenjie and Pitt, Geoffrey S. and Frankish, Adam and Smit, August B. and Ross, M. Elizabeth and Tilgner, Hagen U.},
  year = {2021},
  month = jan,
  journal = {Nature Communications},
  volume = {12},
  number = {1},
  pages = {463},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-020-20343-5},
  abstract = {Splicing varies across brain regions, but the single-cell resolution of regional variation is unclear. We present a single-cell investigation of differential isoform expression (DIE) between brain regions using single-cell long-read sequencing in mouse hippocampus and prefrontal cortex in 45 cell types at postnatal day 7 (www.isoformAtlas.com). Isoform tests for DIE show better performance than exon tests. We detect hundreds of DIE events traceable to cell types, often corresponding to functionally distinct protein isoforms. Mostly, one cell type is responsible for brain-region specific DIE. However, for fewer genes, multiple cell types influence DIE. Thus, regional identity can, although rarely, override cell-type specificity. Cell types indigenous to one anatomic structure display distinctive DIE, e.g. the choroid plexus epithelium manifests distinct transcription-start-site usage. Spatial transcriptomics and long-read sequencing yield a spatially resolved splicing map. Our methods quantify isoform expression with cell-type and spatial resolution and it contributes to further our understanding of how the brain integrates molecular and cellular complexity.},
  copyright = {2021 The Author(s)},
  langid = {english},
  keywords = {Computational neuroscience,Development of the nervous system,RNA splicing,Transcriptomics},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Joglekar et al_2021_A spatially resolved brain region- and cell type-specific isoform atlas of the.pdf}
}

@misc{johnsen22,
  title = {Kjohnsen/Tklfp: V0.2.0},
  shorttitle = {Kjohnsen/Tklfp},
  author = {Johnsen, Kyle},
  year = {2022},
  month = jul,
  doi = {10.5281/zenodo.6787979},
  abstract = {Add functionality for custom, heterogeneous neuron orientations},
  howpublished = {Zenodo}
}

@article{juavinett19,
  title = {Chronically Implanted {{Neuropixels}} Probes Enable High-Yield Recordings in Freely Moving Mice},
  author = {Juavinett, Ashley L and Bekheet, George and Churchland, Anne K},
  editor = {Colgin, Laura L and Steinmetz, Nick},
  year = {2019},
  month = aug,
  journal = {eLife},
  volume = {8},
  pages = {e47188},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.47188},
  abstract = {The advent of high-yield electrophysiology using Neuropixels probes is now enabling researchers to simultaneously record hundreds of neurons with remarkably high signal to noise. However, these probes have not been well-suited to use in freely moving mice. It is critical to study neural activity in unrestricted animals for many reasons, such as leveraging ethological approaches to study neural circuits. We designed and implemented a novel device that allows Neuropixels probes to be customized for chronically implanted experiments in freely moving mice. We demonstrate the ease and utility of this approach in recording hundreds of neurons during an ethological behavior across weeks of experiments. We provide the technical drawings and procedures for other researchers to do the same. Importantly, our approach enables researchers to explant and reuse these valuable probes, a transformative step which has not been established for recordings with any type of chronically-implanted probe.},
  keywords = {behavior,electrophysiology,extracellular,Neuropixels},
  file = {C\:\\Users\\johns\\Zotero\\storage\\LGZD75I2\\Juavinett et al_2019_Chronically implanted Neuropixels probes enable high-yield recordings in freely.pdf}
}

@article{kalaska83,
  title = {Cortical Mechanisms Related to the Direction of Two-Dimensional Arm Movements: Relations in Parietal Area 5 and Comparison with Motor Cortex},
  shorttitle = {Cortical Mechanisms Related to the Direction of Two-Dimensional Arm Movements},
  author = {Kalaska, J. F. and Caminiti, R. and Georgopoulos, A. P.},
  year = {1983},
  month = jul,
  journal = {Experimental Brain Research},
  volume = {51},
  number = {2},
  pages = {247--260},
  issn = {1432-1106},
  doi = {10.1007/BF00237200},
  abstract = {The relations between the direction of two-dimensional arm movements and single cell discharge in area 5 were investigated during 49 penetrations into the superior parietal lobule of 3 monkeys. A significant variation of cell discharge with the direction of movement was observed in 182 of 212 cells that were related to arm movements. In 151/182 of these cells the frequency of discharge was highest during movements in a preferred direction, and decreased in an orderly fashion with movements made in directions farther and farther away from the preferred one; in 112/151 cells this variation in discharge was a sinusoidal function of the direction of movement. Preferred directions differed for different cells so that directional tuning curves overlapped partially. These results are similar to those described for cells in the motor cortex (Georgopoulos et al. 1982): this suggests that directional information may be processed in a similar way in these structures.},
  langid = {english},
  keywords = {Cortex,Direction,Motor,Movement,Parietal},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Kalaska et al_1983_Cortical mechanisms related to the direction of two-dimensional arm movements.pdf}
}

@article{kalman60,
  title = {A New Approach to Linear Filtering and Prediction Problems},
  author = {Kalman, R. E.},
  year = {1960},
  month = mar,
  journal = {Journal of Fluids Engineering, Transactions of the ASME},
  volume = {82},
  number = {1},
  pages = {35--45},
  publisher = {{American Society of Mechanical Engineers Digital Collection}},
  issn = {1528901X},
  doi = {10.1115/1.3662552},
  abstract = {The classical filtering and prediction problem is re-examined using the Bode-Sliannon representation of random processes and the ``state-transition'' method of analysis of dynamic systems. New results are: (1) The formulation and methods of solution of the problem apply without modification to stationary and nonstationary statistics and to growing-memory and infinitememory filters. (2) A nonlinear difference (or differential) equation is derived for the covariance matrix of the optimal estimation error. From the solution of this equation the coefficients of the difference (or differential) equation of the optimal linear filter are obtained without further calculations. (3) The filtering problem is shown to be the dual of the noise-free regulator problem. The new method developed here is applied to two well-known problems, confirming and extending earlier results. The discussion is largely self-contained and proceeds from first principles; basic concepts of the theory of random processes are reviewed in the Appendix. \textcopyright{} 1960 by ASME.},
  keywords = {Dynamic systems,Errors,Statistics as topic,Stochastic processes}
}

@article{kao19,
  title = {Neuroscience out of Control: Control-Theoretic Perspectives on Neural Circuit Dynamics},
  shorttitle = {Neuroscience out of Control},
  author = {Kao, Ta-Chu and Hennequin, Guillaume},
  year = {2019},
  month = oct,
  journal = {Current Opinion in Neurobiology},
  series = {Computational {{Neuroscience}}},
  volume = {58},
  pages = {122--129},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2019.09.001},
  abstract = {A major challenge in systems neuroscience is to understand how the dynamics of neural circuits give rise to behaviour. Analysis of complex dynamical systems is also at the heart of control engineering, where it is central to the design of robust control strategies. Although a rich engineering literature has grown over decades to facilitate the analysis of such systems, little of it has percolated into neuroscience so far. Here, we give a brief introduction to a number of core control-theoretic concepts that provide useful perspectives on neural circuit dynamics. We introduce important mathematical tools related to these concepts, and establish connections to neural circuit analysis, focusing on a number of themes that have arisen from the modern `state-space' view on neural population dynamics.},
  langid = {english}
}

@article{karvat20,
  title = {Real-Time Detection of Neural Oscillation Bursts Allows Behaviourally Relevant Neurofeedback},
  author = {Karvat, Golan and Schneider, Artur and Alyahyay, Mansour and Steenbergen, Florian and Tangermann, Michael and Diester, Ilka},
  year = {2020},
  month = feb,
  journal = {Communications Biology},
  volume = {3},
  number = {1},
  pages = {1--10},
  publisher = {{Nature Publishing Group}},
  issn = {2399-3642},
  doi = {10.1038/s42003-020-0801-z},
  abstract = {Neural oscillations as important information carrier in the brain, are increasingly interpreted as transient bursts rather than as sustained oscillations. Short ({$<$}150\,ms) bursts of beta-waves (15\textendash 30\,Hz) have been documented in humans, monkeys and mice. These events were correlated with memory, movement and perception, and were even suggested as the primary ingredient of all beta-band activity. However, a method to measure these short-lived events in real-time and to investigate their impact on behaviour is missing. Here we present a real-time data analysis system, capable to detect short narrowband bursts, and demonstrate its usefulness to increase the beta-band burst-rate in rats. This neurofeedback~training induced changes in overall oscillatory power, and bursts could be decoded from the movement of the rats, thus enabling future investigation of the role of oscillatory bursts.},
  copyright = {2020 The Author(s)},
  langid = {english},
  keywords = {Brain–machine interface,Motor cortex},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Karvat et al_2020_Real-time detection of neural oscillation bursts allows behaviourally relevant.pdf}
}

@article{kathe22,
  title = {Wireless Closed-Loop Optogenetics across the Entire Dorsoventral Spinal Cord in Mice},
  author = {Kathe, Claudia and Michoud, Fr{\'e}d{\'e}ric and Sch{\"o}nle, Philipp and Rowald, Andreas and Brun, No{\'e} and Ravier, Jimmy and Furfaro, Ivan and Paggi, Valentina and Kim, Kyungjin and Soloukey, Sadaf and Asboth, Leonie and Hutson, Thomas H. and Jelescu, Ileana and Philippides, Antoine and Alwahab, Noaf and Gandar, J{\'e}r{\^o}me and Huber, Daniel and De Zeeuw, Chris I. and Barraud, Quentin and Huang, Qiuting and Lacour, St{\'e}phanie P. and Courtine, Gr{\'e}goire},
  year = {2022},
  month = feb,
  journal = {Nature Biotechnology},
  volume = {40},
  number = {2},
  pages = {198--208},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1696},
  doi = {10.1038/s41587-021-01019-x},
  abstract = {Optoelectronic systems can exert precise control over targeted neurons and pathways throughout the brain in untethered animals, but similar technologies for the spinal cord are not well established. In the present study, we describe a system for ultrafast, wireless, closed-loop manipulation of targeted neurons and pathways across the entire dorsoventral spinal cord in untethered mice. We developed a soft stretchable carrier, integrating microscale light-emitting diodes (micro-LEDs), that conforms to the dura mater of the spinal cord. A coating of silicone\textendash phosphor matrix over the micro-LEDs provides mechanical protection and light conversion for compatibility with a large library of opsins. A lightweight, head-mounted, wireless platform powers the micro-LEDs and performs low-latency, on-chip processing of sensed physiological signals to control photostimulation in a closed loop. We use the device to reveal the role of various neuronal subtypes, sensory pathways and supraspinal projections in the control of locomotion in healthy and spinal-cord injured mice.},
  copyright = {2021 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  keywords = {Optogenetics,Spinal cord},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Kathe et al_2022_Wireless closed-loop optogenetics across the entire dorsoventral spinal cord in.pdf}
}

@article{kaufman14,
  title = {Cortical Activity in the Null Space: {{Permitting}} Preparation without Movement},
  author = {Kaufman, Matthew T. and Churchland, Mark M. and Ryu, Stephen I. and Shenoy, Krishna V.},
  year = {2014},
  month = feb,
  journal = {Nature Neuroscience},
  volume = {17},
  number = {3},
  pages = {440--448},
  publisher = {{Nature Publishing Group}},
  issn = {10976256},
  doi = {10.1038/nn.3643},
  abstract = {Neural circuits must perform computations and then selectively output the results to other circuits. Yet synapses do not change radically at millisecond timescales. A key question then is: how is communication between neural circuits controlled? In motor control, brain areas directly involved in driving movement are active well before movement begins. Muscle activity is some readout of neural activity, yet it remains largely unchanged during preparation. Here we find that during preparation, while the monkey holds still, changes in motor cortical activity cancel out at the level of these population readouts. Motor cortex can thereby prepare the movement without prematurely causing it. Further, we found evidence that this mechanism also operates in dorsal premotor cortex, largely accounting for how preparatory activity is attenuated in primary motor cortex. Selective use of 'output-null' vs. 'output-potent' patterns of activity may thus help control communication to the muscles and between these brain areas. \textcopyright{} 2014 Nature America, Inc.},
  pmid = {24487233},
  keywords = {Motor cortex,Premotor cortex},
  file = {C\:\\Users\\johns\\Zotero\\storage\\6LHR5Y2G\\Kaufman et al_2014_Cortical activity in the null space.pdf}
}

@article{kazemipour19,
  title = {Kilohertz Frame-Rate Two-Photon Tomography},
  author = {Kazemipour, Abbas and Novak, Ondrej and Flickinger, Daniel and Marvin, Jonathan S. and Abdelfattah, Ahmed S. and King, Jonathan and Borden, Philip M. and Kim, Jeong Jun and {Al-Abdullatif}, Sarah H. and Deal, Parker E. and Miller, Evan W. and Schreiter, Eric R. and Druckmann, Shaul and Svoboda, Karel and Looger, Loren L. and Podgorski, Kaspar},
  year = {2019},
  month = jul,
  journal = {Nature Methods},
  volume = {16},
  number = {8},
  pages = {778--786},
  publisher = {{Nature Publishing Group}},
  issn = {15487105},
  doi = {10.1038/s41592-019-0493-9},
  abstract = {Point-scanning two-photon microscopy enables high-resolution imaging within scattering specimens such as the mammalian brain, but sequential acquisition of voxels fundamentally limits its speed. We developed a two-photon imaging technique that scans lines of excitation across a focal plane at multiple angles and computationally recovers high-resolution images, attaining voxel rates of over 1 billion Hz in structured samples. Using a static image as a prior for recording neural activity, we imaged visually evoked and spontaneous glutamate release across hundreds of dendritic spines in mice at depths over 250 \textmu m and frame rates over 1 kHz. Dendritic glutamate transients in anesthetized mice are synchronized within spatially contiguous domains spanning tens of micrometers at frequencies ranging from 1\textendash 100 Hz. We demonstrate millisecond-resolved recordings of acetylcholine and voltage indicators, three-dimensional single-particle tracking and imaging in densely labeled cortex. Our method surpasses limits on the speed of raster-scanned imaging imposed by fluorescence lifetime.},
  pmid = {31363222},
  keywords = {Ca2+ imaging,Fluorescence imaging,Mouse,Synaptic transmission,Visual system},
  file = {C\:\\Users\\johns\\Zotero\\storage\\BMF68FFH\\Kazemipour et al_2019_Kilohertz frame-rate two-photon tomography.pdf}
}

@inproceedings{kepple22,
  title = {Curriculum Learning as a Tool to Uncover Learning Principles in the Brain},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Kepple, Daniel R. and Engelken, Rainer and Rajan, Kanaka},
  year = {2022},
  month = mar,
  abstract = {We present a novel approach to use curricula to identify principles by which a system learns. Previous work in curriculum learning has focused on how curricula can be designed to improve learning of a model on particular tasks. We consider the inverse problem: what can a curriculum tell us about how a learning system acquired a task? Using recurrent neural networks (RNNs) and models of common experimental neuroscience tasks, we demonstrate that curricula can be used to differentiate learning principles using target-based and a representation-based loss functions as use cases. In particular, we compare the performance of RNNs using target-based learning rules versus those using representational learning rules on three different curricula in the context of two tasks. We show that the learned state-space trajectories of RNNs trained by these two learning rules under all curricula tested are indistinguishable. However, by comparing learning times during different curricula, we can disambiguate the learning rules and challenge traditional approaches of interrogating learning systems. Although all animals in neuroscience lab settings are trained by curriculum-based procedures called shaping, almost no behavioral or neural data are collected or published on the relative successes or training times under different curricula. Our results motivate the systematic collection and curation of data during shaping by demonstrating curriculum learning in RNNs as a tool to probe and differentiate learning principles used by biological systems, over conventional statistical analyses of learned state spaces.},
  langid = {english},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Kepple et al_2022_Curriculum learning as a tool to uncover learning principles in the brain.pdf}
}

@article{khaligh-razavi14,
  title = {Deep {{Supervised}}, but {{Not Unsupervised}}, {{Models May Explain IT Cortical Representation}}},
  author = {{Khaligh-Razavi}, Seyed-Mahdi and Kriegeskorte, Nikolaus},
  year = {2014},
  month = nov,
  journal = {PLOS Computational Biology},
  volume = {10},
  number = {11},
  pages = {e1003915},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1003915},
  abstract = {Inferior temporal (IT) cortex in human and nonhuman primates serves visual object recognition. Computational object-vision models, although continually improving, do not yet reach human performance. It is unclear to what extent the internal representations of computational models can explain the IT representation. Here we investigate a wide range of computational model representations (37 in total), testing their categorization performance and their ability to account for the IT representational geometry. The models include well-known neuroscientific object-recognition models (e.g. HMAX, VisNet) along with several models from computer vision (e.g. SIFT, GIST, self-similarity features, and a deep convolutional neural network). We compared the representational dissimilarity matrices (RDMs) of the model representations with the RDMs obtained from human IT (measured with fMRI) and monkey IT (measured with cell recording) for the same set of stimuli (not used in training the models). Better performing models were more similar to IT in that they showed greater clustering of representational patterns by category. In addition, better performing models also more strongly resembled IT in terms of their within-category representational dissimilarities. Representational geometries were significantly correlated between IT and many of the models. However, the categorical clustering observed in IT was largely unexplained by the unsupervised models. The deep convolutional network, which was trained by supervision with over a million category-labeled images, reached the highest categorization performance and also best explained IT, although it did not fully explain the IT data. Combining the features of this model with appropriate weights and adding linear combinations that maximize the margin between animate and inanimate objects and between faces and other objects yielded a representation that fully explained our IT data. Overall, our results suggest that explaining IT requires computational features trained through supervised learning to emphasize the behaviorally important categorical divisions prominently reflected in IT.},
  langid = {english},
  keywords = {Computer vision,Face,Functional magnetic resonance imaging,Learning,Monkeys,Neural networks,Permutation,Vision},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Khaligh-Razavi_Kriegeskorte_2014_Deep Supervised, but Not Unsupervised, Models May Explain IT Cortical.pdf}
}

@inproceedings{kim21,
  title = {Inferring {{Latent Dynamics Underlying Neural Population Activity}} via {{Neural Differential Equations}}},
  booktitle = {Proceedings of the 38th {{International Conference}} on {{Machine Learning}}},
  author = {Kim, Timothy D. and Luo, Thomas Z. and Pillow, Jonathan W. and Brody, Carlos D.},
  year = {2021},
  month = jul,
  pages = {5551--5561},
  publisher = {{PMLR}},
  issn = {2640-3498},
  abstract = {An important problem in systems neuroscience is to identify the latent dynamics underlying neural population activity. Here we address this problem by introducing a low-dimensional nonlinear model for latent neural population dynamics using neural ordinary differential equations (neural ODEs), with noisy sensory inputs and Poisson spike train outputs. We refer to this as the Poisson Latent Neural Differential Equations (PLNDE) model. We apply the PLNDE framework to a variety of synthetic datasets, and show that it accurately infers the phase portraits and fixed points of nonlinear systems augmented to produce spike train data, including the FitzHugh-Nagumo oscillator, a 3-dimensional nonlinear spiral, and a nonlinear sensory decision-making model with attractor dynamics. Our model significantly outperforms existing methods at inferring single-trial neural firing rates and the corresponding latent trajectories that generated them, especially in the regime where the spike counts and number of trials are low. We then apply our model to multi-region neural population recordings from medial frontal cortex of rats performing an auditory decision-making task. Our model provides a general, interpretable framework for investigating the neural mechanisms of decision-making and other cognitive computations through the lens of dynamical systems.},
  langid = {english},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Kim et al_2021_Inferring Latent Dynamics Underlying Neural Population Activity via Neural.pdf;C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Kim et al_2021_Inferring Latent Dynamics Underlying Neural Population Activity via Neural2.pdf}
}

@article{kishi22,
  title = {Structural Basis for Channel Conduction in the Pump-like Channelrhodopsin {{ChRmine}}},
  author = {Kishi, Koichiro E. and Kim, Yoon Seok and Fukuda, Masahiro and Inoue, Masatoshi and Kusakizako, Tsukasa and Wang, Peter Y. and Ramakrishnan, Charu and Byrne, Eamon F.X. and Thadhani, Elina and Paggi, Joseph M. and Matsui, Toshiki E. and Yamashita, Keitaro and Nagata, Takashi and Konno, Masae and Quirin, Sean and Lo, Maisie and Benster, Tyler and Uemura, Tomoko and Liu, Kehong and Shibata, Mikihiro and Nomura, Norimichi and Iwata, So and Nureki, Osamu and Dror, Ron O. and Inoue, Keiichi and Deisseroth, Karl and Kato, Hideaki E.},
  year = {2022},
  month = feb,
  journal = {Cell},
  volume = {185},
  number = {4},
  pages = {672-689.e23},
  publisher = {{Elsevier B.V.}},
  issn = {10974172},
  doi = {10.1016/j.cell.2022.01.007},
  abstract = {ChRmine, a recently discovered pump-like cation-conducting channelrhodopsin, exhibits puzzling properties (large photocurrents, red-shifted spectrum, and extreme light sensitivity) that have created new opportunities in optogenetics. ChRmine and its homologs function as ion channels but, by primary sequence, more closely resemble ion pump rhodopsins; mechanisms for passive channel conduction in this family have remained mysterious. Here, we present the 2.0 \AA{} resolution cryo-EM structure of ChRmine, revealing architectural features atypical for channelrhodopsins: trimeric assembly, a short transmembrane-helix 3, a twisting extracellular-loop 1, large vestibules within the monomer, and an opening at the trimer interface. We applied this structure to design three proteins (rsChRmine and hsChRmine, conferring further red-shifted and high-speed properties, respectively, and frChRmine, combining faster and more red-shifted performance) suitable for fundamental neuroscience opportunities. These results illuminate the conduction and gating of pump-like channelrhodopsins and point the way toward further structure-guided creation of channelrhodopsins for applications across biology.},
  pmid = {35114111},
  keywords = {all-optical,channelrhodopsin,ChRmine,cryo-EM,microbial opsin,optogenetics,PLCR,pump-like channelrhodopsin,structure-guided engineering},
  file = {C\:\\Users\\johns\\Zotero\\storage\\SGCIAVYF\\Kishi et al_2022_Structural basis for channel conduction in the pump-like channelrhodopsin.pdf}
}

@article{klapoetke14,
  title = {Independent Optical Excitation of Distinct Neural Populations},
  author = {Klapoetke, Nathan C. and Murata, Yasunobu and Kim, Sung Soo and Pulver, Stefan R. and {Birdsey-Benson}, Amanda and Cho, Yong Ku and Morimoto, Tania K. and Chuong, Amy S. and Carpenter, Eric J. and Tian, Zhijian and Wang, Jun and Xie, Yinlong and Yan, Zhixiang and Zhang, Yong and Chow, Brian Y. and Surek, Barbara and Melkonian, Michael and Jayaraman, Vivek and {Constantine-Paton}, Martha and Wong, Gane Ka Shu and Boyden, Edward S.},
  year = {2014},
  month = feb,
  journal = {Nature Methods},
  volume = {11},
  number = {3},
  pages = {338--346},
  publisher = {{Nature Publishing Group}},
  issn = {15487105},
  doi = {10.1038/nmeth.2836},
  abstract = {Optogenetic tools enable examination of how specific cell types contribute to brain circuit functions. A long-standing question is whether it is possible to independently activate two distinct neural populations in mammalian brain tissue. Such a capability would enable the study of how different synapses or pathways interact to encode information in the brain. Here we describe two channelrhodopsins, Chronos and Chrimson, discovered through sequencing and physiological characterization of opsins from over 100 species of alga. Chrimson's excitation spectrum is red shifted by 45 nm relative to previous channelrhodopsins and can enable experiments in which red light is preferred. We show minimal visual system-mediated behavioral interference when using Chrimson in neurobehavioral studies in Drosophila melanogaster. Chronos has faster kinetics than previous channelrhodopsins yet is effectively more light sensitive. Together these two reagents enable two-color activation of neural spiking and downstream synaptic transmission in independent neural populations without detectable cross-talk in mouse brain slice. \textcopyright{} 2014 Nature America, Inc.},
  pmid = {24509633},
  keywords = {Optogenetics},
  file = {C\:\\Users\\johns\\Zotero\\storage\\CV29A7KU\\full-text.pdf}
}

@article{knopfel19,
  title = {Optical Voltage Imaging in Neurons: Moving from Technology Development to Practical Tool},
  shorttitle = {Optical Voltage Imaging in Neurons},
  author = {Kn{\"o}pfel, Thomas and Song, Chenchen},
  year = {2019},
  month = dec,
  journal = {Nature Reviews Neuroscience},
  volume = {20},
  number = {12},
  pages = {719--727},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/s41583-019-0231-4},
  abstract = {A central goal in neuroscience is to determine how the brain's neuronal circuits generate perception, cognition and emotions and how these lead to appropriate behavioural actions. A methodological platform based on genetically encoded voltage indicators (GEVIs) that enables the monitoring of large-scale circuit dynamics has brought us closer to this ambitious goal. This Review provides an update on the current state of the art and the prospects of emerging optical GEVI imaging technologies.},
  copyright = {2019 Springer Nature Limited},
  langid = {english},
  keywords = {Calcium signalling,Neural circuits},
  file = {C\:\\Users\\johns\\Zotero\\storage\\ICLETDMH\\Knöpfel_Song_2019_Optical voltage imaging in neurons.pdf}
}

@article{kokaia13,
  title = {An Optogenetic Approach in Epilepsy},
  author = {Kokaia, Merab and Andersson, My and Ledri, Marco},
  year = {2013},
  month = jun,
  journal = {Neuropharmacology},
  volume = {69},
  pages = {89--95},
  issn = {00283908},
  doi = {10.1016/j.neuropharm.2012.05.049},
  abstract = {Optogenetic tools comprise a variety of different light-sensitive proteins from single-cell organisms that can be expressed in mammalian neurons and effectively control their excitability. Two main classes of optogenetic tools allow to either depolarize or hyperpolarize, and respectively generate or inhibit action potentials in selective populations of neurons. This opens unprecedented possibilities for delineating the role of certain neuronal populations in brain processing and diseases. Moreover, optogenetics may be considered for developing potential treatment strategies for brain diseases, particularly for excitability disorders such as epilepsy. Expression of the inhibitory halorhodopsin NpHR in hippocampal principal cells has been recently used as a tool to effectively control chemically and electrically induced epileptiform activity in slice preparations, and to reduce in vivo spiking induced by tetanus toxin injection in the motor cortex. In this review we give a comprehensive summary of what has been achieved so far in the field of epilepsy using optogenetics, and discuss some of the possible strategies that could be envisaged in the future. We also point out some of the challenges and pitfalls in relation to possible outcomes of using optogenetics for controlling network excitability, and associated brain diseases. This article is part of the Special Issue entitled 'New Targets and Approaches to the Treatment of Epilepsy'. \textcopyright{} 2012 Elsevier Ltd. All rights reserved.},
  pmid = {22698957},
  keywords = {ChR2,Epilepsy,Epileptiform activity,NpHR,Optogenetics,Seizure control},
  file = {C\:\\Users\\johns\\Zotero\\storage\\TDYBB28F\\Kokaia et al_2013_An optogenetic approach in epilepsy.pdf}
}

@article{kriegeskorte18,
  title = {Cognitive Computational Neuroscience},
  author = {Kriegeskorte, Nikolaus and Douglas, Pamela K.},
  year = {2018},
  month = aug,
  journal = {Nature Neuroscience},
  volume = {21},
  number = {9},
  eprint = {1807.11819},
  eprinttype = {arxiv},
  pages = {1148--1160},
  publisher = {{Nature Publishing Group}},
  issn = {15461726},
  doi = {10.1038/s41593-018-0210-5},
  abstract = {To learn how cognition is implemented in the brain, we must build computational models that can perform cognitive tasks, and test such models with brain and behavioral experiments. Cognitive science has developed computational models that decompose cognition into functional components. Computational neuroscience has modeled how interacting neurons can implement elementary components of cognition. It is time to assemble the pieces of the puzzle of brain computation and to better integrate these separate disciplines. Modern technologies enable us to measure and manipulate brain activity in unprecedentedly rich ways in animals and humans. However, experiments will yield theoretical insight only when employed to test brain-computational models. Here we review recent work in the intersection of cognitive science, computational neuroscience and artificial intelligence. Computational models that mimic brain information processing during perceptual, cognitive and control tasks are beginning to be developed and tested with brain and behavioral data.},
  archiveprefix = {arXiv},
  pmid = {30127428},
  keywords = {Cognitive neuroscience,Computational neuroscience},
  file = {C\:\\Users\\johns\\Zotero\\storage\\PCPVSMEQ\\Kriegeskorte_Douglas_2018_Cognitive computational neuroscience.pdf}
}

@article{krook-magnuson13,
  title = {On-Demand Optogenetic Control of Spontaneous Seizures in Temporal Lobe Epilepsy},
  author = {{Krook-Magnuson}, Esther and Armstrong, Caren and Oijala, Mikko and Soltesz, Ivan},
  year = {2013},
  month = jan,
  journal = {Nature Communications},
  volume = {4},
  number = {1},
  pages = {1--8},
  publisher = {{Nature Publishing Group}},
  issn = {20411723},
  doi = {10.1038/ncomms2376},
  abstract = {Temporal lobe epilepsy is the most common type of epilepsy in adults, is often medically refractory, and due to broad actions and long-time scales, current systemic treatments have major negative side-effects. However, temporal lobe seizures tend to arise from discrete regions before overt clinical behaviour, making temporally and spatially specific treatment theoretically possible. Here we report the arrest of spontaneous seizures using a real-time, closed-loop, response system and in vivo optogenetics in a mouse model of temporal lobe epilepsy. Either optogenetic inhibition of excitatory principal cells, or activation of a subpopulation of GABAergic cells representing {$<$}5\% of hippocampal neurons, stops seizures rapidly upon light application. These results demonstrate that spontaneous temporal lobe seizures can be detected and terminated by modulating specific cell populations in a spatially restricted manner. A clinical approach built on these principles may overcome many of the side-effects of currently available treatment options. \textcopyright{} 2013 Macmillan Publishers Limited. All rights reserved.},
  pmid = {23340416},
  keywords = {Epilepsy,Medical research,Optogenetics}
}

@article{kumar13,
  title = {Challenges of Understanding Brain Function by Selective Modulation of Neuronal Subpopulations},
  author = {Kumar, Arvind and Vlachos, Ioannis and Aertsen, Ad and Boucsein, Clemens},
  year = {2013},
  month = oct,
  journal = {Trends in Neurosciences},
  volume = {36},
  number = {10},
  pages = {579--586},
  publisher = {{Elsevier Ltd}},
  issn = {1878108X},
  doi = {10.1016/j.tins.2013.06.005},
  abstract = {Neuronal networks confront researchers with an overwhelming complexity of interactions between their elements. A common approach to understanding neuronal processing is to reduce complexity by defining subunits and infer their functional role by selectively modulating them. However, this seemingly straightforward approach may lead to confusing results if the network exhibits parallel pathways leading to recurrent connectivity. We demonstrate limits of the selective modulation approach and argue that, even though highly successful in some instances, the approach fails in networks with complex connectivity. We argue to refine experimental techniques by carefully considering the structural features of the neuronal networks involved. Such methods could dramatically increase the effectiveness of selective modulation and may lead to a mechanistic understanding of principles underlying brain function. \textcopyright{} 2013 Elsevier Ltd.},
  pmid = {23876423},
  file = {C\:\\Users\\johns\\Zotero\\storage\\2K8KH3PH\\Kumar et al_2013_Challenges of understanding brain function by selective modulation of neuronal.pdf}
}

@inproceedings{kwon14,
  title = {A Wireless Slanted Optrode Array with Integrated Micro Leds for Optogenetics},
  booktitle = {2014 {{IEEE}} 27th {{International Conference}} on {{Micro Electro Mechanical Systems}} ({{MEMS}})},
  author = {Kwon, Ki Yong and Lee, Hyung-Min and Ghovanloo, Maysam and Weber, Arthur and Li, Wen},
  year = {2014},
  month = jan,
  pages = {813--816},
  issn = {1084-6999},
  doi = {10.1109/MEMSYS.2014.6765765},
  abstract = {This paper presents a wireless-enabled, flexible optrode array with multichannel micro light-emitting diodes ({$\mu$}-LEDs) for bi-directional wireless neural interface. The array integrates wirelessly addressable {$\mu$}-LED chips with a slanted polymer optrode array for precise light delivery and neural recording at multiple cortical layers simultaneously. A droplet backside exposure (DBE) method was developed to monolithically fabricate varying-length optrodes on a single polymer platform. In vivo tests in rat brains demonstrated that the {$\mu$}-LEDs were inductively powered and controlled using a wireless switched-capacitor stimulator (SCS), and light-induced neural activity was recorded with the optrode array concurrently.},
  keywords = {Arrays,Biomedical optical imaging,Light emitting diodes,Optical device fabrication,Optical waveguides,Wireless communication},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Kwon et al_2014_A wireless slanted optrode array with integrated micro leds for optogenetics.pdf}
}

@article{kwon15,
  title = {Design, Fabrication, and Packaging of an Integrated, Wirelessly-Powered Optrode Array for Optogenetics Application},
  author = {Kwon, Ki Yong and Lee, Hyung-Min and Ghovanloo, Maysam and Weber, Arthur and Li, Wen},
  year = {2015},
  journal = {Frontiers in Systems Neuroscience},
  volume = {9},
  issn = {1662-5137},
  abstract = {The recent development of optogenetics has created an increased demand for advancing engineering tools for optical modulation of neural circuitry. This paper details the design, fabrication, integration, and packaging procedures of a wirelessly-powered, light emitting diode (LED) coupled optrode neural interface for optogenetic studies. The LED-coupled optrode array employs microscale LED ({$\mu$}LED) chips and polymer-based microwaveguides to deliver light into multi-level cortical networks, coupled with microelectrodes to record spontaneous changes in neural activity. An integrated, implantable, switched-capacitor based stimulator (SCS) system provides high instantaneous power to the {$\mu$}LEDs through an inductive link to emit sufficient light and evoke neural activities. The presented system is mechanically flexible, biocompatible, miniaturized, and lightweight, suitable for chronic implantation in small freely behaving animals. The design of this system is scalable and its manufacturing is cost effective through batch fabrication using microelectromechanical systems (MEMS) technology. It can be adopted by other groups and customized for specific needs of individual experiments.},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Kwon et al_2015_Design, fabrication, and packaging of an integrated, wirelessly-powered optrode.pdf}
}

@article{lai21,
  title = {High-Speed Laser-Scanning Biological Microscopy Using {{FACED}}},
  author = {Lai, Queenie T.K. and Yip, Gwinky G.K. and Wu, Jianglai and Wong, Justin S.J. and Lo, Michelle C.K. and Lee, Kelvin C.M. and Le, Tony T.H.D. and So, Hayden K.H. and Ji, Na and Tsia, Kevin K.},
  year = {2021},
  month = aug,
  journal = {Nature Protocols},
  volume = {16},
  number = {9},
  pages = {4227--4264},
  publisher = {{Nature Publishing Group}},
  issn = {17502799},
  doi = {10.1038/s41596-021-00576-4},
  abstract = {Laser scanning is used in advanced biological microscopy to deliver superior imaging contrast, resolution and sensitivity. However, it is challenging to scale up the scanning speed required for interrogating a large and heterogeneous population of biological specimens or capturing highly dynamic biological processes at high spatiotemporal resolution. Bypassing the speed limitation of traditional mechanical methods, free-space angular-chirp-enhanced delay (FACED) is an all-optical, passive and reconfigurable laser-scanning approach that has been successfully applied in different microscopy modalities at an ultrafast line-scan rate of 1\textendash 80 MHz. Optimal FACED imaging performance requires optimized experimental design and implementation to enable specific high-speed applications. In this protocol, we aim to disseminate information allowing FACED to be applied to a broader range of imaging modalities. We provide (i) a comprehensive guide and design specifications for the FACED hardware; (ii) step-by-step optical implementations of the FACED module including the key custom components; and (iii) the overall image acquisition and reconstruction pipeline. We illustrate two practical imaging configurations: multimodal FACED imaging flow cytometry (bright-field, fluorescence and second-harmonic generation) and kHz 2D two-photon fluorescence microscopy. Users with basic experience in optical microscope operation and software engineering should be able to complete the setup of the FACED imaging hardware and software in \textasciitilde 2\textendash 3 months.},
  pmid = {34341580},
  keywords = {Fluorescence imaging,High,Machine learning,Multiphoton microscopy,Optical imaging,throughput screening},
  file = {C\:\\Users\\johns\\Zotero\\storage\\9LMVDRZH\\Lai et al_2021_High-speed laser-scanning biological microscopy using FACED.pdf}
}

@article{lee20,
  title = {Light {{Up}} the {{Brain}}: {{The Application}} of {{Optogenetics}} in {{Cell-Type Specific Dissection}} of {{Mouse Brain Circuits}}},
  shorttitle = {Light {{Up}} the {{Brain}}},
  author = {Lee, Candice and Lavoie, Andreanne and Liu, Jiashu and Chen, Simon X. and Liu, Bao-hua},
  year = {2020},
  journal = {Frontiers in Neural Circuits},
  volume = {14},
  issn = {1662-5110},
  abstract = {The exquisite intricacies of neural circuits are fundamental to an animal's diverse and complex repertoire of sensory and motor functions. The ability to precisely map neural circuits and to selectively manipulate neural activity is critical to understanding brain function and has, therefore been a long-standing goal for neuroscientists. The recent development of optogenetic tools, combined with transgenic mouse lines, has endowed us with unprecedented spatiotemporal precision in circuit analysis. These advances greatly expand the scope of tractable experimental investigations. Here, in the first half of the review, we will present applications of optogenetics in identifying connectivity between different local neuronal cell types and of long-range projections with both in vitro and in vivo methods. We will then discuss how these tools can be used to reveal the functional roles of these cell-type specific connections in governing sensory information processing, and learning and memory in the visual cortex, somatosensory cortex, and motor cortex. Finally, we will discuss the prospect of new optogenetic tools and how their application can further advance modern neuroscience. In summary, this review serves as a primer to exemplify how optogenetics can be used in sophisticated modern circuit analyses at the levels of synapses, cells, network connectivity and behaviors.},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Lee et al_2020_Light Up the Brain.pdf}
}

@article{li22,
  title = {Colocalized, Bidirectional Optogenetic Modulations in Freely Behaving Mice with a Wireless Dual-Color Optoelectronic Probe},
  author = {Li, Lizhu and Lu, Lihui and Ren, Yuqi and Tang, Guo and Zhao, Yu and Cai, Xue and Shi, Zhao and Ding, He and Liu, Changbo and Cheng, Dali and Xie, Yang and Wang, Huachun and Fu, Xin and Yin, Lan and Luo, Minmin and Sheng, Xing},
  year = {2022},
  month = feb,
  journal = {Nature Communications 2022 13:1},
  volume = {13},
  number = {1},
  pages = {1--14},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-28539-7},
  abstract = {Optogenetic methods provide efficient cell-specific modulations, and the ability of simultaneous neural activation and inhibition in the same brain region of freely moving animals is highly desirable. Here we report bidirectional neuronal activity manipulation accomplished by a wireless, dual-color optogenetic probe in synergy with the co-expression of two spectrally distinct opsins (ChrimsonR and stGtACR2) in a rodent model. The flexible probe comprises vertically assembled, thin-film microscale light-emitting diodes with a lateral dimension of 125 \texttimes{} 180 \textmu m2, showing colocalized red and blue emissions and enabling chronic in vivo operations with desirable biocompatibilities. Red or blue irradiations deterministically evoke or silence neurons co-expressing the two opsins. The probe interferes with dopaminergic neurons in the ventral tegmental area of mice, increasing or decreasing dopamine levels. Such bidirectional regulations further generate rewarding and aversive behaviors and interrogate social interactions among multiple mice. These technologies create numerous opportunities and implications for brain research. Simultaneous neural activation and inhibition in the same brain region of animals is highly desirable. Here the authors report a wireless, dual-colour optogenetic probe with the co-expression of two spectrally distinct opsins to allow for bidirectional neuronal activity manipulation in a rodent model.},
  pmid = {35149715},
  keywords = {Neuronal physiology,Optics and photonics,Optogenetics},
  file = {C\:\\Users\\johns\\Zotero\\storage\\V4GTMGER\\Li et al_2022_Colocalized, bidirectional optogenetic modulations in freely behaving mice with.pdf}
}

@misc{lian22,
  title = {An {{Augmented Lagrangian Based Parallelizable Nonconvex Solver}} for {{Bilinear Model Predictive Control}}},
  author = {Lian, Yingzhao and Jiang, Yuning and Opila, Daniel F. and Jones, Colin N.},
  year = {2022},
  month = jun,
  number = {arXiv:2206.10425},
  eprint = {2206.10425},
  eprinttype = {arxiv},
  primaryclass = {cs, eess},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2206.10425},
  abstract = {Nonlinear model predictive control is widely adopted to manipulate bilinear systems, and bilinear models are ubiquitous in chemical process, mechanical system and quantum physics, to name a few. Running an MPC controller in real-time requires solving a non-convex optimization problem at step. In this work, we propose a novel parallel augmented Lagrangian based bilinear MPC solver via a novel horizon splitting scheme. The resulting algorithm converts the non-convex MPC control problem into a set parallelizable multi-parametric quadratic programming (mpQP) and an equality constrained QP problem. The mpQP solution can be pre-computed offline to enable efficient online compuation. The proposed algorithm is validated on a building simulation and is deployed on a TI C2000 LaunchPad to emulate the bilinear DC motor speed control.},
  archiveprefix = {arXiv},
  keywords = {Electrical Engineering and Systems Science - Systems and Control},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Lian et al_2022_An Augmented Lagrangian Based Parallelizable Nonconvex Solver for Bilinear.pdf}
}

@article{lin13,
  title = {{{ReaChR}}: {{A}} Red-Shifted Variant of Channelrhodopsin Enables Deep Transcranial Optogenetic Excitation},
  author = {Lin, John Y. and Knutsen, Per Magne and Muller, Arnaud and Kleinfeld, David and Tsien, Roger Y.},
  year = {2013},
  month = sep,
  journal = {Nature Neuroscience},
  volume = {16},
  number = {10},
  pages = {1499--1508},
  publisher = {{Nature Publishing Group}},
  issn = {10976256},
  doi = {10.1038/nn.3502},
  abstract = {Channelrhodopsins (ChRs) are used to optogenetically depolarize neurons. We engineered a variant of ChR, denoted red-activatable ChR (ReaChR), that is optimally excited with orange to red light ({$\lambda$} {$\sim$}590-630 nm) and offers improved membrane trafficking, higher photocurrents and faster kinetics compared to existing red-shifted ChRs. Red light is less scattered by tissue and is absorbed less by blood than the blue to green wavelengths that are required by other ChR variants. We used ReaChR expressed in the vibrissa motor cortex to drive spiking and vibrissa motion in awake mice when excited with red light through intact skull. Precise vibrissa movements were evoked by expressing ReaChR in the facial motor nucleus in the brainstem and illumination with red light through the external auditory canal. Thus, ReaChR enables transcranial optical activation of neurons in deep brain structures without the need to surgically thin the skull, form a transcranial window orimplant optical fibers. \textcopyright{} 2013 Nature America, Inc. All rights reserved.},
  pmid = {23995068},
  keywords = {Molecular engineering,Optogenetics},
  file = {C\:\\Users\\johns\\Zotero\\storage\\HZKFGRRQ\\Lin et al_2013_ReaChR.pdf}
}

@article{linden14,
  title = {{{LFPy}}: A Tool for Biophysical Simulation of Extracellular Potentials Generated by Detailed Model Neurons},
  shorttitle = {{{LFPy}}},
  author = {Lind{\'e}n, Henrik and Hagen, Espen and Leski, Szymon and Norheim, Eivind and Pettersen, Klas and Einevoll, Gaute},
  year = {2014},
  journal = {Frontiers in Neuroinformatics},
  volume = {7},
  issn = {1662-5196},
  abstract = {Electrical extracellular recordings, i.e., recordings of the electrical potentials in the extracellular medium between cells, have been a main work-horse in electrophysiology for almost a century. The high-frequency part of the signal ({$\greaterequivlnt$}500 Hz), i.e., the multi-unit activity (MUA), contains information about the firing of action potentials in surrounding neurons, while the low-frequency part, the local field potential (LFP), contains information about how these neurons integrate synaptic inputs. As the recorded extracellular signals arise from multiple neural processes, their interpretation is typically ambiguous and difficult. Fortunately, a precise biophysical modeling scheme linking activity at the cellular level and the recorded signal has been established: the extracellular potential can be calculated as a weighted sum of all transmembrane currents in all cells located in the vicinity of the electrode. This computational scheme can considerably aid the modeling and analysis of MUA and LFP signals. Here, we describe LFPy, an open source Python package for numerical simulations of extracellular potentials. LFPy consists of a set of easy-to-use classes for defining cells, synapses and recording electrodes as Python objects, implementing this biophysical modeling scheme. It runs on top of the widely used NEURON simulation environment, which allows for flexible usage of both new and existing cell models. Further, calculation of extracellular potentials using the line-source-method is efficiently implemented. We describe the theoretical framework underlying the extracellular potential calculations and illustrate by examples how LFPy can be used both for simulating LFPs, i.e., synaptic contributions from single cells as well a populations of cells, and MUAs, i.e., extracellular signatures of action potentials.},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Lindén et al_2014_LFPy.pdf}
}

@article{liu15,
  title = {{{OptogenSIM}}: A {{3D Monte Carlo}} Simulation Platform for Light Delivery Design in Optogenetics},
  author = {Liu, Yuming and Jacques, Steven L. and Azimipour, Mehdi and Rogers, Jeremy D. and Pashaie, Ramin and Eliceiri, Kevin W.},
  year = {2015},
  month = dec,
  journal = {Biomedical Optics Express},
  volume = {6},
  number = {12},
  pages = {4859},
  publisher = {{The Optical Society}},
  issn = {2156-7085},
  doi = {10.1364/boe.6.004859},
  abstract = {Optimizing light delivery for optogenetics is critical in order to accurately stimulate the neurons of interest while reducing nonspecific effects such as tissue heating or photodamage. Light distribution is typically predicted using the assumption of tissue homogeneity, which oversimplifies light transport in heterogeneous brain. Here, we present an open-source 3D simulation platform, OptogenSIM, which eliminates this assumption. This platform integrates a voxel-based 3D Monte Carlo model, generic optical property models of brain tissues, and a well-defined 3D mouse brain tissue atlas. The application of this platform in brain data models demonstrates that brain heterogeneity has moderate to significant impact depending on application conditions. Estimated light density contours can show the region of any specified power density in the 3D brain space and thus can help optimize the light delivery settings, such as the optical fiber position, fiber diameter, fiber numerical aperture, light wavelength and power. OptogenSIM is freely available and can be easily adapted to incorporate additional brain atlases.},
  keywords = {Absorption coefficient,Illumination design,Light wavelength,Optical properties,Tissue,Tissue optical properties},
  file = {C\:\\Users\\johns\\Zotero\\storage\\4MYZFY7K\\Liu et al_2015_OptogenSIM.pdf}
}

@article{lopes15,
  title = {Bonsai: An Event-Based Framework for Processing and Controlling Data Streams},
  shorttitle = {Bonsai},
  author = {Lopes, Gon{\c c}alo and Bonacchi, Niccol{\`o} and Fraz{\~a}o, Jo{\~a}o and Neto, Joana P. and Atallah, Bassam V. and Soares, Sofia and Moreira, Lu{\'i}s and Matias, Sara and Itskov, Pavel M. and Correia, Patr{\'i}cia A. and Medina, Roberto E. and Calcaterra, Lorenza and Dreosti, Elena and Paton, Joseph J. and Kampff, Adam R.},
  year = {2015},
  journal = {Frontiers in Neuroinformatics},
  volume = {9},
  issn = {1662-5196},
  abstract = {The design of modern scientific experiments requires the control and monitoring of many different data streams. However, the serial execution of programming instructions in a computer makes it a challenge to develop software that can deal with the asynchronous, parallel nature of scientific data. Here we present Bonsai, a modular, high-performance, open-source visual programming framework for the acquisition and online processing of data streams. We describe Bonsai's core principles and architecture and demonstrate how it allows for the rapid and flexible prototyping of integrated experimental designs in neuroscience. We specifically highlight some applications that require the combination of many different hardware and software components, including video tracking of behavior, electrophysiology and closed-loop control of stimulation.},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Lopes et al_2015_Bonsai.pdf}
}

@article{lundqvist16,
  title = {Gamma and {{Beta Bursts Underlie Working Memory}}},
  author = {Lundqvist, Mikael and Rose, Jonas and Herman, Pawel and Brincat, Scott L L. and Buschman, Timothy J J. and Miller, Earl K K.},
  year = {2016},
  month = apr,
  journal = {Neuron},
  volume = {90},
  number = {1},
  pages = {152--164},
  publisher = {{Cell Press}},
  issn = {10974199},
  doi = {10.1016/j.neuron.2016.02.028},
  abstract = {Working memory is thought to result from sustained neuron spiking. However, computational models suggest complex dynamics with discrete oscillatory bursts. We analyzed local field potential (LFP) and spiking from the prefrontal cortex (PFC) of monkeys performing a working memory task. There were brief bursts of narrow-band gamma oscillations (45\textendash 100 Hz), varied in time and frequency, accompanying encoding and re-activation of sensory information. They appeared at a minority of recording sites associated with spiking reflecting the to-be-remembered items. Beta oscillations (20\textendash 35 Hz) also occurred in brief, variable bursts but reflected a default state interrupted by encoding and decoding. Only activity of neurons reflecting encoding/decoding correlated with changes in gamma burst rate. Thus, gamma bursts could gate access to, and prevent sensory interference with, working memory. This supports the hypothesis that working memory is manifested by discrete oscillatory dynamics and spiking, not sustained activity.},
  pmid = {26996084},
  file = {C\:\\Users\\johns\\Zotero\\storage\\62HEHCY6\\Lundqvist et al_2016_Gamma and Beta Bursts Underlie Working Memory.pdf}
}

@article{lundqvist22a,
  title = {Reduced Variability of Bursting Activity during Working Memory},
  author = {Lundqvist, Mikael and Rose, Jonas and Brincat, Scott L. and Warden, Melissa R. and Buschman, Timothy J. and Herman, Pawel and Miller, Earl K.},
  year = {2022},
  month = sep,
  journal = {Scientific Reports},
  volume = {12},
  number = {1},
  pages = {15050},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-022-18577-y},
  abstract = {Working memories have long been thought to be maintained by persistent spiking. However, mounting evidence from multiple-electrode recording (and single-trial analyses) shows that the underlying spiking is better characterized by intermittent bursts of activity. A counterargument suggested this intermittent activity is at odds with observations that spike-time variability reduces during task performance. However, this counterargument rests on assumptions, such as randomness in the timing of the bursts, which may not be correct. Thus, we analyzed spiking and LFPs from monkeys' prefrontal cortex (PFC) to determine if task-related reductions in variability can co-exist with intermittent spiking. We found that it does because both spiking and associated gamma bursts were task-modulated, not random. In fact, the task-related reduction in spike variability could largely be explained by a related reduction in gamma burst variability. Our results provide further support for the intermittent activity models of working memory as well as novel mechanistic insights into how spike variability is reduced during cognitive tasks.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Cognitive neuroscience,Computational neuroscience,Learning and memory,Neuronal physiology,Neuroscience},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Lundqvist et al_2022_Reduced variability of bursting activity during working memory.pdf}
}

@article{luo18,
  title = {Data-Driven Predictive Control of {{Hammerstein}}\textendash{{Wiener}} Systems Based on Subspace Identification},
  author = {Luo, Xiao-Suo and Song, Yong-Duan},
  year = {2018},
  month = jan,
  journal = {Information Sciences},
  volume = {422},
  pages = {447--461},
  issn = {0020-0255},
  doi = {10.1016/j.ins.2017.09.004},
  abstract = {It poses significant challenge to control Hammerstein\textendash Wiener systems involving modeling nonlinearities. In this paper, a novel data-driven predictive control method based on the subspace identification of Hammerstein\textendash Wiener systems is presented. By reformulating the open- and closed-loop Hammerstein\textendash Wiener model, subspace predictions of the outputs are derived using recursive substitution of the Hankel matrices. The output nonlinearity is presented by polynomial representation and the subspace predictors are obtained using the QR decomposition, together with additional algebra manipulations, where Q is an orthogonal matrix and R is an upper triangular matrix. The predictors are applied to the model predictive controller, wherein the integrated action is successfully incorporated. The effectiveness and feasibility of the proposed controller is also verified by numerical simulation on a fermentation bioreactor system.},
  langid = {english},
  keywords = {Data-driven predictive control,Hammerstein–Wiener systems,Subspace identification,The fermentation bioreactor system},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Luo_Song_2018_Data-driven predictive control of Hammerstein–Wiener systems based on subspace.pdf}
}

@inproceedings{luo19,
  title = {Modelling {{Optogenetic Subthreshold Effects}}},
  booktitle = {Proceedings of the {{Annual International Conference}} of the {{IEEE Engineering}} in {{Medicine}} and {{Biology Society}}, {{EMBS}}},
  author = {Luo, Jun Wen and Nikolic, Konstantin and Degenaar, Patrick},
  year = {2019},
  month = jul,
  pages = {6136--6140},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  issn = {1557170X},
  doi = {10.1109/EMBC.2019.8856664},
  abstract = {We develop a system-level approach to modelling optogenetic-neurons firing behaviour in in-vivo conditions. This approach contains three sub-modules: 1) a Mie/Rayleigh scattering mode of light penetration in tissue; 2) a classic likelihood Poisson spiking train model; 3) a 4-state model of the Channelrhodopsin-2 (ChR2) channel added to a CA3 neuron Hodgkin-Huxley model. We first investigate opto-neurons lightto-spike mechanisms in an in-vivo model: the background noise (synaptic currents) play a dominant role in generating spikes rather than light intensities as for in-vitro conditions (Typically the required light intensity is less than 0.3 mW/mm2 for in-vivo). Then the spiking fidelity is analyzed for different background noise levels. Next, by combining light penetration profiles, we show how neuron firing rates decay as tissue distance increases, for a 2D dimensional cross-section. This preliminary data clearly demonstrate that at given light stimulation protocol, the maximum effected distance in-vivo is 250 {$\mu$}m with small frequency decay rates, while for in-vitro is 50{$\mu$}m with considerable frequency decay rates. Therefore, the developed model can be used for designing sensible light stimulation strategies in-vivo and opto-electronics systems.},
  isbn = {978-1-5386-1311-5},
  pmid = {31947244},
  file = {C\:\\Users\\johns\\Zotero\\storage\\XRU57ZAS\\Luo et al_2019_Modelling Optogenetic Subthreshold Effects.pdf}
}

@article{maaten08,
  title = {Visualizing {{Data}} Using T-{{SNE}}},
  author = {van der Maaten, Laurens and Hinton, Geoffrey},
  year = {2008},
  journal = {Journal of Machine Learning Research},
  volume = {9},
  number = {86},
  pages = {2579--2605},
  issn = {1533-7928},
  abstract = {We present a new technique called "t-SNE" that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map. The technique is a variation of Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is much easier to optimize, and produces significantly better visualizations by reducing the tendency to crowd points together in the center of the map. t-SNE is better than existing techniques at creating a single map that reveals structure at many different scales. This is particularly important for high-dimensional data that lie on several different, but related, low-dimensional manifolds, such as images ofobjects from multiple classes seen from multiple viewpoints. For visualizing the structure of very large data sets, we show how t-SNE can use random walks on neighborhood graphs to allow the implicit structure of all of the data to influence the way in which a subset of the data is displayed. We illustrate the performance of t-SNE on a wide variety of data sets and compare it with many other non-parametric visualization techniques, including Sammon mapping, Isomap, and Locally Linear Embedding. The visualizations produced by t-SNE are significantly better than those produced by the other techniques on almost all of the data sets.},
  file = {C\:\\Users\\johns\\Zotero\\storage\\V8XL7AGK\\Maaten_Hinton_2008_Visualizing Data using t-SNE.pdf}
}

@inproceedings{macke11,
  title = {Empirical Models of Spiking in Neural Populations},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Macke, Jakob H and Buesing, Lars and Cunningham, John P and Yu, Byron M and Shenoy, Krishna V and Sahani, Maneesh},
  year = {2011},
  volume = {24},
  publisher = {{Curran Associates, Inc.}},
  abstract = {Neurons in the neocortex code and compute as part of a locally interconnected population. Large-scale multi-electrode recording makes it possible to access these population processes empirically by fitting statistical models to unaveraged data. What statistical structure best describes the concurrent spiking of cells within  a local network? We argue that in the cortex, where firing exhibits extensive correlations in both time and space and where a typical sample of neurons still reflects only a very small fraction of the local population, the most appropriate model captures shared variability by a low-dimensional latent process evolving with smooth dynamics, rather than by putative direct coupling. We test this claim by comparing  a latent dynamical model with realistic spiking observations to coupled generalised  linear spike-response models (GLMs) using cortical recordings. We find that the latent dynamical approach outperforms the GLM in terms of goodness-of-fit, and reproduces the temporal correlations in the data more accurately. We also compare models whose observations models are either derived from a Gaussian or point-process models, finding that the non-Gaussian model provides slightly  better goodness-of-fit and more realistic population spike counts.},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Macke et al_2011_Empirical models of spiking in neural populations.pdf}
}

@misc{maddalena19,
  title = {A {{Neural Network Architecture}} to {{Learn Explicit MPC Controllers}} from {{Data}}},
  author = {Maddalena, E. T. and Moraes, C. G. da S. and Waltrich, G. and Jones, C. N.},
  year = {2019},
  month = nov,
  number = {arXiv:1911.10789},
  eprint = {1911.10789},
  eprinttype = {arxiv},
  primaryclass = {cs, eess},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1911.10789},
  abstract = {We present a methodology to learn explicit Model Predictive Control (eMPC) laws from sample data points with tunable complexity. The learning process is cast in a special Neural Network setting where the coefficients of two linear layers and a parametric quadratic program (pQP) implicit layer are optimized to fit the training data. Thanks to this formulation, powerful tools from the machine learning community can be exploited to speed up the off-line computations through high parallelization. The final controller can be deployed via low-complexity eMPC and the resulting closed-loop system can be certified for stability using existing tools available in the literature. A numerical example on the voltage-current regulation of a multicell DC-DC converter is provided, where the storage and on-line computational demands of the initial controller are drastically reduced with negligible performance impact.},
  archiveprefix = {arXiv},
  keywords = {Electrical Engineering and Systems Science - Systems and Control},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Maddalena et al_2019_A Neural Network Architecture to Learn Explicit MPC Controllers from Data.pdf}
}

@article{maddalena20,
  title = {A {{Neural Network Architecture}} to {{Learn Explicit MPC Controllers}} from {{Data}}},
  author = {Maddalena, E. T. and {da S. Moraes}, C. G. and Waltrich, G. and Jones, C. N.},
  year = {2020},
  month = jan,
  journal = {IFAC-PapersOnLine},
  series = {21st {{IFAC World Congress}}},
  volume = {53},
  number = {2},
  pages = {11362--11367},
  issn = {2405-8963},
  doi = {10.1016/j.ifacol.2020.12.546},
  abstract = {We present a methodology to learn explicit Model Predictive Control (eMPC) laws from sample data points with tunable complexity. The learning process is cast in a special Neural Network setting where the coefficients of two linear layers and a parametric quadratic program (pQP) implicit layer are optimized to fit the training data. Thanks to this formulation, powerful tools from the machine learning community can be exploited to speed up the offline computations through high parallelization. The final controller can be deployed via low-complexity eMPC and the resulting closed-loop system can be certified for stability using existing tools available in the literature. A numerical example on the voltage-current regulation of a multicell DC-DC converter is provided, where the storage and on-line computational demands of the initial controller are drastically reduced with negligible performance impact.},
  langid = {english},
  keywords = {data-driven control,Explicit model predictive control,machine learning,neural networks,power electronics},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Maddalena et al_2020_A Neural Network Architecture to Learn Explicit MPC Controllers from Data⁎⁎This.pdf}
}

@article{mager18,
  title = {High Frequency Neural Spiking and Auditory Signaling by Ultrafast Red-Shifted Optogenetics},
  author = {Mager, Thomas and Morena, David Lopez De La and Senn, Verena and Schlotte, Johannes and Derrico, Anna and Feldbauer, Katrin and Wrobel, Christian and Jung, Sangyong and Bodensiek, Kai and Rankovic, Vladan and Browne, Lorcan and Huet, Antoine and J{\"u}ttner, Josephine and Wood, Phillip G. and Letzkus, Johannes J. and Moser, Tobias and Bamberg, Ernst},
  year = {2018},
  month = may,
  journal = {Nature Communications},
  volume = {9},
  number = {1},
  pages = {1--14},
  publisher = {{Nature Publishing Group}},
  issn = {20411723},
  doi = {10.1038/s41467-018-04146-3},
  abstract = {Optogenetics revolutionizes basic research in neuroscience and cell biology and bears potential for medical applications. We develop mutants leading to a unifying concept for the construction of various channelrhodopsins with fast closing kinetics. Due to different absorption maxima these channelrhodopsins allow fast neural photoactivation over the whole range of the visible spectrum. We focus our functional analysis on the fast-switching, red light-activated Chrimson variants, because red light has lower light scattering and marginal phototoxicity in tissues. We show paradigmatically for neurons of the cerebral cortex and the auditory nerve that the fast Chrimson mutants enable neural stimulation with firing frequencies of several hundred Hz. They drive spiking at high rates and temporal fidelity with low thresholds for stimulus intensity and duration. Optical cochlear implants restore auditory nerve activity in deaf mice. This demonstrates that the mutants facilitate neuroscience research and future medical applications such as hearing restoration.},
  pmid = {29717130},
  keywords = {Cochlea,Ion transport,Optogenetics},
  file = {C\:\\Users\\johns\\Zotero\\storage\\7534I7TD\\Mager et al_2018_High frequency neural spiking and auditory signaling by ultrafast red-shifted.pdf}
}

@article{mao19,
  title = {Single-{{Cell Optogenetic Control}} of {{Calcium Signaling}} with a {{High-Density Micro-LED Array}}},
  author = {Mao, Dacheng and Li, Ningwei and Xiong, Zheshun and Sun, Yubing and Xu, Guangyu},
  year = {2019},
  month = nov,
  journal = {iScience},
  volume = {21},
  pages = {403--412},
  issn = {2589-0042},
  doi = {10.1016/j.isci.2019.10.024},
  abstract = {Precise optogenetic control, ideally down to single cells in dense cell populations, is essential in understanding the heterogeneity of cell networks. Devices with such capability, if built in a chip scale, will advance optogenetic studies at cellular levels in a variety of experimental settings. Here we demonstrate optogenetic control of intracellular Ca2+ dynamics at the single cell level using a 16-{$\mu$}m pitched micro-light emitting diode (LED) array that features high brightness, small spot size, fast response, and low voltage operation. Individual LED pixels are able to reliably trigger intracellular Ca2+ transients, confirmed by fluorescence microscopy and control experiments and cross-checked by two genetically coded Ca2+ indicators. Importantly, our array can optogenetically address individual cells that are sub-10~{$\mu$}m apart in densely packed cell populations. These results suggest the possible use of the micro-LED array toward a lab-on-a-chip for single-cell optogenetics, which may allow for pharmaceutical screening and fundamental studies on a variety of cell networks.},
  langid = {english},
  keywords = {Bioelectronics,Cellular Neuroscience,Electronic Materials,Techniques in Genetics,Techniques in Neuroscience},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Mao et al_2019_Single-Cell Optogenetic Control of Calcium Signaling with a High-Density.pdf}
}

@article{mao21,
  title = {Brushing-{{Assisted Two-Color Quantum-Dot Micro-LED Array Towards Bi-Directional Optogenetics}}},
  author = {Mao, Dacheng and Xiong, Zheshun and Donnelly, Matthew and Xu, Guangyu},
  year = {2021},
  month = oct,
  journal = {IEEE Electron Device Letters},
  volume = {42},
  number = {10},
  pages = {1504--1507},
  issn = {1558-0563},
  doi = {10.1109/LED.2021.3108554},
  abstract = {Bi-directional optogenetics at single-cell level requires localized, bright, and multi-color light sources to activate both excitatory and inhibitory opsins. To this end, here we report a simple fabrication method of high-density, two-color, quantum dot (QD) based micron-sized light emitting diode (micro-LED) arrays. In particular, we micro-patterned InP/ZnS QDs on top of GaN-based micro-LED pixels via a simple brushing method, and coated them with a spectral filter. The resulting array featured sub- \$20 \textbackslash mu \textbackslash textm\$ sized light spots near both 462 nm and 623 nm, with their optical power density being ca. 0.1 \textendash{} 1.0 mW/mm2. Combined with its low crosstalk and fast response, our two-color QD-LED array may hold promise for bi-directional optogenetics ultimately at the cellular level.},
  keywords = {bi-directional optogenetics,Bidirectional control,Crosstalk,Light emitting diodes,micropatterning of quantum dots,Multi-color micro-LED array,Optical crosstalk,Optical device fabrication,Optical filters,Quantum dots},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Mao et al_2021_Brushing-Assisted Two-Color Quantum-Dot Micro-LED Array Towards Bi-Directional.pdf}
}

@article{marmont49,
  title = {Studies on the Axon Membrane. {{I}}. {{A}} New Method},
  author = {Marmont, George},
  year = {1949},
  journal = {Journal of Cellular and Comparative Physiology},
  volume = {34},
  number = {3},
  pages = {351--382},
  issn = {1553-0809},
  doi = {10.1002/jcp.1030340303},
  langid = {english},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/jcp.1030340303},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Marmont_1949_Studies on the axon membrane.pdf}
}

@article{martinez-garcia20,
  title = {Two Dynamically Distinct Circuits Drive Inhibition in the Sensory Thalamus},
  author = {{Martinez-Garcia}, Rosa I. and Voelcker, Bettina and Zaltsman, Julia B. and Patrick, Saundra L. and Stevens, Tanya R. and Connors, Barry W. and Cruikshank, Scott J.},
  year = {2020},
  month = jul,
  journal = {Nature},
  volume = {583},
  number = {7818},
  pages = {813--818},
  publisher = {{Nature Publishing Group}},
  issn = {14764687},
  doi = {10.1038/s41586-020-2512-5},
  abstract = {Most sensory information destined for the neocortex is relayed through the thalamus, where considerable transformation occurs1,2. One means of transformation involves interactions between excitatory thalamocortical neurons that carry data to the cortex and inhibitory neurons of the thalamic reticular nucleus (TRN) that regulate the flow of those data3\textendash 6. Although the importance of the TRN has long been recognised7\textendash 9, understanding of its cell types, their organization and their functional properties has lagged behind that of the thalamocortical systems they control. Here we address this by investigating the somatosensory and visual circuits of the TRN in mice. In the somatosensory TRN we observed two groups of genetically defined neurons that are topographically segregated and physiologically distinct, and that connect reciprocally with independent thalamocortical nuclei through dynamically divergent synapses. Calbindin-expressing cells\textemdash located in the central core\textemdash connect with the ventral posterior nucleus, the primary somatosensory thalamocortical relay. By contrast, somatostatin-expressing cells\textemdash which reside along the surrounding edges of the TRN\textemdash synapse with the posterior medial thalamic nucleus, a higher-order structure that carries both top-down and bottom-up information10\textendash 12. The two TRN cell groups process their inputs in pathway-specific ways. Synapses from the ventral posterior nucleus to central TRN cells transmit rapid excitatory currents that depress deeply during repetitive activity, driving phasic spike output. Synapses from the posterior medial thalamic nucleus to edge TRN cells evoke slower, less depressing excitatory currents that drive more persistent spiking. Differences in the intrinsic physiology of TRN cell types, including state-dependent bursting, contribute to these output dynamics. The processing specializations of these two somatosensory TRN subcircuits therefore appear to be tuned to the signals they carry\textemdash a primary central subcircuit tuned to discrete sensory events, and a higher-order edge subcircuit tuned to temporally distributed signals integrated from multiple sources. The structure and function of visual TRN subcircuits closely resemble those of the somatosensory TRN. These results provide insights into how subnetworks of TRN neurons may differentially process distinct classes of thalamic information.},
  pmid = {32699410},
  keywords = {Cellular neuroscience,Neural circuits,Sensory processing}
}

@article{mathis18,
  title = {{{DeepLabCut}}: Markerless Pose Estimation of User-Defined Body Parts with Deep Learning},
  shorttitle = {{{DeepLabCut}}},
  author = {Mathis, Alexander and Mamidanna, Pranav and Cury, Kevin M. and Abe, Taiga and Murthy, Venkatesh N. and Mathis, Mackenzie Weygandt and Bethge, Matthias},
  year = {2018},
  month = sep,
  journal = {Nature Neuroscience},
  volume = {21},
  number = {9},
  pages = {1281--1289},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-018-0209-y},
  abstract = {Quantifying behavior is crucial for many applications in neuroscience. Videography provides easy methods for the observation and recording of animal behavior in diverse settings, yet extracting particular aspects of a behavior for further analysis can be highly time consuming. In motor control studies, humans or other animals are often marked with reflective markers to assist with computer-based tracking, but markers are intrusive, and the number and location of the markers must be determined a priori. Here we present an efficient method for markerless pose estimation based on transfer learning with deep neural networks that achieves excellent results with minimal training data. We demonstrate the versatility of this framework by tracking various body parts in multiple species across a broad collection of behaviors. Remarkably, even when only a small number of frames are labeled (\textasciitilde 200), the algorithm achieves excellent tracking performance on test frames that is comparable to human accuracy.},
  copyright = {2018 The Author(s)},
  langid = {english},
  keywords = {Behavioural methods,Computational neuroscience,Machine learning},
  file = {C\:\\Users\\johns\\Zotero\\storage\\WW2GSK53\\Mathis et al_2018_DeepLabCut.pdf}
}

@article{mazzoni15a,
  title = {Computing the {{Local Field Potential}} ({{LFP}}) from {{Integrate-and-Fire Network Models}}},
  author = {Mazzoni, Alberto and Lind{\'e}n, Henrik and Cuntz, Hermann and Lansner, Anders and Panzeri, Stefano and Einevoll, Gaute T.},
  year = {2015},
  journal = {PLOS Computational Biology},
  volume = {11},
  number = {12},
  pages = {e1004584},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/JOURNAL.PCBI.1004584},
  abstract = {Leaky integrate-and-fire (LIF) network models are commonly used to study how the spiking dynamics of neural networks changes with stimuli, tasks or dynamic network states. However, neurophysiological studies in vivo often rather measure the mass activity of neuronal microcircuits with the local field potential (LFP). Given that LFPs are generated by spatially separated currents across the neuronal membrane, they cannot be computed directly from quantities defined in models of point-like LIF neurons. Here, we explore the best approximation for predicting the LFP based on standard output from point-neuron LIF networks. To search for this best ``LFP proxy'', we compared LFP predictions from candidate proxies based on LIF network output (e.g, firing rates, membrane potentials, synaptic currents) with ``ground-truth'' LFP obtained when the LIF network synaptic input currents were injected into an analogous three-dimensional (3D) network model of multi-compartmental neurons with realistic morphology, spatial distributions of somata and synapses. We found that a specific fixed linear combination of the LIF synaptic currents provided an accurate LFP proxy, accounting for most of the variance of the LFP time course observed in the 3D network for all recording locations. This proxy performed well over a broad set of conditions, including substantial variations of the neuronal morphologies. Our results provide a simple formula for estimating the time course of the LFP from LIF network simulations in cases where a single pyramidal population dominates the LFP generation, and thereby facilitate quantitative comparison between computational models and experimental LFP recordings in vivo.},
  keywords = {Action potentials,Gamma-aminobutyric acid,Interneurons,Neural networks,Neuronal dendrites,Neuronal morphology,Neurons,Synapses},
  file = {C\:\\Users\\johns\\Zotero\\storage\\95IIUFS8\\Mazzoni et al_2015_Computing the Local Field Potential (LFP) from Integrate-and-Fire Network Models.pdf}
}

@article{mcalinden19,
  title = {Multisite {{microLED}} Optrode Array for Neural Interfacing},
  author = {McAlinden, Niall and Cheng, Yunzhou and Scharf, Robert and Xie, Enyuan and Gu, Erdan and Reiche, Christopher F. and Sharma, Rohit and Tathireddy, Prashant and Tathireddy, Prashant and Rieth, Loren and Blair, Steve and Mathieson, Keith},
  year = {2019},
  month = aug,
  journal = {Neurophotonics},
  volume = {6},
  number = {3},
  pages = {035010},
  publisher = {{SPIE}},
  issn = {2329-423X, 2329-4248},
  doi = {10.1117/1.NPh.6.3.035010},
  abstract = {{$<$}p{$>$}We present an electrically addressable optrode array capable of delivering light to 181 sites in the brain, each providing sufficient light to optogenetically excite thousands of neurons {$<$}italic{$>$}in vivo{$<$}/italic{$>$}, developed with the aim to allow behavioral studies in large mammals. The device is a glass microneedle array directly integrated with a custom fabricated microLED device, which delivers light to 100 needle tips and 81 interstitial surface sites, giving two-level optogenetic excitation of neurons {$<$}italic{$>$}in vivo{$<$}/italic{$>$}. Light delivery and thermal properties are evaluated, with the device capable of peak irradiances \&gt;80 mW / mm\textsuperscript{2} per needle site. The device consists of an array of 181 80 {$\mu$}m \texttimes{} 80 {$\mu$}m\textsuperscript{2} microLEDs, fabricated on a 150-{$\mu$}m-thick GaN-on-sapphire wafer, coupled to a glass needle array on a 150-{$\mu$}m thick backplane. A pinhole layer is patterned on the sapphire side of the microLED array to reduce stray light. Future designs are explored through optical and thermal modeling and benchmarked against the current device.{$<$}/p{$>$}},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\McAlinden et al_2019_Multisite microLED optrode array for neural interfacing.pdf}
}

@article{meikle13,
  title = {Optical Properties of Biological Tissues: A Review},
  author = {Meikle, Steven R and Sossi, Vesna and Roncali, Emilie},
  year = {2013},
  month = may,
  journal = {Physics in Medicine \& Biology},
  volume = {58},
  number = {11},
  pages = {R37},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/58/11/R37},
  abstract = {A review of reported tissue optical properties summarizes the wavelength-dependent behavior of scattering and absorption. Formulae are presented for generating the optical properties of a generic tissue with variable amounts of absorbing chromophores (blood, water, melanin, fat, yellow pigments) and a variable balance between small-scale scatterers and large-scale scatterers in the ultrastructures of cells and tissues. \textcopyright{} 2013 Institute of Physics and Engineering in Medicine.},
  pmid = {23666068},
  file = {C\:\\Users\\johns\\Zotero\\storage\\VS7V2VC3\\Meikle et al_2013_Optical properties of biological tissues.pdf}
}

@article{moldakarimov18,
  title = {Structured Networks Support Sparse Traveling Waves in Rodent Somatosensory Cortex},
  author = {Moldakarimov, Samat and Bazhenov, Maxim and Feldman, Daniel E. and Sejnowski, Terrence J.},
  year = {2018},
  month = may,
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  volume = {115},
  number = {20},
  pages = {5277--5282},
  publisher = {{National Academy of Sciences}},
  issn = {10916490},
  doi = {10.1073/pnas.1710202115},
  abstract = {Neurons responding to different whiskers are spatially intermixed in the superficial layer 2/3 (L2/3) of the rodent barrel cortex, where a single whisker deflection activates a sparse, distributed neuronal population that spans multiple cortical columns. How the superficial layer of the rodent barrel cortex is organized to support such distributed sensory representations is not clear. In a computer model, we tested the hypothesis that sensory representations in L2/3 of the rodent barrel cortex are formed by activity propagation horizontally within L2/3 from a site of initial activation. The model explained the observed properties of L2/3 neurons, including the low average response probability in the majority of responding L2/3 neurons, and the existence of a small subset of reliably responding L2/3 neurons. Sparsely propagating traveling waves similar to those observed in L2/3 of the rodent barrel cortex occurred in the model only when a subnetwork of strongly connected neurons was immersed in a much larger network of weakly connected neurons.},
  pmid = {29712831},
  keywords = {Cortical organization,Sensory cortex,Small-world network,Space–time population code,Traveling wave},
  file = {C\:\\Users\\johns\\Zotero\\storage\\E5VWDMHB\\Moldakarimov et al_2018_Structured networks support sparse traveling waves in rodent somatosensory.pdf;C\:\\Users\\johns\\Zotero\\storage\\KCWNPKWS\\full-text.pdf}
}

@article{montaseri13,
  title = {Synchrony Suppression in Ensembles of Coupled Oscillators via Adaptive Vanishing Feedback},
  author = {Montaseri, Ghazal and Javad Yazdanpanah, Mohammad and Pikovsky, Arkady and Rosenblum, Michael},
  year = {2013},
  month = aug,
  journal = {Chaos},
  volume = {23},
  number = {3},
  pages = {033122},
  publisher = {{American Institute of PhysicsAIP}},
  issn = {10541500},
  doi = {10.1063/1.4817393},
  abstract = {Synchronization and emergence of a collective mode is a general phenomenon, frequently observed in ensembles of coupled self-sustained oscillators of various natures. In several circumstances, in particular in cases of neurological pathologies, this state of the active medium is undesirable. Destruction of this state by a specially designed stimulation is a challenge of high clinical relevance. Typically, the precise effect of an external action on the ensemble is unknown, since the microscopic description of the oscillators and their interactions are not available. We show that, desynchronization in case of a large degree of uncertainty about important features of the system is nevertheless possible; it can be achieved by virtue of a feedback loop with an additional adaptation of parameters. The adaptation also ensures desynchronization of ensembles with non-stationary, time-varying parameters. We perform the stability analysis of the feedback-controlled system and demonstrate efficient destruction of synchrony for several models, including those of spiking and bursting neurons. \textcopyright{} 2013 AIP Publishing LLC.},
  pmid = {24089958},
  keywords = {nonlinear dynamical systems,oscillators,synchronisation},
  file = {C\:\\Users\\johns\\Zotero\\storage\\4KDXX9LU\\full-text.pdf}
}

@article{morcos16,
  title = {History-Dependent Variability in Population Dynamics during Evidence Accumulation in Cortex},
  author = {Morcos, Ari S. and Harvey, Christopher D.},
  year = {2016},
  month = dec,
  journal = {Nature Neuroscience},
  volume = {19},
  number = {12},
  pages = {1672--1681},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/nn.4403},
  abstract = {The authors developed experimental and computational approaches to study moment-to-moment changes in the activity of populations of cortical neurons as mice accumulated evidence during decision-making in virtual reality. They propose that evidence accumulation may not require winner-take-all competitions but instead emerges from general dynamical properties that instantiate short-term memory.},
  copyright = {2016 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  langid = {english},
  keywords = {Decision,Neural circuits},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Morcos_Harvey_2016_History-dependent variability in population dynamics during evidence.pdf}
}

@article{moriyasu22,
  title = {Structured {{Hammerstein-Wiener Model Learning}} for {{Model Predictive Control}}},
  author = {Moriyasu, Ryuta and Ikeda, Taro and Kawaguchi, Sho and Kashima, Kenji},
  year = {2022},
  journal = {IEEE Control Systems Letters},
  volume = {6},
  pages = {397--402},
  issn = {2475-1456},
  doi = {10.1109/LCSYS.2021.3077201},
  abstract = {This letter aims to improve the reliability of optimal control using models constructed by machine learning methods. Optimal control problems based on such models are generally non-convex and difficult to solve online. In this letter, we propose a model that combines the Hammerstein-Wiener model with input convex neural networks, which have recently been proposed in the field of machine learning. An important feature of the proposed model is that resulting optimal control problems are effectively solvable exploiting their convexity and partial linearity while retaining flexible modeling ability. The practical usefulness of the method is examined through its application to the modeling and control of an engine airpath system.},
  keywords = {Atmospheric modeling,Computational modeling,Control design,convex optimization,input convex neural network,Jacobian matrices,machine learning,Machine learning,Model predictive control,Numerical models,Predictive models},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Moriyasu et al_2022_Structured Hammerstein-Wiener Model Learning for Model Predictive Control.pdf}
}

@article{mukamel19,
  title = {Perspectives on Defining Cell Types in the Brain},
  author = {Mukamel, Eran A and Ngai, John},
  year = {2019},
  month = jun,
  journal = {Current Opinion in Neurobiology},
  series = {Neuronal {{Identity}}},
  volume = {56},
  pages = {61--68},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2018.11.007},
  abstract = {The diversity of brain cell types was one of the earliest observations in modern neuroscience and continues to be one of the central concerns of current neuroscience research. Despite impressive recent progress, including single cell transcriptome and epigenome profiling as well as anatomical methods, we still lack a complete census or taxonomy of brain cell types. We argue this is due partly to the conceptual difficulty in defining a cell type. By considering the biological drivers of cell identity, such as networks of genes and gene regulatory elements, we propose a definition of cell type that emphasizes self-stabilizing regulation. We explore the predictions and hypotheses that arise from this definition. Integration of data from multiple modalities, including molecular profiling of genes and gene products, epigenetic landscape, cellular morphology, connectivity, and physiology, will be essential for a meaningful and broadly useful definition of brain cell types.},
  langid = {english},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Mukamel_Ngai_2019_Perspectives on defining cell types in the brain.pdf}
}

@article{muller15,
  title = {Python in Neuroscience},
  author = {Muller, Eilif and Bednar, James A. and Diesmann, Markus and Gewaltig, Marc Oliver and Hines, Michael and Davison, Andrew P.},
  year = {2015},
  month = apr,
  journal = {Frontiers in Neuroinformatics},
  volume = {9},
  number = {APR},
  pages = {11},
  publisher = {{Frontiers Research Foundation}},
  issn = {16625196},
  doi = {10.3389/fninf.2015.00011},
  pmid = {25926788},
  keywords = {Collaboration,Interoperability,Python language,Scientific computing,Software development},
  file = {C\:\\Users\\johns\\Zotero\\storage\\A8JCW2H2\\Muller et al_2015_Python in neuroscience.pdf}
}

@article{muller18,
  title = {Cortical Travelling Waves: {{Mechanisms}} and Computational Principles},
  author = {Muller, Lyle and Chavane, Fr{\'e}d{\'e}ric and Reynolds, John and Sejnowski, Terrence J.},
  year = {2018},
  month = apr,
  journal = {Nature Reviews Neuroscience},
  volume = {19},
  number = {5},
  pages = {255--268},
  publisher = {{Nature Publishing Group}},
  issn = {14710048},
  doi = {10.1038/nrn.2018.20},
  abstract = {Multichannel recording technologies have revealed travelling waves of neural activity in multiple sensory, motor and cognitive systems. These waves can be spontaneously generated by recurrent circuits or evoked by external stimuli. They travel along brain networks at multiple scales, transiently modulating spiking and excitability as they pass. Here, we review recent experimental findings that have found evidence for travelling waves at single-area (mesoscopic) and whole-brain (macroscopic) scales. We place these findings in the context of the current theoretical understanding of wave generation and propagation in recurrent networks. During the large low-frequency rhythms of sleep or the relatively desynchronized state of the awake cortex, travelling waves may serve a variety of functions, from long-term memory consolidation to processing of dynamic visual stimuli. We explore new avenues for experimental and computational understanding of the role of spatiotemporal activity patterns in the cortex.},
  pmid = {29563572},
  file = {C\:\\Users\\johns\\Zotero\\storage\\AADYTQ3J\\Muller et al_2018_Cortical travelling waves.pdf}
}

@article{musall19,
  title = {Harnessing Behavioral Diversity to Understand Neural Computations for Cognition},
  author = {Musall, Simon and Urai, Anne E and Sussillo, David and Churchland, Anne K},
  year = {2019},
  month = oct,
  journal = {Current Opinion in Neurobiology},
  series = {Computational {{Neuroscience}}},
  volume = {58},
  pages = {229--238},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2019.09.011},
  abstract = {With the increasing acquisition of large-scale neural recordings comes the challenge of inferring the computations they perform and understanding how these give rise to behavior. Here, we review emerging conceptual and technological advances that begin to address this challenge, garnering insights from both biological and artificial neural networks. We argue that neural data should be recorded during rich behavioral tasks, to model cognitive processes and estimate latent behavioral variables. Careful quantification of animal movements can also provide a more complete picture of how movements shape neural dynamics and reflect changes in brain state, such as arousal or stress. Artificial neural networks (ANNs) could serve as artificial model organisms to connect neural dynamics and rich behavioral data. ANNs have already begun to reveal how a wide range of different behaviors can be implemented, generating hypotheses about how observed neural activity might drive behavior and explaining diversity in behavioral strategies.},
  langid = {english},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Musall et al_2019_Harnessing behavioral diversity to understand neural computations for cognition.pdf}
}

@article{nandy19,
  title = {Optogenetically Induced Low-Frequency Correlations Impair Perception},
  author = {Nandy, Anirvan and Nassi, Jonathan J. and Jadi, Monika P. and Reynolds, John},
  year = {2019},
  month = feb,
  journal = {eLife},
  volume = {8},
  publisher = {{eLife Sciences Publications Ltd}},
  issn = {2050084X},
  doi = {10.7554/eLife.35123},
  abstract = {Deployment of covert attention to a spatial location can cause large decreases in low- frequency correlated variability among neurons in macaque area V4 whose receptive-fields lie at the attended location. It has been estimated that this reduction accounts for a substantial fraction of the attention-mediated improvement in sensory processing. These estimates depend on assumptions about how population signals are decoded and the conclusion that correlated variability impairs perception, is purely hypothetical. Here we test this proposal directly by optogenetically inducing low-frequency fluctuations, to see if this interferes with performance in an attention-demanding task. We find that low-frequency optical stimulation of neurons in V4 elevates correlations among pairs of neurons and impairs the animal's ability to make fine sensory discriminations. Stimulation at higher frequencies does not impair performance, despite comparable modulation of neuronal responses. These results support the hypothesis that attention- dependent reductions in correlated variability contribute to improved perception of attended stimuli.},
  pmid = {30794156},
  file = {C\:\\Users\\johns\\Zotero\\storage\\CPFSIMVT\\Nandy et al_2019_Optogenetically induced low-frequency correlations impair perception.pdf}
}

@article{nason20,
  title = {A Low-Power Band of Neuronal Spiking Activity Dominated by Local Single Units Improves the Performance of Brain\textendash Machine Interfaces},
  author = {Nason, Samuel R. and Vaskov, Alex K. and Willsey, Matthew S. and Welle, Elissa J. and An, Hyochan and Vu, Philip P. and Bullard, Autumn J. and Nu, Chrono S. and Kao, Jonathan C. and Shenoy, Krishna V. and Jang, Taekwang and Kim, Hun-Seok and Blaauw, David and Patil, Parag G. and Chestek, Cynthia A.},
  year = {2020},
  month = jul,
  journal = {Nature Biomedical Engineering 2020},
  pages = {1--11},
  publisher = {{Nature Publishing Group}},
  issn = {2157-846X},
  doi = {10.1038/s41551-020-0591-0},
  abstract = {The large power requirement of current brain\textendash machine interfaces is a major hindrance to their clinical translation. In basic behavioural tasks, the downsampled magnitude of the 300\textendash 1,000\,Hz band of spiking activity can predict movement similarly to the threshold crossing rate (TCR) at 30 kilo-samples per second. However, the relationship between such a spiking-band power (SBP) and neural activity remains unclear, as does the capability of using the SBP to decode complicated behaviour. By using simulations of recordings of neural activity, here we show that the SBP is dominated by local single-unit spikes with spatial specificity comparable to or better than that of the TCR, and that the SBP correlates better with the firing rates of lower signal-to-noise-ratio units than the TCR. With non-human primates, in an online task involving the one-dimensional decoding of the movement of finger groups and in an offline two-dimensional cursor-control task, the SBP performed equally well or better than the TCR. The SBP may enhance the decoding performance of neural interfaces while enabling substantial cuts in power consumption. The 300\textendash 1,000\,Hz band of spiking activity, dominated by local single-unit spikes, can enhance the decoding performance of neural interfaces.},
  keywords = {Brain,machine interface,Motor cortex},
  file = {C\:\\Users\\johns\\Zotero\\storage\\2ZISTB7K\\Nason et al_2020_A low-power band of neuronal spiking activity dominated by local single units.pdf}
}

@article{nemec20,
  title = {The Evolution of Brain Structure Captured in Stereotyped Cell Count and Cell Type Distributions},
  author = {N{\v e}mec, Pavel and Osten, Pavel},
  year = {2020},
  month = feb,
  journal = {Current Opinion in Neurobiology},
  series = {Neurobiology of {{Behavior}}},
  volume = {60},
  pages = {176--183},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2019.12.005},
  abstract = {The stereotyped features of brain structure, such as the distribution, morphology and connectivity of neuronal cell types across brain areas, are those most likely to explain the remarkable capacity of the brain to process information and govern behaviors. Recent advances in anatomical methods, including the simple but versatile isotropic fractionator and several whole-brain labeling, clearing and microscopy methods, have opened the door to an exciting new era in comparative brain anatomy, one that has the potential to transform our understanding of the brain structure-function relationship by representing the evolution of brain complexity in quantitative anatomical features shared across species and species-specific or clade-specific. Here we discuss these methods and their application to mapping brain cell count and cell type distributions\textemdash two particularly powerful neural correlates of vertebrate cognitive and behavioral capabilities.},
  langid = {english},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Němec_Osten_2020_The evolution of brain structure captured in stereotyped cell count and cell.pdf}
}

@article{newman13,
  title = {Closed-{{Loop}}, {{Multichannel Experimentation Using}} the {{Open-Source NeuroRighter Electrophysiology Platform}}},
  author = {Newman, Jonathan and {Zeller-Townson}, Riley and Fong, Ming-fai and Arcot Desai, Sharanya and Gross, Robert and Potter, Steve},
  year = {2013},
  journal = {Frontiers in Neural Circuits},
  volume = {6},
  issn = {1662-5110},
  abstract = {Single neuron feedback control techniques, such as voltage clamp and dynamic clamp, have enabled numerous advances in our understanding of ion channels, electrochemical signaling, and neural dynamics. Although commercially available multichannel recording and stimulation systems are commonly used for studying neural processing at the network level, they provide little native support for real-time feedback. We developed the open-source NeuroRighter multichannel electrophysiology hardware and software platform for closed-loop multichannel control with a focus on accessibility and low cost. NeuroRighter allows 64 channels of stimulation and recording for around US \$10,000, along with the ability to integrate with other software and hardware. Here, we present substantial enhancements to the NeuroRighter platform, including a redesigned desktop application, a new stimulation subsystem allowing arbitrary stimulation patterns, low-latency data servers for accessing data streams, and a new application programming interface (API) for creating closed-loop protocols that can be inserted into NeuroRighter as plugin programs. This greatly simplifies the design of sophisticated real-time experiments without sacrificing the power and speed of a compiled programming language. Here we present a detailed description of NeuroRighter as a stand-alone application, its plugin API, and an extensive set of case studies that highlight the system's abilities for conducting closed-loop, multichannel interfacing experiments.},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Newman et al_2013_Closed-Loop, Multichannel Experimentation Using the Open-Source NeuroRighter.pdf}
}

@article{newman15,
  title = {Optogenetic Feedback Control of Neural Activity},
  author = {Newman, Jonathan P. and Fong, Ming Fai and Millard, Daniel C. and Whitmire, Clarissa J. and Stanley, Garrett B. and Potter, Steve M.},
  year = {2015},
  journal = {eLife},
  issn = {2050084X},
  doi = {10.7554/eLife.07192},
  abstract = {Optogenetic techniques enable precise excitation and inhibition of firing in specified neuronal populations and artifact-free recording of firing activity. Several studies have suggested that optical stimulation provides the precision and dynamic range requisite for closed-loop neuronal control, but no approach yet permits feedback control of neuronal firing. Here we present the `optoclamp', a feedback control technology that provides continuous, real-time adjustments of bidirectional optical stimulation in order to lock spiking activity at specified targets over timescales ranging from seconds to days. We demonstrate how this system can be used to decouple neuronal firing levels from ongoing changes in network excitability due to multi-hour periods of glutamatergic or GABAergic neurotransmission blockade in vitro as well as impinging vibrissal sensory drive in vivo. This technology enables continuous, precise optical control of firing in neuronal populations in order to disentangle causally related variables of circuit activation in a physiologically and ethologically relevant manner.},
  pmid = {26140329},
  file = {C\:\\Users\\johns\\Zotero\\storage\\Q4JFWP2N\\Newman et al_2015_Optogenetic feedback control of neural activity.pdf}
}

@article{neymotin20,
  title = {Human Neocortical Neurosolver ({{HNN}}), a New Software Tool for Interpreting the Cellular and Network Origin of Human {{MEG}}/{{EEG}} Data},
  author = {Neymotin, Samuel A. and Daniels, Dylan S. and Caldwell, Blake and McDougal, Robert A. and Carnevale, Nicholas T. and Jas, Mainak and Moore, Christopher I. and Hines, Michael L. and H{\"a}m{\"a}l{\"a}inen, Matti and Jones, Stephanie R.},
  year = {2020},
  month = jan,
  journal = {eLife},
  volume = {9},
  publisher = {{eLife Sciences Publications Ltd}},
  issn = {2050084X},
  doi = {10.7554/eLife.51214},
  abstract = {Magneto-and electro-encephalography (MEG/EEG) non-invasively record human brain activity with millisecond resolution providing reliable markers of healthy and disease states. Relating these macroscopic signals to underlying cellular-and circuit-level generators is a limitation that constrains using MEG/EEG to reveal novel principles of information processing or to translate findings into new therapies for neuropathology. To address this problem, we built Human Neocortical Neurosolver (HNN, https://hnn.brown.edu) software. HNN has a graphical user interface designed to help researchers and clinicians interpret the neural origins of MEG/EEG. HNN's core is a neocortical circuit model that accounts for biophysical origins of electrical currents generating MEG/EEG. Data can be directly compared to simulated signals and parameters easily manipulated to develop/test hypotheses on a signal's origin. Tutorials teach users to simulate commonly measured signals, including event related potentials and brain rhythms. HNN's ability to associate signals across scales makes it a unique tool for translational neuroscience research.},
  pmid = {31967544},
  file = {C\:\\Users\\johns\\Zotero\\storage\\RSPICSCM\\elife_51214_pdf.pdf}
}

@inproceedings{nikolic13,
  title = {Computational Models of Optogenetic Tools for Controlling Neural Circuits with Light},
  booktitle = {Proceedings of the {{Annual International Conference}} of the {{IEEE Engineering}} in {{Medicine}} and {{Biology Society}}, {{EMBS}}},
  author = {Nikolic, Konstantin and Jarvis, Sarahfs and Grossman, Nir and Schultz, Simon},
  year = {2013},
  pages = {5934--5937},
  issn = {1557170X},
  doi = {10.1109/EMBC.2013.6610903},
  abstract = {Optogenetics is a new neurotechnology innovation based on the creation of light sensitivity of neurons using gene technologies and remote light activation. Optogenetics allows for the first time straightforward targeted neural stimulation with practically no interference between multiple stimulation points since either light beam can be finely confined or the expression of light sensitive ion channels and pumps can be genetically targeted. Here we present a generalised computational modeling technique for various types of optogenetic mechanisms, which was implemented in the NEURON simulation environment. It was demonstrated on the example of a two classical mechanisms for cells optical activation and silencing: channelrhodopsin-2 (ChR2) and halorhodopsin (NpHR).We theoretically investigate the dynamics of the neural response of a layer 5 cortical pyramidal neuron (L5) to four different types of illuminations: 1) wide-field whole cell illumination 2) wide-field apical dendritic illumination 3) focal somatic illumination and 4) focal axon initial segment (AIS) illumination. We show that whole-cell illumination of halorhodopsin most effectively hyperpolarizes the neuron and is able to silence the cell even when driving input is present. However, when channelrhodopsin-2 and halorhodopsin are concurrently active, the relative location of each illumination determines whether the response is modulated with a balance towards depolarization. The methodology developed in this study will be significant to interpret and design optogenetic experiments and in the field of neuroengineering in general. \textcopyright{} 2013 IEEE.},
  isbn = {978-1-4577-0216-7},
  file = {C\:\\Users\\johns\\Zotero\\storage\\KMM62WGP\\Nikolic et al_2013_Computational models of optogenetic tools for controlling neural circuits with.pdf}
}

@article{oby19,
  title = {New Neural Activity Patterns Emerge with Long-Term Learning},
  author = {Oby, Emily R. and Golub, Matthew D. and Hennig, Jay A. and Degenhart, Alan D. and {Tyler-Kabara}, Elizabeth C. and Yu, Byron M. and Chase, Steven M. and Batista, Aaron P.},
  year = {2019},
  month = jul,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {116},
  number = {30},
  pages = {15210--15215},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.1820296116},
  file = {C\:\\Users\\johns\\Zotero\\storage\\BGVFL6EZ\\Oby et al_2019_New neural activity patterns emerge with long-term learning.pdf}
}

@article{ohta21,
  title = {Micro-{{LED Array-Based Photo-Stimulation Devices}} for {{Optogenetics}} in {{Rat}} and {{Macaque Monkey Brains}}},
  author = {Ohta, Yasumi and Guinto, Mark Christian and Tokuda, Takashi and Kawahara, Mamiko and Haruta, Makito and Takehara, Hironari and Tashiro, Hiroyuki and Sasagawa, Kiyotaka and Onoe, Hirotaka and Yamaguchi, Reona and Koshimizu, Yoshinori and Isa, Kaoru and Isa, Tadashi and Kobayashi, Kenta and Akay, Yasemin M. and Akay, Metin and Ohta, Jun},
  year = {2021},
  journal = {IEEE Access},
  volume = {9},
  pages = {127937--127949},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2021.3111666},
  abstract = {Optogenetics is a powerful tool for controlling biological functions using light. Optical fibers have been extensively utilized in optical stimulation devices for optogenetics. However, the use of optical fibers results in a small photo-stimulation region. In this study, micro-LED array devices were developed to achieve large-area photo-stimulation in the brain of a large animal, such as macaque monkeys. Planar and linear micro-LED array devices were designed and fabricated to photo-stimulate the prefrontal cortex (PFC) and ventral tegmental area (VTA) of the brain and induce a neurochemical response. Device operation, optical intensity, and safety were first characterized using rats. Subsequently, the devices were used to photo-stimulate the brain of macaque monkeys. In addition, microdialysis in the PFC was performed. The devices detected modulated levels of dopamine in the brains. Thus, the photo-stimulation of both the PFC and VTA were successfully achieved, and the effectiveness of the developed micro-LED array devices was demonstrated. The study will help facilitate further studies on micro-LED array stimulation for system-wide optogenetic manipulation in large animals.},
  keywords = {Animals,Brain,dopamine,implantation,light emitting diodes,Light emitting diodes,macaque monkeys,microdialysis,Neurons,optogenetics,photo-stimulation,Radio access technologies,Rats,Stimulated emission},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Ohta et al_2021_Micro-LED Array-Based Photo-Stimulation Devices for Optogenetics in Rat and.pdf}
}

@article{ortiz21,
  title = {A Visual Introduction to {{Gaussian Belief Propagation}}},
  author = {Ortiz, Joseph and Evans, Talfan and Davison, Andrew J.},
  year = {2021},
  month = jul,
  eprint = {2107.02308},
  eprinttype = {arxiv},
  doi = {10.48550/arxiv.2107.02308},
  abstract = {In this article, we present a visual introduction to Gaussian Belief Propagation (GBP), an approximate probabilistic inference algorithm that operates by passing messages between the nodes of arbitrarily structured factor graphs. A special case of loopy belief propagation, GBP updates rely only on local information and will converge independently of the message schedule. Our key argument is that, given recent trends in computing hardware, GBP has the right computational properties to act as a scalable distributed probabilistic inference framework for future machine learning systems.},
  archiveprefix = {arXiv},
  file = {C\:\\Users\\johns\\Zotero\\storage\\NY4B9REB\\Ortiz et al_2021_A visual introduction to Gaussian Belief Propagation.pdf}
}

@article{packer13,
  title = {Targeting Neurons and Photons for Optogenetics},
  author = {Packer, Adam M. and Roska, Botond and H{\"a}user, Michael},
  year = {2013},
  month = jun,
  journal = {Nature Neuroscience},
  volume = {16},
  number = {7},
  pages = {805--815},
  publisher = {{Nature Publishing Group}},
  issn = {15461726},
  doi = {10.1038/nn.3427},
  abstract = {Optogenetic approaches promise to revolutionize neuroscience by using light to manipulate neural activity in genetically or functionally defined neurons with millisecond precision. Harnessing the full potential of optogenetic tools, however, requires light to be targeted to the right neurons at the right time. Here we discuss some barriers and potential solutions to this problem. We review methods for targeting the expression of light-activatable molecules to specific cell types, under genetic, viral or activity-dependent control. Next we explore new ways to target light to individual neurons to allow their precise activation and inactivation. These techniques provide a precision in the temporal and spatial activation of neurons that was not achievable in previous experiments. In combination with simultaneous recording and imaging techniques, these strategies will allow us to mimic the natural activity patterns of neurons in vivo, enabling previously impossible 'dream experiments'. \textcopyright{} 2013 Nature America, Inc. All rights reserved.},
  pmid = {23799473},
  keywords = {Neuroscience},
  file = {C\:\\Users\\johns\\Zotero\\storage\\9J2EU342\\Packer et al_2013_Targeting neurons and photons for optogenetics.pdf}
}

@article{packer15,
  title = {Simultaneous All-Optical Manipulation and Recording of Neural Circuit Activity with Cellular Resolution in Vivo},
  author = {Packer, Adam M. and Russell, Lloyd E. and Dalgleish, Henry W. P. and H{\"a}usser, Michael},
  year = {2015},
  month = feb,
  journal = {Nature Methods},
  volume = {12},
  number = {2},
  pages = {140--146},
  publisher = {{Nature Publishing Group}},
  issn = {1548-7105},
  doi = {10.1038/nmeth.3217},
  abstract = {Here, the authors present an approach for the simultaneous optogenetic manipulation and recording of neural activity at cellular resolution using two-photon microscopy and apply their strategy in the mouse barrel cortex.},
  copyright = {2014 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  langid = {english},
  keywords = {Fluorescence imaging,Neuroscience,Optogenetics},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Packer et al_2015_Simultaneous all-optical manipulation and recording of neural circuit activity.pdf}
}

@article{pandarinath18,
  title = {Inferring Single-Trial Neural Population Dynamics Using Sequential Auto-Encoders},
  author = {Pandarinath, Chethan and O'Shea, Daniel J. and Collins, Jasmine and Jozefowicz, Rafal and Stavisky, Sergey D. and Kao, Jonathan C. and Trautmann, Eric M. and Kaufman, Matthew T. and Ryu, Stephen I. and Hochberg, Leigh R. and Henderson, Jaimie M. and Shenoy, Krishna V. and Abbott, L. F. and Sussillo, David},
  year = {2018},
  month = oct,
  journal = {Nature Methods},
  volume = {15},
  number = {10},
  pages = {805--815},
  publisher = {{Nature Publishing Group}},
  issn = {1548-7091},
  doi = {10.1038/s41592-018-0109-9},
  abstract = {Neuroscience is experiencing a revolution in which simultaneous recording of thousands of neurons is revealing population dynamics that are not apparent from single-neuron responses. This structure is typically extracted from data averaged across many trials, but deeper understanding requires studying phenomena detected in single trials, which is challenging due to incomplete sampling of the neural population, trial-to-trial variability, and fluctuations in action potential timing. We introduce latent factor analysis via dynamical systems, a deep learning method to infer latent dynamics from single-trial neural spiking data. When applied to a variety of macaque and human motor cortical datasets, latent factor analysis via dynamical systems accurately predicts observed behavioral variables, extracts precise firing rate estimates of neural dynamics on single trials, infers perturbations to those dynamics that correlate with behavioral choices, and combines data from non-overlapping recording sessions spanning months to improve inference of underlying dynamics.},
  keywords = {Computational neuroscience,Machine learning,Motor control},
  file = {C\:\\Users\\johns\\Zotero\\storage\\TQ4ZSRZ8\\Pandarinath et al_2018_Inferring single-trial neural population dynamics using sequential auto-encoders.pdf}
}

@article{parasuram16,
  title = {Computational Modeling of Single Neuron Extracellular Electric Potentials and Network Local Field Potentials Using {{LFPsim}}},
  author = {Parasuram, Harilal and Nair, Bipin and D'Angelo, Egidio and Hines, Michael and Naldi, Giovanni and Diwakar, Shyam},
  year = {2016},
  month = jun,
  journal = {Frontiers in Computational Neuroscience},
  volume = {10},
  number = {Jun},
  pages = {65},
  publisher = {{Frontiers Research Foundation}},
  issn = {16625188},
  doi = {10.3389/fncom.2016.00065},
  abstract = {Local Field Potentials (LFPs) are population signals generated by complex spatiotemporal interaction of current sources and dipoles. Mathematical computations of LFPs allow the study of circuit functions and dysfunctions via simulations. This paper introduces LFPsim, a NEURON-based tool for computing population LFP activity and single neuron extracellular potentials. LFPsim was developed to be used on existing cable compartmental neuron and network models. Point source, line source, and RC based filter approximations can be used to compute extracellular activity. As a demonstration of efficient implementation, we showcase LFPs from mathematical models of electrotonically compact cerebellum granule neurons and morphologically complex neurons of the neocortical column. LFPsim reproduced neocortical LFP at 8, 32, and 56 Hz via current injection, in vitro post-synaptic N2a, N2b waves and in vivo T-C waves in cerebellum granular layer. LFPsim also includes a simulation of multi-electrode array of LFPs in network populations to aid computational inference between biophysical activity in neural networks and corresponding multi-unit activity resulting in extracellular and evoked LFP signals.},
  keywords = {Cerebellum,Circuit,Computational neuroscience,Local Field Potential,Neocortex,Neuron,Simulation},
  file = {C\:\\Users\\johns\\Zotero\\storage\\GD6VSBSZ\\Parasuram et al_2016_Computational modeling of single neuron extracellular electric potentials and.pdf}
}

@book{pearl09,
  title = {Causality},
  author = {Pearl, Judea},
  year = {2009},
  publisher = {{Cambridge University Press}},
  address = {{New York}},
  doi = {10.1017/CBO9780511803161},
  abstract = {Written by one of the preeminent researchers in the field, this book provides a comprehensive exposition of modern analysis of causation. It shows how causality has grown from a nebulous concept into a mathematical theory with significant applications in the fields of statistics, artificial intelligence, economics, philosophy, cognitive science, and the health and social sciences. Judea Pearl presents and unifies the probabilistic, manipulative, counterfactual, and structural approaches to causation and devises simple mathematical tools for studying the relationships between causal connections and statistical associations. Cited in more than 2,100 scientific publications, it continues to liberate scientists from the traditional molds of statistical thinking. In this revised edition, Judea Pearl elucidates thorny issues, answers readers' questions, and offers a panoramic view of recent advances in this field of research. Causality will be of interest to students and professionals in a wide variety of fields. Dr Judea Pearl has received the 2011 Rumelhart Prize for his leading research in Artificial Intelligence (AI) and systems from The Cognitive Science Society.},
  isbn = {978-0-521-89560-6},
  langid = {english},
  keywords = {Causation,Probabilities}
}

@inproceedings{pearl10,
  title = {Causal {{Inference}}},
  booktitle = {Proceedings of {{Workshop}} on {{Causality}}: {{Objectives}} and {{Assessment}} at {{NIPS}} 2008},
  author = {Pearl, Judea},
  year = {2010},
  month = feb,
  pages = {39--58},
  publisher = {{PMLR}},
  issn = {1938-7228},
  abstract = {This paper reviews a theory of causal inference based on the Structural Causal Model (SCM) described in Pearl (2000a). The theory unifies the graphical, potential-outcome (Neyman-Rubin), decision analytical, and structural equation approaches to causation, and provides both a mathematical foundation and a friendly calculus for the analysis of causes and counterfactuals. In particular, the paper establishes a methodology for inferring (from a combination of data and assumptions) the answers to three types of causal queries: (1) queries about the effect of potential interventions, (2) queries about counterfactuals, and (3) queries about the direct (or indirect) effect of one event on another.},
  langid = {english},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Pearl_2010_Causal Inference.pdf}
}

@article{peixoto21,
  title = {Decoding and Perturbing Decision States in Real Time},
  author = {Peixoto, Diogo and Verhein, Jessica R and Kiani, Roozbeh and Kao, Jonathan C and Nuyujukian, Paul and Chandrasekaran, Chandramouli and Brown, Julian and Fong, Sania and Ryu, Stephen I and Shenoy, Krishna V and Newsome, William T},
  year = {2021},
  journal = {Nature},
  volume = {591},
  number = {7851},
  pages = {604--609},
  issn = {14764687},
  doi = {10.1038/s41586-020-03181-9},
  abstract = {In dynamic environments, subjects often integrate multiple samples of a signal and combine them to reach a categorical judgment1. The process of deliberation can be described by a time-varying decision variable (DV), decoded from neural population activity, that predicts a subject's upcoming decision2. Within single trials, however, there are large moment-to-moment fluctuations in the DV, the behavioural significance of which is unclear. Here, using real-time, neural feedback control of stimulus duration, we show that within-trial DV fluctuations, decoded from motor cortex, are tightly linked to decision state in macaques, predicting behavioural choices substantially better than the condition-averaged DV or the visual stimulus alone. Furthermore, robust changes in DV sign have the statistical regularities expected from behavioural studies of changes of mind3. Probing the decision process on single trials with weak stimulus pulses, we find evidence for time-varying absorbing decision bounds, enabling us to distinguish between specific models of decision making.},
  pmid = {33473215},
  file = {C\:\\Users\\johns\\Zotero\\storage\\QGEP45AB\\Peixoto et al_2021_Decoding and perturbing decision states in real time.pdf}
}

@article{peng19,
  title = {High-Throughput Microcircuit Analysis of Individual Human Brains through next-Generation Multineuron Patch-Clamp},
  author = {Peng, Yangfan and Mittermaier, Franz Xaver and Planert, Henrike and Schneider, Ulf Christoph and Alle, Henrik and Geiger, J{\"o}rg Rolf Paul},
  year = {2019},
  month = nov,
  journal = {eLife},
  volume = {8},
  pages = {e48178},
  issn = {2050-084X},
  doi = {10.7554/eLife.48178},
  abstract = {Comparing neuronal microcircuits across different brain regions, species and individuals can reveal common and divergent principles of network computation. Simultaneous patch-clamp recordings from multiple neurons offer the highest temporal and subthreshold resolution to analyse local synaptic connectivity. However, its establishment is technically complex and the experimental performance is limited by high failure rates, long experimental times and small sample sizes. We introduce an in vitro multipatch setup with an automated pipette pressure and cleaning system facilitating recordings of up to 10 neurons simultaneously and sequential patching of additional neurons. We present hardware and software solutions that increase the usability, speed and data throughput of multipatch experiments which allowed probing of 150 synaptic connections between 17 neurons in one human cortical slice and screening of over 600 connections in tissue from a single patient. This method will facilitate the systematic analysis of microcircuits and allow unprecedented assessment of inter-individual variability.},
  pmcid = {PMC6894931},
  pmid = {31742558},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Peng et al_High-throughput microcircuit analysis of individual human brains through.pdf}
}

@article{pettersen12,
  title = {Extracellular Spikes and {{CSD}}},
  author = {Pettersen, Klas H and Lind{\'e}n, Henrik and Dale, Anders M and Einevoll, Gaute T},
  year = {2012},
  journal = {Handbook of neural activity measurement},
  volume = {1},
  pages = {92--135},
  publisher = {{Cambridge University Press Cambridge, UK}},
  keywords = {★},
  file = {C\:\\Users\\johns\\Zotero\\storage\\IY57KAPZ\\Pettersen et al_2012_Extracellular spikes and CSD.pdf}
}

@article{potter14,
  title = {Closed-Loop Neuroscience and Neuroengineering},
  author = {Potter, Steve M. and El Hady, Ahmed and Fetz, Eberhard E.},
  year = {2014},
  journal = {Frontiers in Neural Circuits},
  volume = {0},
  pages = {115},
  publisher = {{Frontiers}},
  issn = {1662-5110},
  doi = {10.3389/FNCIR.2014.00115},
  keywords = {BCI,bidirectional BCI,Brain-computer interface,CMOS,Control,Deep Brain Stimulation,Feedback,in vitro,MEA,microelectrode array,Movement,Multi-Electrode Array,on-line,Real-time,stimulation,Theory},
  file = {C\:\\Users\\johns\\Zotero\\storage\\47E9WJMX\\Potter et al_2014_Closed-loop neuroscience and neuroengineering.pdf}
}

@article{prinz04,
  title = {The Dynamic Clamp Comes of Age},
  author = {Prinz, Astrid A and Abbott, L. F and Marder, Eve},
  year = {2004},
  month = apr,
  journal = {Trends in Neurosciences},
  volume = {27},
  number = {4},
  pages = {218--224},
  issn = {0166-2236},
  doi = {10.1016/j.tins.2004.02.004},
  abstract = {The dynamic clamp uses computer simulation to introduce artificial membrane or synaptic conductances into biological neurons and to create hybrid circuits of real and model neurons. In the ten years since it was first developed, the dynamic clamp has become a widely used tool for the study of neural systems at the cellular and circuit levels. This review describes recent state-of-the-art implementations of the dynamic clamp and summarizes insights gained through its use, ranging from the role of voltage-dependent conductances in shaping neuronal activity to the effects of synaptic dynamics on network behavior and the impact of in vivo-like input on neuronal information processing.},
  langid = {english}
}

@article{prsa17,
  title = {Rapid {{Integration}} of {{Artificial Sensory Feedback}} during {{Operant Conditioning}} of {{Motor Cortex Neurons}}},
  author = {Prsa, Mario and Gali{\~n}anes, Gregorio L. and Huber, Daniel},
  year = {2017},
  month = feb,
  journal = {Neuron},
  volume = {93},
  number = {4},
  pages = {929-939.e6},
  publisher = {{Cell Press}},
  issn = {10974199},
  doi = {10.1016/j.neuron.2017.01.023},
  abstract = {Neuronal motor commands, whether generating real~or neuroprosthetic movements, are shaped by ongoing sensory feedback from the displacement being produced. Here we asked if cortical stimulation could provide artificial feedback during operant conditioning of cortical neurons. Simultaneous two-photon imaging and real-time optogenetic stimulation were used to train mice to activate a single neuron in motor cortex (M1), while continuous feedback of its activity level was provided by proportionally stimulating somatosensory cortex. This artificial signal was necessary to rapidly learn to increase the conditioned activity, detect correct performance, and maintain the learned behavior. Population imaging in M1 revealed that learning-related activity changes are observed in the conditioned cell only, which highlights the functional potential of individual neurons in the neocortex. Our findings demonstrate the capacity of animals to use an artificially induced cortical channel in a behaviorally relevant way and reveal the remarkable speed and specificity at which this can occur.},
  pmid = {28231470},
  keywords = {all-optical,artificial feedback,brain-machine interface,in cerebro learning,motor learning,neurofeedback,neuroprosthetics,operant conditioning,optogenetic stimulation,two-photon imaging},
  file = {C\:\\Users\\johns\\Zotero\\storage\\X89U485H\\Prsa et al_2017_Rapid Integration of Artificial Sensory Feedback during Operant Conditioning of.pdf}
}

@article{qiu20,
  title = {Explicit {{MPC Based}} on the {{Galerkin Method}} for {{AGC Considering Volatile Generations}}},
  author = {Qiu, Yiwei and Lin, Jin and Liu, Feng and Song, Yonghua},
  year = {2020},
  month = jan,
  journal = {IEEE Transactions on Power Systems},
  volume = {35},
  number = {1},
  pages = {462--473},
  issn = {1558-0679},
  doi = {10.1109/TPWRS.2019.2934318},
  abstract = {The imbalance of generation and load caused by the increasing integration of volatile generations poses challenges on frequency regulation. AGC is required to respond to the generation fluctuations without violating operational and security constraints. Explicit model predictive control (EMPC) provides an approach to reaching such requirements, which calculates the control laws of MPC in an explicit form, allowing for offline validation of the controller and enabling fast online computation. However, the partition number of EMPC's piecewise affine control laws grows exponentially with the number of constraints and prediction/control horizons, which hinders its application in large systems. In this paper, we propose an alternative explicit control approach for AGC by approximating the control laws of EMPC using Legendre polynomial series expansions, thus entirely eliminating the partition issue. The Galerkin method is applied to the KKT conditions of EMPC's multiparametric quadratic programming (mp-QP) problem to compute the approximation. Case studies in an illustrative system and IEEE 118-Bus System verify the performance and efficiency of the proposed controller.},
  keywords = {Automatic generation control,explicit model predictive control,Frequency control,galerkin projection,legendre polynomials,Method of moments,multi-parametric programming,optimal control,Optimal control,Optimization,Power system dynamics,Predictive control,spectral method},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Qiu et al_2020_Explicit MPC Based on the Galerkin Method for AGC Considering Volatile.pdf}
}

@article{quachio17,
  title = {{{MPC Relevant Identification Method}} for {{Hammerstein Models}}},
  author = {Quachio, Raphael and Garcia, Claudio},
  year = {2017},
  month = dec,
  journal = {IFAC-PapersOnLine},
  series = {Control {{Conference Africa CCA}} 2017},
  volume = {50},
  number = {2},
  pages = {47--52},
  issn = {2405-8963},
  doi = {10.1016/j.ifacol.2017.12.009},
  abstract = {MPC Controllers are widely applied in the process industry, notably in Oil Refining and Petrochemical processes. MPC Relevant Identification (MRI) methods have been developed to identify models suitable for linear MPC controllers. However, most chemical processes exhibit nonlinear dynamics, for which linear MPC controllers are suitable only for a limited operating range. This paper presents an MRI method for obtaining nonlinear models with polynomial Hammerstein structure. The algorithm is applied in the identification of data from an electric heater. The obtained results indicate that the proposed method generated satisfactory results.},
  langid = {english},
  keywords = {Hammerstein Models,MPC Relevant Identification,System Identification},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Quachio_Garcia_2017_MPC Relevant Identification Method for Hammerstein Models.pdf}
}

@article{rackauckas17,
  title = {{{DifferentialEquations}}.Jl \textendash{} {{A Performant}} and {{Feature-Rich Ecosystem}} for {{Solving Differential Equations}} in {{Julia}}},
  author = {Rackauckas, Christopher and Nie, Qing},
  year = {2017},
  month = may,
  journal = {Journal of Open Research Software},
  volume = {5},
  number = {1},
  pages = {15},
  publisher = {{Ubiquity Press}},
  issn = {2049-9647},
  doi = {10.5334/jors.151},
  abstract = {Article: DifferentialEquations.jl \textendash{} A Performant and Feature-Rich Ecosystem for Solving Differential Equations in Julia},
  copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are \textcopyright, \textregistered{} or \texttrademark{} of their respective owners. No challenge to any owner's rights is intended or should be inferred.},
  langid = {english},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Rackauckas_Nie_2017_DifferentialEquations.pdf}
}

@article{rajalingham22,
  title = {Recurrent Neural Networks with Explicit Representation of Dynamic Latent Variables Can Mimic Behavioral Patterns in a Physical Inference Task},
  author = {Rajalingham, Rishi and Piccato, A{\'i}da and Jazayeri, Mehrdad},
  year = {2022},
  month = oct,
  journal = {Nature Communications},
  volume = {13},
  number = {1},
  pages = {1--15},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-33581-6},
  abstract = {Primates can richly parse sensory inputs to infer latent information. This ability is hypothesized to rely on establishing mental models of the external world and running mental simulations of those models. However, evidence supporting this hypothesis is limited to behavioral models that do not emulate neural computations. Here, we test this hypothesis by directly comparing the behavior of primates (humans and monkeys) in a ball interception task to that of a large set of recurrent neural network (RNN) models with or without the capacity to dynamically track the underlying latent variables. Humans and monkeys exhibit similar behavioral patterns. This primate behavioral pattern is best captured by RNNs endowed with dynamic inference, consistent with the hypothesis that the primate brain uses dynamic inferences to support flexible physical predictions. Moreover, our work highlights a general strategy for using model neural systems to test computational hypotheses of higher brain function. The ability to infer the dynamics of physical objects is hypothesized to rely on running simulations of mental models. Here, the authors test this hypothesis by comparing human and monkey behavior to recurrent neural network models in a physical inference task.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Cognitive neuroscience,Network models},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Rajalingham et al_2022_Recurrent neural networks with explicit representation of dynamic latent.pdf}
}

@inproceedings{rajendran21,
  title = {Computational {{Reconstructions}} of {{Extracellular Action Potentials}} and {{Local Field Potentials}} of a {{Rat Cerebellum Using Point Neurons}}},
  booktitle = {Lecture {{Notes}} in {{Electrical Engineering}}},
  author = {Rajendran, Arathi and Sargurunathan, Naveen Kumar and Menon, Varadha Sasi and Variyath, Sneha and Sai, Satram Dayamai and Diwakar, Shyam},
  year = {2021},
  volume = {736 LNEE},
  pages = {3--13},
  publisher = {{Springer, Singapore}},
  issn = {18761119},
  doi = {10.1007/978-981-33-6987-0_1},
  abstract = {One of the main challenges in computational modeling of neurons is to reconstruct the realistic behavior of the neurons of the brain under different functional conditions. At the same time, simulation of large networks is time-consuming and requires huge computational power. The use of spiking neuron models could reduce the computational cost and time. In this study, the extracellular potentials were reconstructed from a single point neuron model of cerebellum granule neuron, and local field potentials (LFP) were modeled. Realistic reconstruction of cerebellum Crus II evoked post-synaptic local field potentials using simple models of granule neurons help to explore emergent behavior attributing patterns of information flow in the granule layer of the cerebellum. The modeling suggests that the evoked extracellular action potential (EAP) arises from the transmembrane currents correlating spiking activity and conductive properties of the extracellular medium to the LFP. The computation study reproduces experimentally observed in vitro N2a and N2b evoked LFP waves and can be used to test the scaling of models developed from a bottom-up approach.},
  isbn = {978-981-336-986-3},
  keywords = {Cerebellum,Computational biology,Extracellular,Local field potential,Modeling,Neuron}
}

@article{ramot22,
  title = {Closed-Loop Neuromodulation for Studying Spontaneous Activity and Causality},
  author = {Ramot, Michal and Martin, Alex},
  year = {2022},
  month = apr,
  journal = {Trends in Cognitive Sciences},
  volume = {26},
  number = {4},
  pages = {290--299},
  publisher = {{Elsevier}},
  issn = {1879307X},
  doi = {10.1016/j.tics.2022.01.008},
  abstract = {Having established that spontaneous brain activity follows meaningful coactivation patterns and correlates with behavior, researchers have turned their attention to understanding its function and behavioral significance. We suggest closed-loop neuromodulation as a neural perturbation tool uniquely well suited for this task. Closed-loop neuromodulation has primarily been viewed as an interventionist tool to teach subjects to directly control their own brain activity. We examine an alternative operant conditioning model of closed-loop neuromodulation which, through implicit feedback, can manipulate spontaneous activity at the network level, without violating the spontaneous or endogenous nature of the signal, thereby providing a direct test of network causality.},
  pmid = {35210175},
  keywords = {causality,implicit learning,neurofeedback,perturbation,spontaneous activity}
}

@article{reimann13,
  title = {A Biophysically Detailed Model of Neocortical Local Field Potentials Predicts the Critical Role of Active Membrane Currents},
  author = {Reimann, Michael W. and Anastassiou, Costas A. and Perin, Rodrigo and Hill, Sean L. and Markram, Henry and Koch, Christof},
  year = {2013},
  month = jul,
  journal = {Neuron},
  volume = {79},
  number = {2},
  pages = {375--390},
  publisher = {{Elsevier}},
  issn = {08966273},
  doi = {10.1016/j.neuron.2013.05.023},
  abstract = {Brain activity generates extracellular voltage fluctuations recorded as local field potentials (LFPs). It is known that the relevant microvariables, the ionic currents across membranes, jointly generate the macrovariables, the extracellular voltage, but neither the detailed biophysical knowledge nor the required computational power have been available to model these processes. We simulated the LFP in a model of the rodent neocortical column composed of {$>$}12,000 reconstructed, multicompartmental, and spiking cortical layer 4 and 5 pyramidal neurons and basket cells, including five million dendritic and somatic compartments with voltage- and ion-dependent currents, realistic connectivity, and probabilistic AMPA, NMDA, and GABA synapses. We found that, depending on a number of factors, the LFP reflects local and cross-layer processing. Active currents dominate the generation of LFPs, not synaptic ones. Spike-related currents impact the LFP not only at higher frequencies but below 50Hz. This work calls for re-evaluating the genesis of LFPs},
  pmid = {23889937},
  file = {C\:\\Users\\johns\\Zotero\\storage\\PTA5E97K\\full-text.pdf}
}

@article{riemenschneider19,
  title = {Targeted Partial Reconstruction for Real-Time {{fMRI}} with Arbitrary Trajectories},
  author = {Riemenschneider, Bruno and LeVan, Pierre and Hennig, J{\"u}rgen},
  year = {2019},
  month = feb,
  journal = {Magnetic Resonance in Medicine},
  volume = {81},
  number = {2},
  pages = {1118--1129},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {15222594},
  doi = {10.1002/mrm.27478},
  abstract = {Purpose: A partial image reconstruction formalism is introduced for the targeted extraction of real-time feedback from arbitrary trajectories when full image reconstruction in real time is computationally too demanding. Methods: Explicit calculation and storage of linear combinations of lines of the reconstruction matrix by an incomplete basis change in spatial coordinates lead to translation of the expensive full reconstruction from a frame-wise application to a region of interest (ROI)-wise application. This step is independent from signal data and can be executed before the experiment. Subsequently, the results of the sum over fully reconstructed voxels can be evaluated directly. Data from a high-speed fMRI acquisition was used to investigate the targeted partial reconstruction of a functional ROI atlas, incorporating an intravolume dephasing correction. The same data and ROIs were used for a comparison of the time series obtained with those obtained from already existing methods for compartment-wise reconstruction. To examine real-time feasibility, the reconstruction was implemented and tested for online reconstruction performance. Results: The reconstruction yields results that are virtually identical to the standard reconstruction (i.e., the magnitude sums over the ROIs), with negligible discrepancies even after termination of the conjugate gradient algorithm at a feasible number of iterations. Notably, more discrepancies arise with existing compartment-wise reconstructions. The online real-time implementation evaluated 1 ROI within 2.8 ms in the case of a highly parallel 3D whole brain acquisition. Conclusion: The high reconstruction fidelity and speed are satisfying for the exemplary application of real-time functional feedback using a highly parallel 3D whole brain acquisition.},
  pmid = {30230016},
  keywords = {fMRI,non-Cartesian trajectories,partial reconstruction,real-time feedback,SENSE},
  file = {C\:\\Users\\johns\\Zotero\\storage\\JY8EQVL2\\Riemenschneider et al_2019_Targeted partial reconstruction for real-time fMRI with arbitrary trajectories.pdf}
}

@article{rolston10,
  title = {Closed-{{Loop}}, {{Open-Source Electrophysiology}}},
  author = {Rolston, John D and Gross, Robert E and Potter, Steve M},
  year = {2010},
  journal = {Frontiers in Neuroscience},
  volume = {0},
  number = {SEP},
  pages = {31},
  publisher = {{Frontiers}},
  issn = {1662-453X},
  doi = {10.3389/FNINS.2010.00031},
  abstract = {Multiple extracellular microelectrodes (multi-electrode arrays, or MEAs) effectively record rapidly varying neural signals, and can also be used for electrical stimulation. Multi-electrode recording can serve as artificial output (efferents) from a neural system, while complex spatially and temporally targeted stimulation can serve as artificial input (afferents) to the neuronal network. Multi-unit or local field potential recordings can not only be used to control real world artifacts, such as prostheses, computers or robots, but can also trigger or alter subsequent stimulation. Real-time feedback stimulation may serve to modulate or normalize aberrant neural activity, to induce plasticity, or to serve as artificial sensory input. Despite promising closed-loop applications, commercial electrophysiology systems do not yet take advantage of the bidirectional capabilities of multi-electrodes, especially for use in freely moving animals. We addressed this lack of tools for closing the loop with NeuroRighter, an open-source system including recording hardware, stimulation hardware, and control software with a graphical user interface. The integrated system is capable of multi-electrode recording and simultaneous patterned microstimulation triggered by recordings with minimal stimulation artifact. The potential applications of closed-loop systems as research tools and clinical treatments are broad; we provide one example where epileptic activity recorded by a multi-electrode probe is used to trigger targeted stimulation, via that probe, to freely moving rodents.},
  keywords = {artifact,BMI,closed-loop,Epilepsy,MEA,micro-electrode array,Multi-Electrode Array,rat,stimulation},
  file = {C\:\\Users\\johns\\Zotero\\storage\\F4CSY4YP\\Rolston et al_2010_Closed-Loop, Open-Source Electrophysiology.pdf}
}

@article{ronzitti17,
  title = {Submillisecond {{Optogenetic Control}} of {{Neuronal Firing}} with {{Two-Photon Holographic Photoactivation}} of {{Chronos}}},
  author = {Ronzitti, Emiliano and Conti, Rossella and Zampini, Valeria and Tanese, Dimitrii and Foust, Amanda J. and Klapoetke, Nathan and Boyden, Edward S. and Papagiakoumou, Eirini and Emiliani, Valentina},
  year = {2017},
  month = nov,
  journal = {Journal of Neuroscience},
  volume = {37},
  number = {44},
  pages = {10679--10689},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.1246-17.2017},
  abstract = {Optogenetic neuronal network manipulation promises to unravel a long-standing mystery in neuroscience: how does microcircuit activity relate causally to behavioral and pathological states? The challenge to evoke spikes with high spatial and temporal complexity necessitates further joint development of light-delivery approaches and custom opsins. Two-photon (2P) light-targeting strategies demonstrated in-depth generation of action potentials in photosensitive neurons both in vitro and in vivo, but thus far lack the temporal precision necessary to induce precisely timed spiking events. Here, we show that efficient current integration enabled by 2P holographic amplified laser illumination of Chronos, a highly light-sensitive and fast opsin, can evoke spikes with submillisecond precision and repeated firing up to 100 Hz in brain slices from Swiss male mice. These results pave the way for optogenetic manipulation with the spatial and temporal sophistication necessary to mimic natural microcircuit activity. SIGNIFICANCE STATEMENT To reveal causal links between neuronal activity and behavior, it is necessary to develop experimental strategies to induce spatially and temporally sophisticated perturbation of network microcircuits. Two-photon computer generated holography (2P-CGH) recently demonstrated 3D optogenetic control of selected pools of neurons with single-cell accuracy in depth in the brain. Here, we show that exciting the fast opsin Chronos with amplified laser 2P-CGH enables cellular-resolution targeting with unprecedented temporal control, driving spiking up to 100 Hz with submillisecond onset precision using low laser power densities. This system achieves a unique combination of spatial flexibility and temporal precision needed to pattern optogenetically inputs that mimic natural neuronal network activity patterns.},
  chapter = {Research Articles},
  copyright = {Copyright \textcopyright{} 2017 the authors 0270-6474/17/3710679-11\$15.00/0},
  langid = {english},
  pmid = {28972125},
  keywords = {holography,optogenetics,two-photon excitation},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Ronzitti et al_2017_Submillisecond Optogenetic Control of Neuronal Firing with Two-Photon.pdf}
}

@article{roth16,
  title = {{{DREADDs}} for {{Neuroscientists}}},
  author = {Roth, Bryan L.},
  year = {2016},
  month = feb,
  journal = {Neuron},
  volume = {89},
  number = {4},
  pages = {683--694},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2016.01.040},
  abstract = {To understand brain function, it is essential that we discover how cellular signaling specifies normal and pathological brain function. In this regard, chemogenetic technologies represent valuable platforms for manipulating neuronal and non-neuronal signal transduction in a cell-type-specific fashion in freely moving animals. Designer Receptors Exclusively Activated by Designer Drugs (DREADD)-based chemogenetic tools are now commonly used by neuroscientists to identify the circuitry and cellular signals that specify behavior, perceptions, emotions, innate drives, and motor functions in species ranging from flies to nonhuman primates. Here I provide a primer on DREADDs highlighting key technical and conceptual considerations and identify challenges for chemogenetics going forward.},
  langid = {english},
  keywords = {chemical biology,chemogenetic,DREADD,synthetic biology},
  file = {C\:\\Users\\johns\\Zotero\\storage\\GIZFHFTQ\\Roth_2016_DREADDs for Neuroscientists.pdf}
}

@article{rule18,
  title = {Phase Reorganization Leads to Transient {$\beta$}-{{LFP}} Spatial Wave Patterns in Motor Cortex during Steady-State Movement Preparation},
  author = {Rule, Michael E. and {Vargas-Irwin}, Carlos and Donoghue, John P. and Truccolo, Wilson},
  year = {2018},
  month = jun,
  journal = {Journal of Neurophysiology},
  volume = {119},
  number = {6},
  pages = {2212--2228},
  publisher = {{American Physiological Society}},
  issn = {15221598},
  doi = {10.1152/jn.00525.2017},
  abstract = {Previous studies on the origin and properties of spatial patterns in motor cortex {$\beta$}-local field potential ({$\beta$}-LFP) oscillations have focused on planar traveling waves. However, it is unclear 1) whether {$\beta$}-LFP waves are limited to plane waves, or even 2) whether they are propagating waves of excito-excitatory activity, i.e., primarily traveling waves in excitable media; they could reflect, instead, reorganization in the relative phases of transient oscillations at different spatial sites. We addressed these two problems in {$\beta$}-LFPs recorded via microelectrode arrays implanted in three adjacent motor cortex areas of nonhuman primates during steady-state movement preparation. Our findings are fourfold: 1) {$\beta$}-LFP wave patterns emerged as transient events, despite stable firing rates of single neurons concurrently recorded during the same periods. 2) {$\beta$}-LFP waves showed a richer variety of spatial dynamics, including rotating and complex waves. 3) {$\beta$}-LFP wave patterns showed no characteristic wavelength, presenting instead a range of scales with global zero-lag phase synchrony as a limiting case, features surprising for purely excito-excitatory waves but consistent with waves in coupled oscillator systems. 4) Furthermore, excito-excitatory traveling waves induced by optogenetic stimulation in motor cortex showed, in contrast, a characteristic wavelength and reduced phase synchrony. Overall, {$\beta$}-LFP wave statistics differed from those of induced traveling waves in excitable media recorded under the same microelectrode array setup. Our findings suggest phase reorganization in neural coupled oscillators contribute significantly to the origin of transient {$\beta$}-LFP spatial dynamics during preparatory steady states and outline important constraints for spatially extended models of {$\beta$}-LFP dynamics in motor cortex. NEW \& NOTEWORTHY We show that a rich variety of transient {$\beta$}-local field potential ({$\beta$}-LFP) wave patterns emerge in motor cortex during preparatory steady states, despite stable neuronal firing rates. Furthermore, unlike optogenetically induced traveling waves, {$\beta$}-LFP waves showed no characteristic wavelength, presenting instead a range of scales with global phase synchrony as a limiting case. Overall, our statistical analyses suggest that transient phase reorganization in neural coupled oscillators, beyond purely excito-excitatory traveling waves, contribute significantly to the origin of motor cortex {$\beta$}-LFP wave patterns.},
  pmid = {29442553},
  keywords = {Beta oscillations,Cortical waves,Neural dynamics,Optogenetically induced oscillations},
  file = {C\:\\Users\\johns\\Zotero\\storage\\988BDQZM\\Rule et al_2018_Phase reorganization leads to transient β-LFP spatial wave patterns in motor.pdf}
}

@article{sabatier18,
  title = {Modeling the {{Electro-chemical Properties}} of {{Microbial Opsin ChrimsonR}} for {{Application}} to {{Optogenetics-based Vision Restoration}}},
  author = {Sabatier, Quentin and Joffrois, Corentin and Gauvain, Gr{\'e}gory and Chavas, Jo{\"e}l and Pruneau, Didier and Picaud, Serge and Benosman, Ryad},
  year = {2018},
  month = sep,
  journal = {bioRxiv},
  pages = {417899},
  publisher = {{Cold Spring Harbor Laboratory}},
  doi = {10.1101/417899},
  abstract = {Optogenetic activation of neurons [[1][1]] have greatly contributed to our understanding of how neural circuits operate, and holds huge promise in the field of neural prosthetics, particularly in sensory restoration. The discovery of new channelrhodopsins, Chrimson \textemdash{} which is 45 nm more red-shifted than any previously discovered or engineered channelrhodopsin \textemdash{} and its mutant ChrimsonR with faster kinetics [[2][2]] made this technology available for medical applications. However, a detailed model that would be able to accurately reproduce the membrane potential dynamics in cells transfected with ChrimsonR under light stimulation is missing. We address this issue by developing the first model for the electrochemical behavior of ChrimsonR that predicts its conductance in response to arbitrary light stimulation. Our model captures ON and OFF dynamics of the protein for stimuli with frequencies up to 100 Hz and their relationship with the brightness, as well as its activation curve, the steady-state amplitude of the response as a function of light intensity. Additionally, we capture a slow adaptation mechanism at a timescale at the order of minutes. Our model holds for light intensities covering the whole dynamic range of the channel (from response onset to saturation) and for timescales in the order of up to several minutes. This model is a new step towards modeling the spiking activity of ChrimsonR-expressing neurons, required for the precise control of information transmission in optogenetics-based Brain-Computer Interfaces, and will inform future applications of ChrimsonR based optogenetics. [1]: \#ref-1 [2]: \#ref-2},
  file = {C\:\\Users\\johns\\Zotero\\storage\\WM3ALSL8\\Sabatier et al_2018_Modeling the Electro-chemical Properties of Microbial Opsin ChrimsonR for.pdf}
}

@article{sadeh20,
  title = {Patterned Perturbation of Inhibition Can Reveal the Dynamical Structure of Neural Processing},
  author = {Sadeh, Sadra and Clopath, Claudia},
  year = {2020},
  month = feb,
  journal = {eLife},
  volume = {9},
  publisher = {{eLife Sciences Publications Ltd}},
  issn = {2050084X},
  doi = {10.7554/eLife.52757},
  abstract = {Perturbation of neuronal activity is key to understanding the brain's functional properties, however, intervention studies typically perturb neurons in a nonspecific manner. Recent optogenetics techniques have enabled patterned perturbations, in which specific patterns of activity can be invoked in identified target neurons to reveal more specific cortical function. Here, we argue that patterned perturbation of neurons is in fact necessary to reveal the specific dynamics of inhibitory stabilization, emerging in cortical networks with strong excitatory and inhibitory functional subnetworks, as recently reported in mouse visual cortex. We propose a specific perturbative signature of these networks and investigate how this can be measured under different experimental conditions. Functionally, rapid spontaneous transitions between selective ensembles of neurons emerge in such networks, consistent with experimental results. Our study outlines the dynamical and functional properties of feature-specific inhibitory-stabilized networks, and suggests experimental protocols that can be used to detect them in the intact cortex.},
  pmid = {32073400},
  file = {C\:\\Users\\johns\\Zotero\\storage\\VNWUDTYY\\Sadeh_Clopath_2020_Patterned perturbation of inhibition can reveal the dynamical structure of.pdf}
}

@article{saleem17,
  title = {Subcortical {{Source}} and {{Modulation}} of the {{Narrowband Gamma Oscillation}} in {{Mouse Visual Cortex}}},
  author = {Saleem, Aman B. and Lien, Anthony D. and Krumin, Michael and Haider, Bilal and Ros{\'o}n, Miroslav Rom{\'a}n and Ayaz, Asli and Reinhold, Kimberly and Busse, Laura and Carandini, Matteo and Harris, Kenneth D. and Carandini, Matteo},
  year = {2017},
  month = jan,
  journal = {Neuron},
  volume = {93},
  number = {2},
  pages = {315--322},
  publisher = {{Cell Press}},
  issn = {10974199},
  doi = {10.1016/j.neuron.2016.12.028},
  abstract = {Primary visual cortex exhibits two types of gamma rhythm: broadband activity in the 30\textendash 90 Hz range and a narrowband oscillation seen in mice at frequencies close to 60 Hz. We investigated the sources of the narrowband gamma oscillation, the factors modulating its strength, and its relationship to broadband gamma activity. Narrowband and broadband gamma power were uncorrelated. Increasing visual contrast had opposite effects on the two rhythms: it increased broadband activity, but suppressed the narrowband oscillation. The narrowband oscillation was strongest in layer 4 and was mediated primarily by excitatory currents entrained by the synchronous, rhythmic firing of neurons in the lateral geniculate nucleus (LGN). The power and peak frequency of the narrowband gamma oscillation increased with light intensity. Silencing the cortex optogenetically did not abolish the narrowband oscillation in either LGN firing or cortical excitatory currents, suggesting that this oscillation reflects unidirectional flow of signals from thalamus to cortex.},
  pmid = {28103479},
  keywords = {gamma,lateral geniculate nucleus,mouse vision,neural circuits,primary visual cortex,thalamus},
  file = {C\:\\Users\\johns\\Zotero\\storage\\UXXA8THB\\Saleem et al_2017_Subcortical Source and Modulation of the Narrowband Gamma Oscillation in Mouse.pdf}
}

@article{sani18,
  title = {Mood Variations Decoded from Multi-Site Intracranial Human Brain Activity},
  author = {Sani, Omid G. and Yang, Yuxiao and Lee, Morgan B. and Dawes, Heather E. and Chang, Edward F. and Shanechi, Maryam M.},
  year = {2018},
  month = nov,
  journal = {Nature Biotechnology},
  volume = {36},
  number = {10},
  pages = {954--961},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1696},
  doi = {10.1038/nbt.4200},
  abstract = {Mood state changes are decoded using human neural activity data from electrodes implanted in seven epilepsy patients.},
  copyright = {2018 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  langid = {english},
  keywords = {Biomedical engineering,Biotechnology,Emotion,Neural decoding},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Sani et al_2018_Mood variations decoded from multi-site intracranial human brain activity.pdf}
}

@article{sani21,
  title = {Where Is All the Nonlinearity: Flexible Nonlinear Modeling of Behaviorally Relevant Neural Dynamics Using Recurrent Neural Networks},
  author = {Sani, Omid G and Pesaran, Bijan and Shanechi, Maryam M and Hsieh, Ming},
  year = {2021},
  month = sep,
  journal = {bioRxiv},
  pages = {2021.09.03.458628},
  publisher = {{Cold Spring Harbor Laboratory}},
  doi = {10.1101/2021.09.03.458628},
  abstract = {Understanding the dynamical transformation of neural activity to behavior requires modeling this transformation while both dissecting its potential nonlinearities and dissociating and preserving its nonlinear behaviorally relevant neural dynamics, which remain unaddressed. We present RNN PSID, a nonlinear dynamic modeling method that enables flexible dissection of nonlinearities, dissociation and preferential learning of neural dynamics relevant to specific behaviors, and causal decoding. We first validate RNN PSID in simulations and then use it to investigate nonlinearities in monkey spiking and LFP activity across four tasks and different brain regions. Nonlinear RNN PSID successfully dissociated and preserved nonlinear behaviorally relevant dynamics, thus outperforming linear and non-preferential nonlinear learning methods in behavior decoding while reaching similar neural prediction. Strikingly, dissecting the nonlinearities with RNN PSID revealed that consistently across all tasks, summarizing the nonlinearity only in the mapping from the latent dynamics to behavior was largely sufficient for predicting behavior and neural activity. RNN PSID provides a novel tool to reveal new characteristics of nonlinear neural dynamics underlying behavior. \#\#\# Competing Interest Statement The authors have declared no competing interest.},
  file = {C\:\\Users\\johns\\Zotero\\storage\\PC4LI2PB\\Sani et al_2021_Where is all the nonlinearity.pdf}
}

@article{sani21a,
  title = {Modeling Behaviorally Relevant Neural Dynamics Enabled by Preferential Subspace Identification},
  author = {Sani, Omid G and Abbaspourazad, Hamidreza and Wong, Yan T and Pesaran, Bijan and Shanechi, Maryam M},
  year = {2021},
  journal = {Nature Neuroscience},
  volume = {24},
  number = {1},
  pages = {140--149},
  publisher = {{Springer US}},
  issn = {15461726},
  doi = {10.1038/s41593-020-00733-0},
  abstract = {Neural activity exhibits complex dynamics related to various brain functions, internal states and behaviors. Understanding how neural dynamics explain specific measured behaviors requires dissociating behaviorally relevant and irrelevant dynamics, which is not achieved with current neural dynamic models as they are learned without considering behavior. We develop preferential subspace identification (PSID), which is an algorithm that models neural activity while dissociating and prioritizing its behaviorally relevant dynamics. Modeling data in two monkeys performing three-dimensional reach and grasp tasks, PSID revealed that the behaviorally relevant dynamics are significantly lower-dimensional than otherwise implied. Moreover, PSID discovered distinct rotational dynamics that were more predictive of behavior. Furthermore, PSID more accurately learned behaviorally relevant dynamics for each joint and recording channel. Finally, modeling data in two monkeys performing saccades demonstrated the generalization of PSID across behaviors, brain regions and neural signal types. PSID provides a general new tool to reveal behaviorally relevant neural dynamics that can otherwise go unnoticed.},
  pmid = {33169030},
  file = {C\:\\Users\\johns\\Zotero\\storage\\M5GBQM9T\\s41593-020-00733-0.pdf}
}

@article{santhanam09,
  title = {Factor-{{Analysis Methods}} for {{Higher-Performance Neural Prostheses}}},
  author = {Santhanam, Gopal and Yu, Byron M. and Gilja, Vikash and Ryu, Stephen I. and Afshar, Afsheen and Sahani, Maneesh and Shenoy, Krishna V.},
  year = {2009},
  month = aug,
  journal = {Journal of Neurophysiology},
  volume = {102},
  number = {2},
  pages = {1315--1330},
  publisher = {{American Physiological Society}},
  issn = {0022-3077},
  doi = {10.1152/jn.00097.2009},
  abstract = {Neural prostheses aim  provide  options for  with nervous-system  or injury. It is necessary, however,  increase the  of such systems before they can be clinically viable for  with motor dysfunction. One  limitation is the presence of correlated trial-to-trial variability that can cause neural responses to wax and wane in  as the subject is, for , more attentive or more fatigued. If  does not properly account for this variability, it may  interpret such variability as an entirely different intention by the subject. We report here  and characterization of factor-analysis (FA)\textendash based decoding algorithms that can contend with this confound. We characterize the decoders (classifiers) on experimental data where monkeys performed both a real reach  and a prosthetic  task while we recorded from 96 electrodes implanted in dorsal premotor cortex. The decoder attempts to infer the underlying factors that comodulate the neurons' responses and can use this  to substantially lower error rates (one of  reach endpoint predictions) by {$\lessequivlnt$}75\% (e.g., {$\sim$}20\%  prediction error using traditional independent Poisson models reduced to {$\sim$}5\%). We also examine additional key aspects of these new algorithms: the effect of neural integration window length on performance, an extension of the algorithms to use Poisson statistics, and the effect of training set size on the decoding accuracy of test data. We found that FA-based methods are most effective for integration windows {$>$}150 ms, although still advantageous at shorter timescales, that Gaussian-based algorithms performed better than the analogous Poisson-based algorithms and that the FA algorithm is robust even with a limited amount of training data. We propose that FA-based methods are effective in modeling correlated trial-to-trial neural variability and can be used to substantially increase overall prosthetic system performance.},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Santhanam et al_2009_Factor-Analysis Methods for Higher-Performance Neural Prostheses.pdf}
}

@article{sanzleon13,
  title = {The Virtual Brain: {{A}} Simulator of Primate Brain Network Dynamics},
  author = {Sanzleon, Paula and Knock, Stuart A. and Woodman, M. Marmaduke and Domide, Lia and Mersmann, Jochen and Mcintosh, Anthony R. and Jirsa, Viktor},
  year = {2013},
  month = jun,
  journal = {Frontiers in Neuroinformatics},
  volume = {7},
  number = {MAY},
  pages = {10},
  publisher = {{Frontiers Media S.A.}},
  issn = {16625196},
  doi = {10.3389/fninf.2013.00010},
  abstract = {We present TheVirtualBrain (TVB), a neuroinformatics platform for full brain network simulations using biologically realistic connectivity. This simulation environment enables the model-based inference of neurophysiological mechanisms across different brain scales that underlie the generation of macroscopic neuroimaging signals including functional MRI (fMRI), EEG and MEG. Researchers from different backgrounds can benefit from an integrative software platform including a supporting framework for data management (generation, organization, storage, integration and sharing) and a simulation core written in Python. TVB allows the reproduction and evaluation of personalized configurations of the brain by using individual subject data. This personalization facilitates an exploration of the consequences of pathological changes in the system, permitting to investigate potential ways to counteract such unfavorable processes. The architecture of TVB supports interaction with MATLAB packages, for example, the well known Brain Connectivity Toolbox. TVB can be used in a client-server configuration, such that it can be remotely accessed through the Internet thanks to its web-based HTML5, JS and WebGL graphical user interface. TVB is also accessible as a standalone cross-platform Python library and application, and users can interact with the scientific core through the scripting interface IDLE, enabling easy modeling, development and debugging of the scientific kernel. This second interface makes TVB extensible by combining it with other libraries and modules developed by the Python scientific community. In this article, we describe the theoretical background and foundations that led to the development of TVB, the architecture and features of its major software components as well as potential neuroscience applications. \textcopyright{} 2013 Sanz\_leon, Knock, Woodman, Domide, Mersmann, Mcintosh and Jirsa.},
  keywords = {Connectivity,Connectome,Full-brain network model,GPUs,Large-scale simulation,Neural field,Neural mass,Python,Time delays,Virtual brain,Web platform},
  file = {C\:\\Users\\johns\\Zotero\\storage\\Y37FIBDC\\Sanzleon et al_2013_The virtual brain.pdf}
}

@article{saran18,
  title = {Theoretical Analysis of Low-Power Fast Optogenetic Control of Firing of {{Chronos-expressing}} Neurons},
  author = {Saran, Sant and Gupta, Neha and Roy, Sukhdev},
  year = {2018},
  month = may,
  journal = {Neurophotonics},
  volume = {5},
  number = {02},
  pages = {1},
  publisher = {{SPIE}},
  issn = {23294248},
  doi = {10.1117/1.nph.5.2.025009},
  abstract = {\textcopyright{} 2018 Society of Photo-Optical Instrumentation Engineers (SPIE). A detailed theoretical analysis of low-power, fast optogenetic control of firing of Chronos-expressing neurons has been presented. A three-state model for the Chronos photocycle has been formulated and incorporated in a fast-spiking interneuron circuit model. The effect of excitation wavelength, pulse irradiance, pulse width, and pulse frequency has been studied in detail and compared with ChR2. Theoretical simulations are in excellent agreement with recently reported experimental results and bring out additional interesting features. At very low irradiances (0.005 mW/mm2), the plateau current in Chronos exhibits a maximum. At 0.05 mW/mm2, the plateau current is 2 orders of magnitude smaller and saturates at longer pulse widths ({$\sim$}700 ms) compared to ChR2 ({$\sim$}350 ms). Ipeak in Chronos saturates at much shorter pulse widths (1775 pA at 1.5 ms and 5 mW/mm2) than in ChR2. Spiking fidelity is also higher at lower irradiances and longer pulse widths compared to ChR2. Chronos exhibits an average maximal driven rate of over 200 spikes/s in response to 100 pulses/s stimuli, each of 1-ms pulse-width, in the intensity range 0 to 200 mW/mm2. The analysis is important to not only understand the photodynamics of Chronos and Chronos-expressing neurons but also to design opsins with optimized properties and perform precision experiments with required spatiotemporal resolution.},
  keywords = {Absorption,Action potentials,Circuit switching,Modulation,Molecules,Neurons,Neurophotonics,Optogenetics,Sodium,Thermal modeling},
  file = {C\:\\Users\\johns\\Zotero\\storage\\2PRLHYND\\full-text.pdf}
}

@article{sato12,
  title = {Traveling {{Waves}} in {{Visual Cortex}}},
  author = {Sato, Tatsuo K. and Nauhaus, Ian and Carandini, Matteo},
  year = {2012},
  month = jul,
  journal = {Neuron},
  volume = {75},
  number = {2},
  pages = {218--229},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2012.06.029},
  abstract = {Electrode recordings and imaging studies have revealed that localized visual stimuli elicit waves of activity that travel across primary visual cortex. Traveling waves are present also during spontaneous activity, but they can be greatly reduced by widespread and intensive visual stimulation. In this Review, we summarize the evidence in favor of these traveling waves. We suggest that their substrate may lie in long-range horizontal connections and that their functional role may involve the integration of information over large regions of space.},
  langid = {english},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Sato et al_2012_Traveling Waves in Visual Cortex.pdf}
}

@article{scheffer20,
  title = {A Connectome and Analysis of the Adult {{Drosophila}} Central Brain},
  author = {Scheffer, Louis K and Xu, C Shan and Januszewski, Michal and Lu, Zhiyuan and Takemura, Shin-ya and Hayworth, Kenneth J and Huang, Gary B and Shinomiya, Kazunori and {Maitlin-Shepard}, Jeremy and Berg, Stuart and Clements, Jody and Hubbard, Philip M and Katz, William T and Umayam, Lowell and Zhao, Ting and Ackerman, David and Blakely, Tim and Bogovic, John and Dolafi, Tom and Kainmueller, Dagmar and Kawase, Takashi and Khairy, Khaled A and Leavitt, Laramie and Li, Peter H and Lindsey, Larry and Neubarth, Nicole and Olbris, Donald J and Otsuna, Hideo and Trautman, Eric T and Ito, Masayoshi and Bates, Alexander S and Goldammer, Jens and Wolff, Tanya and Svirskas, Robert and Schlegel, Philipp and Neace, Erika and Knecht, Christopher J and Alvarado, Chelsea X and Bailey, Dennis A and Ballinger, Samantha and Borycz, Jolanta A and Canino, Brandon S and Cheatham, Natasha and Cook, Michael and Dreher, Marisa and Duclos, Octave and Eubanks, Bryon and Fairbanks, Kelli and Finley, Samantha and Forknall, Nora and Francis, Audrey and Hopkins, Gary Patrick and Joyce, Emily M and Kim, SungJin and Kirk, Nicole A and Kovalyak, Julie and Lauchie, Shirley A and Lohff, Alanna and Maldonado, Charli and Manley, Emily A and McLin, Sari and Mooney, Caroline and Ndama, Miatta and Ogundeyi, Omotara and Okeoma, Nneoma and Ordish, Christopher and Padilla, Nicholas and Patrick, Christopher M and Paterson, Tyler and Phillips, Elliott E and Phillips, Emily M and Rampally, Neha and Ribeiro, Caitlin and Robertson, Madelaine K and Rymer, Jon Thomson and Ryan, Sean M and Sammons, Megan and Scott, Anne K and Scott, Ashley L and Shinomiya, Aya and Smith, Claire and Smith, Kelsey and Smith, Natalie L and Sobeski, Margaret A and Suleiman, Alia and Swift, Jackie and Takemura, Satoko and Talebi, Iris and Tarnogorska, Dorota and Tenshaw, Emily and Tokhi, Temour and Walsh, John J and Yang, Tansy and Horne, Jane Anne and Li, Feng and Parekh, Ruchi and Rivlin, Patricia K and Jayaraman, Vivek and Costa, Marta and Jefferis, Gregory SXE and Ito, Kei and Saalfeld, Stephan and George, Reed and Meinertzhagen, Ian A and Rubin, Gerald M and Hess, Harald F and Jain, Viren and Plaza, Stephen M},
  editor = {Marder, Eve and Eisen, Michael B and Pipkin, Jason and Doe, Chris Q},
  year = {2020},
  month = sep,
  journal = {eLife},
  volume = {9},
  pages = {e57443},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.57443},
  abstract = {The neural circuits responsible for animal behavior remain largely unknown. We summarize new methods and present the circuitry of a large fraction of the brain of the fruit fly Drosophila melanogaster. Improved methods include new procedures to prepare, image, align, segment, find synapses in, and proofread such large data sets. We define cell types, refine computational compartments, and provide an exhaustive atlas of cell examples and types, many of them novel. We provide detailed circuits consisting of neurons and their chemical synapses for most of the central brain. We make the data public and simplify access, reducing the effort needed to answer circuit questions, and provide procedures linking the neurons defined by our analysis with genetic reagents. Biologically, we examine distributions of connection strengths, neural motifs on different scales, electrical consequences of compartmentalization, and evidence that maximizing packing density is an important criterion in the evolution of the fly's brain.},
  keywords = {brain regions,cell types,connectome,connectome reconstuction methods,graph properties,synapse detecton},
  file = {C\:\\Users\\johns\\Zotero\\storage\\VLRS9844\\Scheffer et al_2020_A connectome and analysis of the adult Drosophila central brain.pdf}
}

@misc{schneider22,
  title = {Learnable Latent Embeddings for Joint Behavioral and Neural Analysis},
  author = {Schneider, Steffen and Lee, Jin Hwa and Mathis, Mackenzie Weygandt},
  year = {2022},
  month = apr,
  number = {arXiv:2204.00673},
  eprint = {2204.00673},
  eprinttype = {arxiv},
  primaryclass = {cs, q-bio},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2204.00673},
  abstract = {Mapping behavioral actions to neural activity is a fundamental goal of neuroscience. As our ability to record large neural and behavioral data increases, there is growing interest in modeling neural dynamics during adaptive behaviors to probe neural representations. In particular, neural latent embeddings can reveal underlying correlates of behavior, yet, we lack non-linear techniques that can explicitly and flexibly leverage joint behavior and neural data. Here, we fill this gap with a novel method, CEBRA, that jointly uses behavioral and neural data in a hypothesis- or discovery-driven manner to produce consistent, high-performance latent spaces. We validate its accuracy and demonstrate our tool's utility for both calcium and electrophysiology datasets, across sensory and motor tasks, and in simple or complex behaviors across species. It allows for single and multi-session datasets to be leveraged for hypothesis testing or can be used label-free. Lastly, we show that CEBRA can be used for the mapping of space, uncovering complex kinematic features, and rapid, high-accuracy decoding of natural movies from visual cortex.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Quantitative Biology - Neurons and Cognition,Quantitative Biology - Quantitative Methods},
  file = {C\:\\Users\\johns\\Zotero\\storage\\DK3A23H4\\Schneider et al_2022_Learnable latent embeddings for joint behavioral and neural analysis.pdf}
}

@article{sharp93,
  title = {The Dynamic Clamp: Artificial Conductances in Biological Neurons},
  shorttitle = {The Dynamic Clamp},
  author = {Sharp, Andrew A. and O'Neil, Michael B. and Abbott, L. F. and Marder, Eve},
  year = {1993},
  month = oct,
  journal = {Trends in Neurosciences},
  volume = {16},
  number = {10},
  pages = {389--394},
  issn = {0166-2236},
  doi = {10.1016/0166-2236(93)90004-6},
  abstract = {The dynamic clamp is a novel method that uses computer simulation to introduce conductances into biological neurons. This method can be used to study the role of various conductances in shaping the activity of single neurons, or neurons within networks. The dynamic clamp can also be used to form circuits from previously unconnected neurons. This approach makes computer simulation an interactive experimental tool, and will be useful in many applications where the role of synaptic strengths and intrinsic properties in neuronal and network dynamics is of interest.},
  langid = {english},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Sharp et al_1993_The dynamic clamp.pdf}
}

@article{shenoy13,
  title = {Cortical {{Control}} of {{Arm Movements}}: {{A Dynamical Systems Perspective}}},
  author = {Shenoy, Krishna V and Sahani, Maneesh and Churchland, Mark M},
  year = {2013},
  journal = {Annual Review of Neuroscience},
  volume = {36},
  pages = {337--359},
  doi = {10.1146/annurev-neuro-062111-150509},
  abstract = {Our ability to move is central to everyday life. Investigating the neural control of movement in general, and the cortical control of volitional arm movements in particular, has been a major research focus in recent decades. Studies have involved primarily either attempts to account for single-neuron responses in terms of tuning for movement parameters or attempts to decode movement parameters from populations of tuned neurons. Even though this focus on encoding and decoding has led to many seminal advances, it has not produced an agreed-upon conceptual framework. Interest in understanding the underlying neural dynamics has recently increased, leading to questions such as how does the current population response determine the future population response, and to what purpose? We review how a dynamical systems perspective may help us understand why neural activity evolves the way it does, how neural activity relates to movement parameters, and how a unified conceptual framework may result.},
  keywords = {dimensionality reduction,neural control of movement,premotor cortex,primary motor cortex},
  file = {C\:\\Users\\johns\\Zotero\\storage\\EZIFKU67\\Shenoy et al_2013_Cortical Control of Arm Movements.pdf}
}

@article{shenoy21,
  title = {Measurement, Manipulation and Modeling of Brain-Wide Neural Population Dynamics},
  author = {Shenoy, Krishna V. and Kao, Jonathan C.},
  year = {2021},
  month = dec,
  journal = {Nature Communications},
  volume = {12},
  number = {1},
  pages = {1--5},
  publisher = {{Nature Research}},
  issn = {20411723},
  doi = {10.1038/s41467-020-20371-1},
  abstract = {Neural recording technologies increasingly enable simultaneous measurement of neural activity from multiple brain areas. To gain insight into distributed neural computations, a commensurate advance in experimental and analytical methods is necessary. We discuss two opportunities towards this end: the manipulation and modeling of neural population dynamics. Neural circuits comprise networks of individual neurons that perform sensory, cognitive, and motor functions. Neuronal biophysics, together with these circuits, give rise to neural population dynamics, which express how the activity of the neural population evolves through time in principled ways. Neural population dynamics provide a framework for understanding neural computation. Prior studies have modeled neural population dynamics to gain insight into computations involved in decision-making, timing, and motor control 1. Here, we present emerging opportunities for new experiments and analyses that use a dynamical systems framework to better understand brain circuits, how they interact, and how they relate to behavior. The simplest model of neural population dynamics is a linear dynamical system (LDS). An LDS (Fig. 1a) is described by a dynamics equation (x(t + 1) = Ax(t) + Bu(t)) and an observation equation (y(t) = Cx(t) + d). Typically, y(t) reflects experimental measurements, such as a vector where each element is the number of action potentials fired by a neuron in a brief time bin (e.g., 10 ms). The vector x(t) is a "neural population state" that captures information in y(t). This neural population state can be thought of as a representation of the dominant activity patterns in the experimental neural recordings. Typically, x(t) is an abstract representation in a low-dimensional subspace (or manifold) found via dimensionality reduction 2 (Fig. 1b, neural state), reflecting that the neural activity is correlated and the dominant patterns can be described by a relatively small number of variables. The neural population state can also represent the activity of each neuron in the original dimensionality of the measured data (e.g., 100D if 100 neurons). The observation equation relates the observed action potentials (y(t)) to the neural population state (x(t)) through an observation matrix (C). The vector, d, is a constant offset (e.g., to model baseline firing). The neural population state moves through neural state space, constituting a neural population trajectory. The dynamics equation expresses how the neural population state (x(t)) progresses through time as a function of a dynamics matrix (A), an input matrix (B) and https://doi.},
  pmid = {33504773},
  keywords = {Computational neuroscience,Motor control,Neuroscience},
  file = {C\:\\Users\\johns\\Zotero\\storage\\YPHFWW8Q\\Shenoy_Kao_2021_Measurement, manipulation and modeling of brain-wide neural population dynamics.pdf}
}

@article{siegle17,
  title = {Open {{Ephys}}: An Open-Source, Plugin-Based Platform for Multichannel Electrophysiology},
  shorttitle = {Open {{Ephys}}},
  author = {Siegle, Joshua H. and L{\'o}pez, Aar{\'o}n Cuevas and Patel, Yogi A. and Abramov, Kirill and Ohayon, Shay and Voigts, Jakob},
  year = {2017},
  month = jun,
  journal = {Journal of Neural Engineering},
  volume = {14},
  number = {4},
  pages = {045003},
  publisher = {{IOP Publishing}},
  issn = {1741-2552},
  doi = {10.1088/1741-2552/aa5eea},
  abstract = {Objective. Closed-loop experiments, in which causal interventions are conditioned on the state of the system under investigation, have become increasingly common in neuroscience. Such experiments can have a high degree of explanatory power, but they require a precise implementation that can be difficult to replicate across laboratories. We sought to overcome this limitation by building open-source software that makes it easier to develop and share algorithms for closed-loop control. Approach. We created the Open Ephys GUI, an open-source platform for multichannel electrophysiology experiments. In addition to the standard `open-loop' visualization and recording functionality, the GUI also includes modules for delivering feedback in response to events detected in the incoming data stream. Importantly, these modules can be built and shared as plugins, which makes it possible for users to extend the functionality of the GUI through a simple API, without having to understand the inner workings of the entire application. Main results. In combination with low-cost, open-source hardware for amplifying and digitizing neural signals, the GUI has been used for closed-loop experiments that perturb the hippocampal theta rhythm in a phase-specific manner. Significance. The Open Ephys GUI is the first widely used application for multichannel electrophysiology that leverages a plugin-based workflow. We hope that it will lower the barrier to entry for electrophysiologists who wish to incorporate real-time feedback into their research.},
  langid = {english},
  file = {C\:\\Users\\johns\\Zotero\\storage\\K3S7ICG7\\Siegle et al_2017_Open Ephys.pdf}
}

@inproceedings{smith21,
  title = {Reverse Engineering Recurrent Neural Networks with {{Jacobian}} Switching Linear Dynamical Systems},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Smith, Jimmy T.H. and Linderman, Scott W and Sussillo, David},
  year = {2021},
  month = dec,
  volume = {20},
  eprint = {2111.01256},
  eprinttype = {arxiv},
  pages = {16700--16713},
  issn = {10495258},
  abstract = {Recurrent neural networks (RNNs) are powerful models for processing time-series data, but it remains challenging to understand how they function. Improving this understanding is of substantial interest to both the machine learning and neuro-science communities. The framework of reverse engineering a trained RNN by linearizing around its fixed points has provided insight, but the approach has significant challenges. These include difficulty choosing which fixed point to expand around when studying RNN dynamics and error accumulation when reconstructing the nonlinear dynamics with the linearized dynamics. We present a new model that overcomes these limitations by co-training an RNN with a novel switching linear dynamical system (SLDS) formulation. A first-order Taylor series expansion of the co-trained RNN and an auxiliary function trained to pick out the RNN's fixed points govern the SLDS dynamics. The results are a trained SLDS variant that closely approximates the RNN, an auxiliary function that can produce a fixed point for each point in state-space, and a trained nonlinear RNN whose dynamics have been regularized such that its first-order terms perform the computation, if possible. This model removes the post-training fixed point optimization and allows us to unambiguously study the learned dynamics of the SLDS at any point in state-space. It also generalizes SLDS models to continuous manifolds of switching points while sharing parameters across switches. We validate the utility of the model on two synthetic tasks relevant to previous work reverse engineering RNNs. We then show that our model can be used as a drop-in in more complex architectures, such as LEADS, and apply this LEADS hybrid to analyze single-trial spiking activity from the motor system of a non-human primate.},
  archiveprefix = {arXiv},
  isbn = {978-1-71384-539-3},
  file = {C\:\\Users\\johns\\Zotero\\storage\\HTULHIX3\\NeurIPS-2021-reverse-engineering-recurrent-neural-networks-with-jacobian-switching-linear-dynamical-systems-Supplemental.pdf;C\:\\Users\\johns\\Zotero\\storage\\MM9XZTIU\\full-text.pdf}
}

@incollection{sorger20,
  title = {Real-Time {{fMRI}} for Brain-Computer Interfacing},
  booktitle = {Handbook of {{Clinical Neurology}}},
  author = {Sorger, Bettina and Goebel, Rainer},
  year = {2020},
  month = jan,
  volume = {168},
  pages = {289--302},
  publisher = {{Elsevier}},
  issn = {22124152},
  doi = {10.1016/B978-0-444-63934-9.00021-4},
  abstract = {Brain-computer interfaces (BCIs) based on functional magnetic resonance imaging (fMRI) provide an important complement to other noninvasive BCIs. While fMRI has several disadvantages (being nonportable, methodologically challenging, costly, and noisy), it is the only method providing high spatial resolution whole-brain coverage of brain activation. These properties allow relating mental activities to specific brain regions and networks providing a transparent scheme for BCI users to encode information and for real-time fMRI BCI systems to decode the intents of the user. Various mental activities have been used successfully in fMRI BCIs so far that can be classified into the four categories: (a) higher-order cognitive tasks (e.g., mental calculation), (b) covert language-related tasks (e.g., mental speech and mental singing), (c) imagery tasks (motor, visual, auditory, tactile, and emotion imagery), and (d) selective attention tasks (visual, auditory, and tactile attention). While the ultimate spatial and temporal resolution of fMRI BCIs is limited by the physiologic properties of the hemodynamic response, technical and analytical advances will likely lead to substantially improved fMRI BCIs in the future using, for example, decoding of imagined letter shapes at 7 T as the basis for more ``natural'' communication BCIs.},
  pmid = {32164860},
  keywords = {(Real-time) functional magnetic resonance imaging,BOLD signal,Brain hemodynamics,Brain-based communication and control,Brain-computer interface,Decoding,Neural information encoding,Neurofeedback}
}

@article{soviany22,
  title = {Curriculum {{Learning}}: {{A Survey}}},
  shorttitle = {Curriculum {{Learning}}},
  author = {Soviany, Petru and Ionescu, Radu Tudor and Rota, Paolo and Sebe, Nicu},
  year = {2022},
  month = jun,
  journal = {International Journal of Computer Vision},
  volume = {130},
  number = {6},
  pages = {1526--1565},
  issn = {1573-1405},
  doi = {10.1007/s11263-022-01611-x},
  abstract = {Training machine learning models in a meaningful order, from the easy samples to the hard ones, using curriculum learning can provide performance improvements over the standard training approach based on random data shuffling, without any additional computational costs. Curriculum learning strategies have been successfully employed in all areas of machine learning, in a wide range of tasks. However, the necessity of finding a way to rank the samples from easy to hard, as well as the right pacing function for introducing more difficult data can limit the usage of the curriculum approaches. In this survey, we show how these limits have been tackled in the literature, and we present different curriculum learning instantiations for various tasks in machine learning. We construct a multi-perspective taxonomy of curriculum learning approaches by hand, considering various classification criteria. We further build a hierarchical tree of curriculum learning methods using an agglomerative clustering algorithm, linking the discovered clusters with our taxonomy. At the end, we provide some interesting directions for future work.},
  langid = {english},
  keywords = {68T01,68T05,68T40,68T45,68T50,68U10,68U15,Curriculum learning,Deep learning,Learning from easy to hard,Neural networks,Self-paced learning},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Soviany et al_2022_Curriculum Learning.pdf}
}

@article{sporns18,
  title = {Graph Theory Methods: Applications in Brain Networks},
  shorttitle = {Graph Theory Methods},
  author = {Sporns, Olaf},
  year = {2018},
  month = jun,
  journal = {Dialogues in Clinical Neuroscience},
  volume = {20},
  number = {2},
  pages = {111--121},
  publisher = {{Taylor \& Francis}},
  issn = {null},
  doi = {10.31887/DCNS.2018.20.2/osporns},
  abstract = {Network neuroscience is a thriving and rapidly expanding field. Empirical data on brain networks, from molecular to behavioral scales, are ever increasing in size and complexity. These developments lead to a strong demand for appropriate tools and methods that model and analyze brain network data, such as those provided by graph theory. This brief review surveys some of the most commonly used and neurobiologically insightful graph measures and techniques. Among these, the detection of network communities or modules, and the identification of central network elements that facilitate communication and signal transfer, are particularly salient. A number of emerging trends are the growing use of generative models, dynamic (time-varying) and multilayer networks, as well as the application of algebraic topology. Overall, graph theory methods are centrally important to understanding the architecture, development, and evolution of brain networks.},
  pmid = {30250388},
  keywords = {connectome,functional MRI,graph theory,neuroanatomy,neuroimaging},
  annotation = {\_eprint: https://doi.org/10.31887/DCNS.2018.20.2/osporns},
  file = {C\:\\Users\\johns\\Zotero\\storage\\K3HSM9LF\\Sporns_2018_Graph theory methods.pdf}
}

@article{sridharan22,
  title = {High-Performance Microbial Opsins for Spatially and Temporally Precise Perturbations of Large Neuronal Networks},
  author = {Sridharan, Savitha and Gajowa, Marta A. and Ogando, Mora B. and Jagadisan, Uday K. and Abdeladim, Lamiae and Sadahiro, Masato and Bounds, Hayley A. and Hendricks, William D. and Turney, Toby S. and Tayler, Ian and Gopakumar, Karthika and Oldenburg, Ian Ant{\'o}n and Brohawn, Stephen G. and Adesnik, Hillel},
  year = {2022},
  month = feb,
  journal = {Neuron},
  volume = {110},
  number = {7},
  pages = {1139-1155.e6},
  publisher = {{Elsevier BV}},
  issn = {10974199},
  doi = {10.1016/j.neuron.2022.01.008},
  abstract = {The biophysical properties of existing optogenetic tools constrain the scale, speed, and fidelity of precise optogenetic control. Here, we use structure-guided mutagenesis to engineer opsins that exhibit very high potency while retaining fast kinetics. These new opsins enable large-scale, temporally and spatially precise control of population neural activity. We extensively benchmark these new opsins against existing optogenetic tools and provide a detailed biophysical characterization of a diverse family of opsins under two-photon illumination. This establishes a resource for matching the optimal opsin to the goals and constraints of patterned optogenetics experiments. Finally, by combining these new opsins with optimized procedures for holographic photostimulation, we demonstrate the simultaneous coactivation of several hundred spatially defined neurons with a single hologram and nearly double that number by temporally interleaving holograms at fast rates. These newly engineered opsins substantially extend the capabilities of patterned illumination optogenetic paradigms for addressing neural circuits and behavior.},
  pmid = {35120626},
  keywords = {3D-SHOT,calcium imaging,ChroME,holography,neural circuits,neural coding,opsins,optogenetics,two-photon,visual cortex},
  file = {C\:\\Users\\johns\\Zotero\\storage\\ECDMVRST\\Sridharan et al_2022_High-performance microbial opsins for spatially and temporally precise.pdf}
}

@article{srinivasan18,
  title = {Closed-Loop Functional Optogenetic Stimulation},
  author = {Srinivasan, Shriya S. and Maimon, Benjamin E. and Diaz, Maurizio and Song, Hyungeun and Herr, Hugh M.},
  year = {2018},
  month = dec,
  journal = {Nature Communications},
  volume = {9},
  number = {1},
  pages = {1--10},
  publisher = {{Nature Publishing Group}},
  issn = {20411723},
  doi = {10.1038/s41467-018-07721-w},
  abstract = {Optogenetics has been used to orchestrate temporal- and tissue-specific control of neural tissues and offers a wealth of unique advantages for neuromuscular control. Here, we establish a~closed-loop functional optogenetic stimulation (CL-FOS) system to control ankle joint position in murine models. Using the measurement of either joint angle or fascicle length as a feedback signal, we compare the controllability of CL-FOS to closed-loop functional electrical stimulation (CL-FES) and demonstrate significantly greater accuracy, lower rise times and lower overshoot percentages. We demonstrate orderly recruitment of motor units and reduced fatigue when performing cyclical movements with CL-FOS compared with CL-FES. We develop and investigate a 3-phase, photo-kinetic model to elucidate the underlying mechanisms for temporal variations in optogenetically activated neuromusculature during closed-loop control experiments. Methods and insights from this study lay the groundwork for the development of closed-loop optogenetic neuromuscular stimulation therapies and devices for peripheral limb control.},
  pmid = {30546051},
  keywords = {Biomaterials,Biomedical engineering,Musculoskeletal system,Neurology},
  file = {C\:\\Users\\johns\\Zotero\\storage\\CCB2K5JR\\Srinivasan et al_2018_Closed-loop functional optogenetic stimulation.pdf}
}

@article{steinmetz21,
  title = {Neuropixels 2.0: {{A}} Miniaturized High-Density Probe for Stable, Long-Term Brain Recordings},
  author = {Steinmetz, Nicholas A. and Aydin, Cagatay and Lebedeva, Anna and Okun, Michael and Pachitariu, Marius and Bauza, Marius and Beau, Maxime and Bhagat, Jai and B{\"o}hm, Claudia and Broux, Martijn and Chen, Susu and Colonell, Jennifer and Gardner, Richard J. and Karsh, Bill and Kloosterman, Fabian and Kostadinov, Dimitar and {Mora-Lopez}, Carolina and O'Callaghan, John and Park, Junchol and Putzeys, Jan and Sauerbrei, Britton and {van Daal}, Rik J.J. and Vollan, Abraham Z. and Wang, Shiwei and Welkenhuysen, Marleen and Ye, Zhiwen and Dudman, Joshua T. and Dutta, Barundeb and Hantman, Adam W. and Harris, Kenneth D. and Lee, Albert K. and Moser, Edvard I. and O'Keefe, John and Renart, Alfonso and Svoboda, Karel and H{\"a}usser, Michael and Haesler, Sebastian and Carandini, Matteo and Harris, Timothy D.},
  year = {2021},
  month = apr,
  journal = {Science},
  volume = {372},
  number = {6539},
  publisher = {{American Association for the Advancement of Science}},
  issn = {10959203},
  doi = {10.1126/science.abf4588},
  abstract = {Measuring the dynamics of neural processing across time scales requires following the spiking of thousands of individual neurons over milliseconds and months. To address this need, we introduce the Neuropixels 2.0 probe together with newly designed analysis algorithms. The probe has more than 5000 sites and is miniaturized to facilitate chronic implants in small mammals and recording during unrestrained behavior. High-quality recordings over long time scales were reliably obtained in mice and rats in six laboratories. Improved site density and arrangement combined with newly created data processing methods enable automatic post hoc correction for brain movements, allowing recording from the same neurons for more than 2 months. These probes and algorithms enable stable recordings from thousands of sites during free behavior, even in small animals such as mice.},
  pmid = {33859006},
  file = {C\:\\Users\\johns\\Zotero\\storage\\XXE7DYIY\\full-text.pdf}
}

@article{stimberg19,
  title = {Brian 2, an Intuitive and Efficient Neural Simulator},
  author = {Stimberg, Marcel and Brette, Romain and Goodman, Dan F.M.},
  year = {2019},
  month = aug,
  journal = {eLife},
  volume = {8},
  publisher = {{eLife Sciences Publications Ltd}},
  issn = {2050084X},
  doi = {10.7554/eLife.47314},
  abstract = {Brian 2 allows scientists to simply and efficiently simulate spiking neural network models. These models can feature novel dynamical equations, their interactions with the environment, and experimental protocols. To preserve high performance when defining new models, most simulators offer two options: Low-level programming or description languages. The first option requires expertise, is prone to errors, and is problematic for reproducibility. The second option cannot describe all aspects of a computational experiment, such as the potentially complex logic of a stimulation protocol. Brian addresses these issues using runtime code generation. Scientists write code with simple and concise high-level descriptions, and Brian transforms them into efficient low-level code that can run interleaved with their code. We illustrate this with several challenging examples: A plastic model of the pyloric network, a closed-loop sensorimotor model, a programmatic exploration of a neuron model, and an auditory model with real-time input.},
  pmid = {31429824},
  file = {C\:\\Users\\johns\\Zotero\\storage\\KUCA8KE8\\Stimberg et al_2020_Brian2GeNN.pdf;C\:\\Users\\johns\\Zotero\\storage\\T8E8T2PL\\Stimberg et al_2019_Brian 2, an intuitive and efficient neural simulator.pdf}
}

@article{stimberg20,
  title = {{{Brian2GeNN}}: Accelerating Spiking Neural Network Simulations with Graphics Hardware},
  author = {Stimberg, Marcel and Goodman, Dan F.M. and Nowotny, Thomas},
  year = {2020},
  month = dec,
  journal = {Scientific Reports},
  volume = {10},
  number = {1},
  publisher = {{Nature Research}},
  issn = {20452322},
  doi = {10.1038/s41598-019-54957-7},
  abstract = {``Brian'' is a popular Python-based simulator for spiking neural networks, commonly used in computational neuroscience. GeNN is a C++-based meta-compiler for accelerating spiking neural network simulations using consumer or high performance grade graphics processing units (GPUs). Here we introduce a new software package, Brian2GeNN, that connects the two systems so that users can make use of GeNN GPU acceleration when developing their models in Brian, without requiring any technical knowledge about GPUs, C++ or GeNN. The new Brian2GeNN software uses a pipeline of code generation to translate Brian scripts into C++ code that can be used as input to GeNN, and subsequently can be run on suitable NVIDIA GPU accelerators. From the user's perspective, the entire pipeline is invoked by adding two simple lines to their Brian scripts. We have shown that using Brian2GeNN, two non-trivial models from the literature can run tens to hundreds of times faster than on CPU.}
}

@article{stringer21,
  title = {High-Precision Coding in Visual Cortex},
  author = {Stringer, Carsen and Michaelos, Michalis and Tsyboulski, Dmitri and Lindo, Sarah E. and Pachitariu, Marius},
  year = {2021},
  month = may,
  journal = {Cell},
  volume = {184},
  number = {10},
  pages = {2767-2778.e15},
  publisher = {{Cell Press}},
  issn = {10974172},
  doi = {10.1016/j.cell.2021.03.042},
  abstract = {Individual neurons in visual cortex provide the brain with unreliable estimates of visual features. It is not known whether the single-neuron variability is correlated across large neural populations, thus impairing the global encoding of stimuli. We recorded simultaneously from up to 50,000 neurons in mouse primary visual cortex (V1) and in higher order visual areas and measured stimulus discrimination thresholds of 0.35\textdegree{} and 0.37\textdegree, respectively, in an orientation decoding task. These neural thresholds were almost 100 times smaller than the behavioral discrimination thresholds reported in mice. This discrepancy could not be explained by stimulus properties or arousal states. Furthermore, behavioral variability during a sensory discrimination task could not be explained by neural variability in V1. Instead, behavior-related neural activity arose dynamically across a network of non-sensory brain areas. These results imply that perceptual discrimination in mice is limited by downstream decoders, not by neural noise in sensory representations.},
  pmid = {33857423},
  keywords = {information theory,large-scale neural recordings,population coding,visual cortex}
}

@article{stujenske15,
  title = {Modeling the {{Spatiotemporal Dynamics}} of {{Light}} and {{Heat Propagation}} for {{InVivo Optogenetics}}},
  author = {Stujenske, Joseph M. and Spellman, Timothy and Gordon, Joshua A.},
  year = {2015},
  month = jul,
  journal = {Cell Reports},
  volume = {12},
  number = {3},
  pages = {525--534},
  publisher = {{Elsevier}},
  issn = {22111247},
  doi = {10.1016/j.celrep.2015.06.036},
  abstract = {Despite the increasing use of optogenetics invivo, the effects of direct light exposure to brain tissue are understudied. Of particular concern is the potential for heat induced by prolonged optical stimulation. We demonstrate that high-intensity light, delivered through an optical fiber, is capable of elevating firing rate locally, even in the absence of opsin expression. Predicting the severity and spatial extent of any temperature increase during optogenetic stimulation is therefore of considerable importance. Here, we describe a realistic model that simulates light and heat propagation during optogenetic experiments. We validated the model by comparing predicted and measured temperature changes invivo. We further demonstrate the utility of this model by comparing predictions for various wavelengths of light and fiber sizes, as well as testing methods for reducing heat effects on neural targets invivo.},
  pmid = {26166563},
  file = {C\:\\Users\\johns\\Zotero\\storage\\LW8ML23X\\Stujenske et al_2015_Modeling the Spatiotemporal Dynamics of Light and Heat Propagation for InVivo.pdf}
}

@article{sun21,
  title = {A {{Temporal Precision Approach}} for {{Deep Transcranial Optogenetics}} with {{Non-invasive Surgery}}},
  author = {Sun, Shanshan and Shi, Jiali and Wang, Yongjie and Cheng, Jun and Huang, Zhihui},
  year = {2021},
  month = aug,
  journal = {Neuroscience Bulletin},
  volume = {37},
  number = {8},
  pages = {1260--1263},
  issn = {1995-8218},
  doi = {10.1007/s12264-021-00721-9},
  langid = {english},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Sun et al_2021_A Temporal Precision Approach for Deep Transcranial Optogenetics with.pdf}
}

@article{sussillo13,
  title = {Opening the {{Black Box}}: {{Low-Dimensional Dynamics}} in {{High-Dimensional Recurrent Neural Networks}}},
  shorttitle = {Opening the {{Black Box}}},
  author = {Sussillo, David and Barak, Omri},
  year = {2013},
  month = mar,
  journal = {Neural Computation},
  volume = {25},
  number = {3},
  pages = {626--649},
  issn = {0899-7667},
  doi = {10.1162/NECO_a_00409},
  abstract = {Recurrent neural networks (RNNs) are useful tools for learning nonlinear relationships between time-varying inputs and outputs with complex temporal dependencies. Recently developed algorithms have been successful at training RNNs to perform a wide variety of tasks, but the resulting networks have been treated as black boxes: their mechanism of operation remains unknown. Here we explore the hypothesis that fixed points, both stable and unstable, and the linearized dynamics around them, can reveal crucial aspects of how RNNs implement their computations. Further, we explore the utility of linearization in areas of phase space that are not true fixed points but merely points of very slow movement. We present a simple optimization technique that is applied to trained RNNs to find the fixed and slow points of their dynamics. Linearization around these slow regions can be used to explore, or reverse-engineer, the behavior of the RNN. We describe the technique, illustrate it using simple examples, and finally showcase it on three high-dimensional RNN examples: a 3-bit flip-flop device, an input-dependent sine wave generator, and a two-point moving average. In all cases, the mechanisms of trained networks could be inferred from the sets of fixed and slow points and the linearized dynamics around them.},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Sussillo_Barak_2013_Opening the Black Box.pdf}
}

@article{sussillo14,
  title = {Neural Circuits as Computational Dynamical Systems},
  author = {Sussillo, David},
  year = {2014},
  month = apr,
  journal = {Current Opinion in Neurobiology},
  series = {Theoretical and Computational Neuroscience},
  volume = {25},
  pages = {156--163},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2014.01.008},
  abstract = {Many recent studies of neurons recorded from cortex reveal complex temporal dynamics. How such dynamics embody the computations that ultimately lead to behavior remains a mystery. Approaching this issue requires developing plausible hypotheses couched in terms of neural dynamics. A tool ideally suited to aid in this question is the recurrent neural network (RNN). RNNs straddle the fields of nonlinear dynamical systems and machine learning and have recently seen great advances in both theory and application. I summarize recent theoretical and technological advances and highlight an example of how RNNs helped to explain perplexing high-dimensional neurophysiological data in the prefrontal cortex.},
  langid = {english}
}

@article{sussillo16,
  title = {{{LFADS}} - {{Latent Factor Analysis}} via {{Dynamical Systems}}},
  author = {Sussillo, David and Jozefowicz, Rafal and Abbott, L. F. and Pandarinath, Chethan},
  year = {2016},
  month = aug,
  eprint = {1608.06315},
  eprinttype = {arxiv},
  abstract = {Neuroscience is experiencing a data revolution in which many hundreds or thousands of neurons are recorded simultaneously. Currently, there is little consensus on how such data should be analyzed. Here we introduce LFADS (Latent Factor Analysis via Dynamical Systems), a method to infer latent dynamics from simultaneously recorded, single-trial, high-dimensional neural spiking data. LFADS is a sequential model based on a variational auto-encoder. By making a dynamical systems hypothesis regarding the generation of the observed data, LFADS reduces observed spiking to a set of low-dimensional temporal factors, per-trial initial conditions, and inferred inputs. We compare LFADS to existing methods on synthetic data and show that it significantly out-performs them in inferring neural firing rates and latent dynamics.},
  archiveprefix = {arXiv},
  file = {C\:\\Users\\johns\\Zotero\\storage\\J6RQXXRQ\\Sussillo et al_2016_LFADS - Latent Factor Analysis via Dynamical Systems.pdf}
}

@article{svoboda06,
  title = {Principles of {{Two-Photon Excitation Microscopy}} and {{Its Applications}} to {{Neuroscience}}},
  author = {Svoboda, Karel and Yasuda, Ryohei},
  year = {2006},
  month = jun,
  journal = {Neuron},
  volume = {50},
  number = {6},
  pages = {823--839},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2006.05.019},
  abstract = {The brain is complex and dynamic. The spatial scales of interest to the neurobiologist range from individual synapses ({$\sim$}1 {$\mu$}m) to neural circuits (centimeters); the timescales range from the flickering of channels (less than a millisecond) to long-term memory (years). Remarkably, fluorescence microscopy has the potential to revolutionize research on all of these spatial and temporal scales. Two-photon excitation (2PE) laser scanning microscopy allows high-resolution and high-sensitivity fluorescence microscopy in intact neural tissue, which is hostile to traditional forms of microscopy. Over the last 10 years, applications of 2PE, including microscopy and photostimulation, have contributed to our understanding of a broad array of neurobiological phenomena, including the dynamics of single channels in individual synapses and the functional organization of cortical maps. Here we review the principles of 2PE microscopy, highlight recent applications, discuss its limitations, and point to areas for future research and development.},
  langid = {english},
  file = {C\:\\Users\\johns\\Zotero\\storage\\GZ3GIHTM\\Svoboda_Yasuda_2006_Principles of Two-Photon Excitation Microscopy and Its Applications to.pdf}
}

@article{tafazoli20,
  title = {Learning to Control the Brain through Adaptive Closed-Loop Patterned Stimulation},
  author = {Tafazoli, Sina and MacDowell, Camden J. and Che, Zongda and Letai, Katherine C. and Steinhardt, Cynthia R. and Buschman, Timothy J.},
  year = {2020},
  month = oct,
  journal = {Journal of Neural Engineering},
  volume = {17},
  number = {5},
  pages = {056007},
  publisher = {{IOP Publishing}},
  issn = {1741-2552},
  doi = {10.1088/1741-2552/abb860},
  abstract = {Objective. Stimulation of neural activity is an important scientific and clinical tool, causally testing hypotheses and treating neurodegenerative and neuropsychiatric diseases. However, current stimulation approaches cannot flexibly control the pattern of activity in populations of neurons. To address this, we developed a model-free, adaptive, closed-loop stimulation (ACLS) system that learns to use multi-site electrical stimulation to control the pattern of activity of a population of neurons. Approach. The ACLS system combined multi-electrode electrophysiological recordings with multi-site electrical stimulation to simultaneously record the activity of a population of 5\textendash 15 multiunit neurons and deliver spatially-patterned electrical stimulation across 4\textendash 16 sites. Using a closed-loop learning system, ACLS iteratively updated the pattern of stimulation to reduce the difference between the observed neural response and a specific target pattern of firing rates in the recorded multiunits. Main results. In silico and in vivo experiments showed ACLS learns to produce specific patterns of neural activity (in {$\sim$}15 min) and was robust to noise and drift in neural responses. In visual cortex of awake mice, ACLS learned electrical stimulation patterns that produced responses similar to the natural response evoked by visual stimuli. Similar to how repetition of a visual stimulus causes an adaptation in the neural response, the response to electrical stimulation was adapted when it was preceded by the associated visual stimulus. Significance. Our results show an ACLS system that can learn, in real-time, to generate specific patterns of neural activity. This work provides a framework for using model-free closed-loop learning to control neural activity.},
  langid = {english},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Tafazoli et al_2020_Learning to control the brain through adaptive closed-loop patterned stimulation.pdf}
}

@article{tal20,
  title = {Oscillatory {{Bursting}} as a {{Mechanism}} for {{Temporal Coupling}} and {{Information Coding}}},
  author = {Tal, Idan and Neymotin, Samuel and Bickel, Stephan and Lakatos, Peter and Schroeder, Charles E.},
  year = {2020},
  journal = {Frontiers in Computational Neuroscience},
  volume = {14},
  issn = {1662-5188},
  abstract = {Even the simplest cognitive processes involve interactions between cortical regions. To study these processes, we usually rely on averaging across several repetitions of a task or across long segments of data to reach a statistically valid conclusion. Neuronal oscillations reflect synchronized excitability fluctuations in ensembles of neurons and can be observed in electrophysiological recordings in the presence or absence of an external stimulus. Oscillatory brain activity has been viewed as sustained increase in power at specific frequency bands. However, this perspective has been challenged in recent years by the notion that oscillations may occur as transient burst-like events that occur in individual trials and may only appear as sustained activity when multiple trials are averaged together. In this review, we examine the idea that oscillatory activity can manifest as a transient burst as well as a sustained increase in power. We discuss the technical challenges involved in the detection and characterization of transient events at the single trial level, the mechanisms that might generate them and the features that can be extracted from these events to study single-trial dynamics of neuronal ensemble activity.},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Tal et al_2020_Oscillatory Bursting as a Mechanism for Temporal Coupling and Information Coding.pdf}
}

@article{telenczuk20,
  title = {A Kernel-Based Method to Calculate Local Field Potentials from Networks of Spiking Neurons},
  author = {Telenczuk, Bartosz and Telenczuk, Maria and Destexhe, Alain},
  year = {2020},
  month = oct,
  journal = {Journal of Neuroscience Methods},
  volume = {344},
  pages = {108871},
  publisher = {{Elsevier}},
  issn = {1872678X},
  doi = {10.1016/j.jneumeth.2020.108871},
  abstract = {Background: The local field potential (LFP) is usually calculated from current sources arising from transmembrane currents, in particular in asymmetric cellular morphologies such as pyramidal neurons. New method: Here, we adopt a different point of view and relate the spiking of neurons to the LFP through efferent synaptic connections and provide a method to calculate LFPs. Results: We show that the so-called unitary LFPs (uLFP) provide the key to such a calculation. We show experimental measurements and simulations of uLFPs in neocortex and hippocampus, for both excitatory and inhibitory neurons. We fit a ``kernel'' function to measurements of uLFPs, and we estimate its spatial and temporal spread by using simulations of morphologically detailed reconstructions of hippocampal pyramidal neurons. Assuming that LFPs are the sum of uLFPs generated by every neuron in the network, the LFP generated by excitatory and inhibitory neurons can be calculated by convolving the trains of action potentials with the kernels estimated from uLFPs. This provides a method to calculate the LFP from networks of spiking neurons, even for point neurons for which the LFP is not easily defined. We show examples of LFPs calculated from networks of point neurons and compare to the LFP calculated from synaptic currents. Conclusions: The kernel-based method provides a practical way to calculate LFPs from networks of point neurons.},
  pmid = {32687850},
  keywords = {Biophysics,Computational models,Electric potential,Excitatory synapse,Inhibitory synapse,Neural simulation,Unitary fields},
  file = {C\:\\Users\\johns\\Zotero\\storage\\7TBQ7PJG\\Telenczuk et al_2020_A kernel-based method to calculate local field potentials from networks of.pdf}
}

@article{thornton19,
  title = {The Virtual Electrode Recording Tool for Extracellular Potentials ({{VERTEX}}) {{Version}} 2.0: {{Modelling}} in Vitro Electrical Stimulation of Brain Tissue},
  author = {Thornton, Christopher and Hutchings, Frances and Kaiser, Marcus},
  year = {2019},
  journal = {Wellcome Open Research},
  volume = {4},
  publisher = {{F1000 Research Ltd}},
  issn = {2398502X},
  doi = {10.12688/wellcomeopenres.15058.1},
  abstract = {Neuronal circuits can be modelled in detail allowing us to predict the effects of stimulation on individual neurons. Electrical stimulation of neuronal circuits in vitro and in vivo excites a range of neurons within the tissue and measurements of neural activity, e.g the local field potential (LFP), are again an aggregate of a large pool of cells. The previous version of our Virtual Electrode Recording Tool for EXtracellular Potentials (VERTEX) allowed for the simulation of the LFP generated by a patch of brain tissue. Here, we extend VERTEX to simulate the effect of electrical stimulation through a focal electric field. We observe both direct changes in neural activity and changes in synaptic plasticity. Testing our software in a model of a rat neocortical slice, we determine the currents contributing to the LFP, the effects of paired pulse stimulation to induce short term plasticity (STP), and the effect of theta burst stimulation (TBS) to induce long term potentiation (LTP).},
  keywords = {Electrical Stimulation,Local Field Potential,Long Term Potentiation,Neocortex,Short Term Plasticity,Spike-timing Dependent Plasticity,Synaptic Plasticity},
  file = {C\:\\Users\\johns\\Zotero\\storage\\X5KQD7B3\\Thornton et al_2019_The virtual electrode recording tool for extracellular potentials (VERTEX).pdf}
}

@article{tomsett15,
  title = {Virtual {{Electrode Recording Tool}} for {{EXtracellular}} Potentials ({{VERTEX}}): Comparing Multi-Electrode Recordings from Simulated and Biological Mammalian Cortical Tissue},
  author = {Tomsett, Richard J. and Ainsworth, Matt and Thiele, Alexander and Sanayei, Mehdi and Chen, Xing and Gieselmann, Marc A. and Whittington, Miles A. and Cunningham, Mark O. and Kaiser, Marcus},
  year = {2015},
  month = jul,
  journal = {Brain Structure and Function},
  volume = {220},
  number = {4},
  pages = {2333--2353},
  publisher = {{Springer Verlag}},
  issn = {18632661},
  doi = {10.1007/s00429-014-0793-x},
  abstract = {Local field potentials (LFPs) sampled with extracellular electrodes are frequently used as a measure of population neuronal activity. However, relating such measurements to underlying neuronal behaviour and connectivity is non-trivial. To help study this link, we developed the Virtual Electrode Recording Tool for EXtracellular potentials (VERTEX). We first identified a reduced neuron model that retained the spatial and frequency filtering characteristics of extracellular potentials from neocortical neurons. We then developed VERTEX as an easy-to-use Matlab tool for simulating LFPs from large populations ({$>$}100,000 neurons). A VERTEX-based simulation successfully reproduced features of the LFPs from an in vitro multi-electrode array recording of macaque neocortical tissue. Our model, with virtual electrodes placed anywhere in 3D, allows direct comparisons with the in vitro recording setup. We envisage that VERTEX will stimulate experimentalists, clinicians, and computational neuroscientists to use models to understand the mechanisms underlying measured brain dynamics in health and disease.},
  pmid = {24863422},
  keywords = {Computational modelling,Gamma oscillation,Local field potential,Macaque,Microconnectome,Neocortex},
  file = {C\:\\Users\\johns\\Zotero\\storage\\TBTKP62S\\Tomsett et al_2015_Virtual Electrode Recording Tool for EXtracellular potentials (VERTEX).pdf}
}

@article{tran20,
  title = {Fast Simulation of Extracellular Action Potential Signatures Based on a Morphological Filtering Approximation},
  author = {Tran, Harry and Ranta, Radu and Le Cam, Steven and {Louis-Dorr}, Val{\'e}rie},
  year = {2020},
  month = jan,
  journal = {Journal of Computational Neuroscience},
  volume = {48},
  number = {1},
  pages = {27--46},
  publisher = {{Springer}},
  issn = {15736873},
  doi = {10.1007/s10827-019-00735-3},
  abstract = {Simulating extracellular recordings of neuronal populations is an important and challenging task both for understanding the nature and relationships between extracellular field potentials at different scales, and for the validation of methodological tools for signal analysis such as spike detection and sorting algorithms. Detailed neuronal multicompartmental models with active or passive compartments are commonly used in this objective. Although using such realistic NEURON models could lead to realistic extracellular potentials, it may require a high computational burden making the simulation of large populations difficult without a workstation. We propose in this paper a novel method to simulate extracellular potentials of firing neurons, taking into account the NEURON geometry and the relative positions of the electrodes. The simulator takes the form of a linear geometry based filter that models the shape of an action potential by taking into account its generation in the cell body / axon hillock and its propagation along the axon. The validity of the approach for different NEURON morphologies is assessed. We demonstrate that our method is able to reproduce realistic extracellular action potentials in a given range of axon/dendrites surface ratio, with a time-efficient computational burden.},
  pmid = {31953614},
  keywords = {Computational modelling,Extracellular action potential,LFP},
  file = {C\:\\Users\\johns\\Zotero\\storage\\WV37WZGW\\Tran et al_2020_Fast simulation of extracellular action potential signatures based on a.pdf}
}

@article{trensch18,
  title = {Rigorous {{Neural Network Simulations}}: {{A Model Substantiation Methodology}} for {{Increasing}} the {{Correctness}} of {{Simulation Results}} in the {{Absence}} of {{Experimental Validation Data}}},
  shorttitle = {Rigorous {{Neural Network Simulations}}},
  author = {Trensch, Guido and Gutzen, Robin and Blundell, Inga and Denker, Michael and Morrison, Abigail},
  year = {2018},
  journal = {Frontiers in Neuroinformatics},
  volume = {12},
  issn = {1662-5196},
  abstract = {The reproduction and replication of scientific results is an indispensable aspect of good scientific practice, enabling previous studies to be built upon and increasing our level of confidence in them. However, reproducibility and replicability are not sufficient: an incorrect result will be accurately reproduced if the same incorrect methods are used. For the field of simulations of complex neural networks, the causes of incorrect results vary from insufficient model implementations and data analysis methods, deficiencies in workmanship (e.g., simulation planning, setup, and execution) to errors induced by hardware constraints (e.g., limitations in numerical precision). In order to build credibility, methods such as verification and validation have been developed, but they are not yet well-established in the field of neural network modeling and simulation, partly due to ambiguity concerning the terminology. In this manuscript, we propose a terminology for model verification and validation in the field of neural network modeling and simulation. We outline a rigorous workflow derived from model verification and validation methodologies for increasing model credibility when it is not possible to validate against experimental data. We compare a published minimal spiking network model capable of exhibiting the development of polychronous groups, to its reproduction on the SpiNNaker neuromorphic system, where we consider the dynamics of several selected network states. As a result, by following a formalized process, we show that numerical accuracy is critically important, and even small deviations in the dynamics of individual neurons are expressed in the dynamics at network level.},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Trensch et al_2018_Rigorous Neural Network Simulations.pdf}
}

@article{vaidya19,
  title = {Lesion {{Studies}} in {{Contemporary Neuroscience}}},
  author = {Vaidya, Avinash R. and Pujara, Maia S. and Petrides, Michael and Murray, Elisabeth A. and Fellows, Lesley K.},
  year = {2019},
  month = aug,
  journal = {Trends in Cognitive Sciences},
  volume = {23},
  number = {8},
  pages = {653--671},
  publisher = {{Elsevier Ltd}},
  issn = {1879307X},
  doi = {10.1016/j.tics.2019.05.009},
  abstract = {Studies of humans with focal brain damage and non-human animals with experimentally induced brain lesions have provided pivotal insights into the neural basis of behavior. As the repertoire of neural manipulation and recording techniques expands, the utility of studying permanent brain lesions bears re-examination. Studies on the effects of permanent lesions provide vital data about brain function that are distinct from those of reversible manipulations. Focusing on work carried out in humans and nonhuman primates, we address the inferential strengths and limitations of lesion studies, recent methodological developments, the integration of this approach with other methods, and the clinical and ecological relevance of this research. We argue that lesion studies are essential to the rigorous assessment of neuroscience theories.},
  pmid = {31279672},
  keywords = {brain damage,humans,lesion–behavior mapping,lesion–symptom mapping,methods,neuropsychology,nonhuman primates}
}

@article{vierock21,
  title = {{{BiPOLES}} Is an Optogenetic Tool Developed for Bidirectional Dual-Color Control of Neurons},
  author = {Vierock, Johannes and {Rodriguez-Rozada}, Silvia and Dieter, Alexander and Pieper, Florian and Sims, Ruth and Tenedini, Federico and Bergs, Amelie C.F. and Bendifallah, Imane and Zhou, Fangmin and Zeitzschel, Nadja and Ahlbeck, Joachim and Augustin, Sandra and Sauter, Kathrin and Papagiakoumou, Eirini and Gottschalk, Alexander and Soba, Peter and Emiliani, Valentina and Engel, Andreas K. and Hegemann, Peter and Wiegert, J. Simon},
  year = {2021},
  month = jul,
  journal = {Nature Communications},
  volume = {12},
  number = {1},
  pages = {1--20},
  publisher = {{Nature Publishing Group}},
  issn = {20411723},
  doi = {10.1038/s41467-021-24759-5},
  abstract = {Optogenetic manipulation of neuronal activity through excitatory and inhibitory opsins has become an indispensable experimental strategy in neuroscience research. For many applications bidirectional control of neuronal activity allowing both excitation and inhibition of the same neurons in a single experiment is desired. This requires low spectral overlap between the excitatory and inhibitory opsin, matched photocurrent amplitudes and a fixed expression ratio. Moreover, independent activation of two distinct neuronal populations with different optogenetic actuators is still challenging due to blue-light sensitivity of all opsins. Here we report BiPOLES, an optogenetic tool for potent neuronal excitation and inhibition with light of two different wavelengths. BiPOLES enables sensitive, reliable dual-color neuronal spiking and silencing with single- or two-photon excitation, optical tuning of the membrane voltage, and independent optogenetic control of two neuronal populations using a second, blue-light sensitive opsin. The utility of BiPOLES is demonstrated in worms, flies, mice and ferrets.},
  pmid = {34312384},
  keywords = {Ion channels in the nervous system,Molecular neuroscience,Multiphoton microscopy,Optogenetics},
  file = {C\:\\Users\\johns\\Zotero\\storage\\FDQU4BXI\\Vierock et al_2021_BiPOLES is an optogenetic tool developed for bidirectional dual-color control.pdf}
}

@article{vila19,
  title = {Optimizing Optogenetic Stimulation Protocols in Auditory Corticofugal Neurons Based on Closed-Loop Spike Feedback},
  author = {Vila, Charles Henri and Williamson, Ross S. and Hancock, Kenneth E. and Polley, Daniel B.},
  year = {2019},
  month = oct,
  journal = {Journal of Neural Engineering},
  volume = {16},
  number = {6},
  pages = {066023},
  publisher = {{IOP Publishing}},
  issn = {17412552},
  doi = {10.1088/1741-2552/ab39cf},
  abstract = {Objective. Optogenetics provides a means to probe functional connections between brain areas. By activating a set of presynaptic neurons and recording the activity from a downstream brain area, one can establish the sign and strength of a feedforward connection. One challenge is that there are virtually limitless patterns that can be used to stimulate a presynaptic brain area. Functional influences on downstream brain areas can depend not just on whether presynaptic neurons were activated, but how they were activated. Corticofugal axons from the auditory cortex (ACtx) heavily innervate the auditory tectum, the inferior colliculus (IC). Here, we sought to determine whether different modes of corticocollicular activation could titrate the strength of feedforward modulation of sound processing in IC neurons. Approach. We used multi-channel electrophysiology and optogenetics to record from multiple regions of the IC in awake head-fixed mice while optogenetically stimulating ACtx neurons expressing Chronos, an ultra-fast channelrhodopsin. To identify cortical activation patterns associated with the strongest effects on IC firing rates, we employed a closed-loop evolutionary optimization procedure that tailored the voltage command signal sent to the laser based on spike feedback from single IC neurons. Main results. Within minutes, our evolutionary search procedure converged on ACtx stimulation configurations that produced more effective and widespread enhancement of IC unit activity than generic activation parameters. Cortical modulation of midbrain spiking was bi-directional, as the evolutionary search procedure could be programmed to converge on activation patterns that either suppressed or enhanced sound-evoked IC firing rate. Significance. This study introduces a closed-loop optimization procedure to probe functional connections between brain areas. Our findings demonstrate that the influence of descending feedback projections on subcortical sensory processing can vary both in sign and degree depending on how cortical neurons are activated in time.},
  pmid = {31394519},
  keywords = {closed-loop,corticofugal,descending}
}

@article{viswam19,
  title = {Optimal Electrode Size for Multi-Scale Extracellular-Potential Recording from Neuronal Assemblies},
  author = {Viswam, Vijay and Obien, Marie Engelene J. and Franke, Felix and Frey, Urs and Hierlemann, Andreas},
  year = {2019},
  journal = {Frontiers in Neuroscience},
  volume = {13},
  number = {APR},
  pages = {385},
  publisher = {{Frontiers Media S.A.}},
  issn = {1662453X},
  doi = {10.3389/fnins.2019.00385},
  abstract = {Advances in microfabrication technology have enabled the production of devices containing arrays of thousands of closely spaced recording electrodes, which afford subcellular resolution of electrical signals in neurons and neuronal networks. Rationalizing the electrode size and configuration in such arrays demands consideration of application-specific requirements and inherent features of the electrodes. Tradeoffs among size, spatial density, sensitivity, noise, attenuation, and other factors are inevitable. Although recording extracellular signals from neurons with planar metal electrodes is fairly well established, the effects of the electrode characteristics on the quality and utility of recorded signals, especially for small, densely packed electrodes, have yet to be fully characterized. Here, we present a combined experimental and computational approach to elucidating how electrode size, and size-dependent parameters, such as impedance, baseline noise, and transmission characteristics, influence recorded neuronal signals. Using arrays containing platinum electrodes of different sizes, we experimentally evaluated the electrode performance in the recording of local field potentials (LFPs) and extracellular action potentials (EAPs) from the following cell preparations: acute brain slices, dissociated cell cultures, and organotypic slice cultures. Moreover, we simulated the potential spatial decay of point-current sources to investigate signal averaging using known signal sources. We demonstrated that the noise and signal attenuation depend more on the electrode impedance than on electrode size, per se, especially for electrodes {$<$}10 {$\mu$}m in width or diameter to achieve high-spatial-resolution readout. By minimizing electrode impedance of small electrodes ({$<$}10 {$\mu$}m) via surface modification, we could maximize the signal-to-noise ratio to electrically visualize the propagation of axonal EAPs and to isolate single-unit spikes. Due to the large amplitude of LFP signals, recording quality was high and nearly independent of electrode size. These findings should be of value in configuring in vitro and in vivo microelectrode arrays for extracellular recordings with high spatial resolution in various applications.},
  keywords = {Electrode size,Extracellular action potential,Extracellular recording,Impedance,Local field potential,Microelectrode array},
  file = {C\:\\Users\\johns\\Zotero\\storage\\AW35SGKH\\Viswam et al_2019_Optimal electrode size for multi-scale extracellular-potential recording from.pdf}
}

@book{vo-dinh03,
  title = {Biomedical {{Photonics}}: {{Handbook}}},
  author = {{Vo-Dinh}, Tuan},
  year = {2003},
  journal = {Biomedical Photonics: Handbook},
  publisher = {{CRC Press}},
  doi = {10.1001/archfaci.3.3.207},
  abstract = {The joining of tissue by the application of heat through the use of hot-loop forceps was first described in the 1960s. In 1964, a neodymium laser was used to join small blood vessels \textemdash{} the first reported use of a laser for thermal welding of tissue. Since then, numerous experimental studies have been conducted using a variety of lasers for welding of soft tissues including blood vessels, the genitourinary tract, the gastrointestinal tract, liver, spleen, nerves, dura mater, skin, sclera, trachea, and cartilage. As we enter the 21st century, laser tissue welding has reached the threshold at which it is moving from the laboratory bench to clinical application, making this an exciting time for all involved. This chapter reviews the principles, theory, and application of laser tissue welding. An insight is also provided into several important developments that have been made involving the use of light-activated surgical adhesives to assist in the welding procedure, infrared (IR) temperature feedback control of the laser device, and computer modeling of the welding process. In addition, this chapter provides a comprehensive review of current and future clinical applications of laser tissue welding including developments in the fields of endoscopic and laparoscopic surgeries.},
  isbn = {978-0-203-00899-7},
  file = {C\:\\Users\\johns\\Zotero\\storage\\FJB7ECAF\\Biomedical Photonics Handbook by Tuan Vo-Dinh (z-lib.org).pdf}
}

@article{vyas20,
  title = {Computation through {{Neural Population Dynamics}}},
  author = {Vyas, Saurabh and Golub, Matthew D. and Sussillo, David and Shenoy, Krishna V.},
  year = {2020},
  month = jul,
  journal = {Annual Review of Neuroscience},
  volume = {43},
  pages = {249--275},
  publisher = {{Annual Reviews Inc.}},
  issn = {15454126},
  doi = {10.1146/annurev-neuro-092619-094115},
  abstract = {Significant experimental, computational, and theoretical work has identified rich structure within the coordinated activity of interconnected neural populations. An emerging challenge now is to uncover the nature of the associated computations, how they are implemented, and what role they play in driving behavior. We term this computation through neural population dynamics. If successful, this framework will reveal general motifs of neural population activity and quantitatively describe how neural population dynamics implement computations necessary for driving goal-directed behavior. Here, we start with a mathematical primer on dynamical systems theory and analytical tools necessary to apply this perspective to experimental data. Next, we highlight some recent discoveries resulting from successful application of dynamical systems. We focus on studies spanning motor control, timing, decision-making, and working memory. Finally, we briefly discuss promising recent lines of investigation and future directions for the computation through neural population dynamics framework.},
  pmid = {32640928},
  keywords = {dynamical systems,neural computation,neural population dynamics,state spaces,Why FB control},
  file = {C\:\\Users\\johns\\Zotero\\storage\\BH6C9U8N\\Vyas et al_2020_Computation through Neural Population Dynamics.pdf}
}

@article{vyas20a,
  title = {Causal {{Role}} of {{Motor Preparation}} during {{Error-Driven Learning}}},
  author = {Vyas, Saurabh and O'Shea, Daniel J. and Ryu, Stephen I. and Shenoy, Krishna V.},
  year = {2020},
  month = apr,
  journal = {Neuron},
  volume = {106},
  number = {2},
  pages = {329-339.e4},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2020.01.019},
  abstract = {Current theories suggest that an error-driven learning process updates trial-by-trial to facilitate motor adaptation. How this process interacts with motor cortical preparatory activity\textemdash which current models suggest plays a critical role in movement initiation\textemdash remains unknown. Here, we evaluated the role of motor preparation during visuomotor adaptation. We found that preparation time was inversely correlated to variance of errors on current trials and mean error on subsequent trials. We also found causal evidence that intracortical microstimulation during motor preparation was sufficient to disrupt learning. Surprisingly, stimulation did not affect current trials, but instead disrupted the update computation of a learning process, thereby affecting subsequent trials. This is consistent with a Bayesian estimation framework where the motor system reduces its learning rate by virtue of lowering error sensitivity when faced with uncertainty. This interaction between motor preparation and the error-driven learning system may facilitate new probes into mechanisms underlying trial-by-trial adaptation.},
  langid = {english},
  keywords = {dynamical systems,error-driven learning,microstimulation,motor preparation,preparatory,visuomotor adaptation},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Vyas et al_2020_Causal Role of Motor Preparation during Error-Driven Learning.pdf}
}

@article{wagenaar05,
  title = {Controlling Bursting in Cortical Cultures with Closed-Loop Multi-Electrode Stimulation},
  author = {Wagenaar, Daniel A. and Madhavan, Radhika and Pine, Jerome and Potter, Steve M.},
  year = {2005},
  month = jan,
  journal = {Journal of Neuroscience},
  volume = {25},
  number = {3},
  pages = {680--688},
  publisher = {{Society for Neuroscience}},
  issn = {02706474},
  doi = {10.1523/JNEUROSCI.4209-04.2005},
  abstract = {One of the major modes of activity of high-density cultures of dissociated neurons is globally synchronized bursting. Unlike in vivo, neuronal ensembles in culture maintain activity patterns dominated by global bursts for the lifetime of the culture (up to 2 years). We hypothesize that persistence of bursting is caused by a lack of input from other brain areas. To study this hypothesis, we grew small but dense monolayer cultures of cortical neurons and glia from rat embryos on multi-electrode arrays and used electrical stimulation to substitute for afferents. We quantified the burstiness of the firing of the cultures in spontaneous activity and during several stimulation protocols. Although slow stimulation through individual electrodes increased burstiness as a result of burst entrainment, rapid stimulation reduced burstiness. Distributing stimuli across several electrodes, as well as continuously fine-tuning stimulus strength with closed-loop feedback, greatly enhanced burst control. We conclude that externally applied electrical stimulation can substitute for natural inputs to cortical neuronal ensembles in transforming burst-dominated activity to dispersed spiking, more reminiscent of the awake cortex in vivo. This nonpharmacological method of controlling bursts will be a critical tool for exploring the information processing capacities of neuronal ensembles in vitro and has potential applications for the treatment of epilepsy.},
  pmid = {15659605},
  keywords = {Bursting,Cortex,Deep brain stimulation,Dissociated culture,Distributed stimulation,Epilepsy,Multi-electrode array},
  file = {C\:\\Users\\johns\\Zotero\\storage\\SMFN63X5\\Wagenaar et al_2005_Controlling bursting in cortical cultures with closed-loop multi-electrode.pdf}
}

@article{wang10,
  title = {Fast {{Model Predictive Control Using Online Optimization}}},
  author = {Wang, Yang and Boyd, Stephen},
  year = {2010},
  journal = {IEEE TRANSACTIONS ON CONTROL SYSTEMS TECHNOLOGY},
  volume = {18},
  number = {2},
  pages = {267},
  doi = {10.1109/TCST.2009.2017934},
  abstract = {A widely recognized shortcoming of model predictive control (MPC) is that it can usually only be used in applications with slow dynamics, where the sample time is measured in seconds or minutes. A well-known technique for implementing fast MPC is to compute the entire control law offline, in which case the on-line controller can be implemented as a lookup table. This method works well for systems with small state and input dimensions (say, no more than five), few constraints, and short time horizons. In this paper, we describe a collection of methods for improving the speed of MPC, using online optimization. These custom methods, which exploit the particular structure of the MPC problem, can compute the control action on the order of 100 times faster than a method that uses a generic optimizer. As an example, our method computes the control actions for a problem with 12 states, 3 controls, and horizon of 30 time steps (which entails solving a quadratic program with 450 variables and 1284 constraints) in around 5 ms, allowing MPC to be carried out at 200 Hz. Index Terms-Model predictive control (MPC), real-time convex optimization.},
  file = {C\:\\Users\\johns\\Zotero\\storage\\J444VKY4\\Wang_Boyd_2010_Fast Model Predictive Control Using Online Optimization.pdf}
}

@article{wang15,
  title = {An Optogenetics- and Imaging-Assisted Simultaneous Multiple Patch-Clamp Recording System for Decoding Complex Neural Circuits},
  author = {Wang, Guangfu and Wyskiel, Daniel R. and Yang, Weiguo and Wang, Yiqing and Milbern, Lana C. and Lalanne, Txomin and Jiang, Xiaolong and Shen, Ying and Sun, Qian Quan and Zhu, J. Julius},
  year = {2015},
  month = feb,
  journal = {Nature Protocols},
  volume = {10},
  number = {3},
  pages = {397--412},
  publisher = {{Nature Publishing Group}},
  issn = {17502799},
  doi = {10.1038/nprot.2015.019},
  abstract = {Deciphering neuronal circuitry is central to understanding brain function and dysfunction, yet it remains a daunting task. To facilitate the dissection of neuronal circuits, a process requiring functional analysis of synaptic connections and morphological identification of interconnected neurons, we present here a method for stable simultaneous octuple patch-clamp recordings. This method allows physiological analysis of synaptic interconnections among 4-8 simultaneously recorded neurons and/or 10-30 sequentially recorded neurons, and it allows anatomical identification of {$>$}85\% of recorded interneurons and {$>$}99\% of recorded principal neurons. We describe how to apply the method to rodent tissue slices; however, it can be used on other model organisms. We also describe the latest refinements and optimizations of mechanics, electronics, optics and software programs that are central to the realization of a combined single- and two-photon microscopy-based, optogenetics- and imaging-assisted, stable, simultaneous quadruple-viguple patch-clamp recording system. Setting up the system, from the beginning of instrument assembly and software installation to full operation, can be completed in 3-4 d.},
  pmid = {25654757},
  keywords = {Neural decoding,Neuronal physiology,Patch clamp,Synaptic transmission},
  file = {C\:\\Users\\johns\\Zotero\\storage\\LN4XXH27\\Wang et al_2015_An optogenetics- and imaging-assisted simultaneous multiple patch-clamp.pdf}
}

@article{wang18,
  title = {Fabrication and Modification of Implantable Optrode Arrays for in Vivo Optogenetic Applications},
  author = {Wang, Lulu and Huang, Kang and Zhong, Cheng and Wang, Liping and Lu, Yi},
  year = {2018},
  month = apr,
  journal = {Biophysics Reports},
  volume = {4},
  number = {2},
  pages = {82--93},
  issn = {2364-3420},
  doi = {10.1007/s41048-018-0052-4},
  langid = {english},
  keywords = {Electrodeposition,Electrophysiological recording,Neural electrode,Optical stimulation,Optogenetics,Optrode},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Wang et al_2018_Fabrication and modification of implantable optrode arrays for in vivo.pdf}
}

@article{wang96,
  title = {Gamma Oscillation by Synaptic Inhibition in a Hippocampal Interneuronal Network Model},
  author = {Wang, Xiao-Jing and Buzs{\'a}ki, Gy{\"o}rgy},
  year = {1996},
  journal = {Journal of neuroscience},
  volume = {16},
  number = {20},
  pages = {6402--6413},
  publisher = {{Soc Neuroscience}},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Wang_Buzsáki_1996_Gamma oscillation by synaptic inhibition in a hippocampal interneuronal network.pdf}
}

@article{welkenhuysen16,
  title = {An Integrated Multi-Electrode-Optrode Array for in Vitro Optogenetics},
  author = {Welkenhuysen, Marleen and Hoffman, Luis and Luo, Zhengxiang and De Proft, Anabel and {Van den Haute}, Chris and Baekelandt, Veerle and Debyser, Zeger and Gielen, Georges and Puers, Robert and Braeken, Dries},
  year = {2016},
  month = feb,
  journal = {Scientific Reports},
  volume = {6},
  number = {1},
  pages = {20353},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/srep20353},
  abstract = {Modulation of a group of cells or tissue needs to be very precise in order to exercise effective control over the cell population under investigation. Optogenetic tools have already demonstrated to be of great value in the study of neuronal circuits and in neuromodulation. Ideally, they should permit very accurate resolution, preferably down to the single cell level. Further, to address a spatially distributed sample, independently addressable multiple optical outputs should be present. In current techniques, at least one of these requirements is not fulfilled. In addition to this, it is interesting to directly monitor feedback of the modulation by electrical registration of the activity of the stimulated cells. Here, we present the fabrication and characterization of a fully integrated silicon-based multi-electrode-optrode array (MEOA) for in vitro optogenetics. We demonstrate that this device allows for artifact-free electrical recording. Moreover, the MEOA was used to reliably elicit spiking activity from ChR2-transduced neurons. Thanks to the single cell resolution stimulation capability, we could determine spatial and temporal activation patterns and spike latencies of the neuronal network. This integrated approach to multi-site combined optical stimulation and electrical recording significantly advances today's tool set for neuroscientists in their search to unravel neuronal network dynamics.},
  copyright = {2016 The Author(s)},
  langid = {english},
  keywords = {Brain,Neurology},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Welkenhuysen et al_2016_An integrated multi-electrode-optrode array for in vitro optogenetics.pdf}
}

@article{wiegert17,
  title = {Silencing {{Neurons}}: {{Tools}}, {{Applications}}, and {{Experimental Constraints}}},
  author = {Wiegert, J Simon and Mahn, Mathias and Prigge, Matthias and Printz, Yoav and Yizhar, Ofer},
  year = {2017},
  journal = {Neuron},
  volume = {95},
  number = {3},
  pages = {504--529},
  issn = {10974199},
  doi = {10.1016/j.neuron.2017.06.050},
  abstract = {Reversible silencing of neuronal activity is a powerful approach for isolating the roles of specific neuronal populations in circuit dynamics and behavior. In contrast with neuronal excitation, for which the majority of studies have used a limited number of optogenetic and chemogenetic tools, the number of genetically encoded tools used for inhibition of neuronal activity has vastly expanded. Silencing strategies vary widely in their mechanism of action and in their spatial and temporal scales. Although such manipulations are commonly applied, the design and interpretation of neuronal silencing experiments present unique challenges, both technically and conceptually. Here, we review the most commonly used tools for silencing neuronal activity and provide an in-depth analysis of their mechanism of action and utility for particular experimental applications. We further discuss the considerations that need to be given to experimental design, analysis, and interpretation of collected data. Finally, we discuss future directions for the development of new silencing approaches in neuroscience. Optogenetic and chemogenetic tools for neuronal silencing have become indispensable in modern neuroscience research. In this review, Wiegert et al. describe some of the most commonly used genetically encoded tools for silencing of neural activity, highlighting their unique features and major constraints.},
  pmid = {28772120},
  keywords = {archaerhodopsin,channelrhodopsin,chemogenetics,halorhodopsin,light-activated G-protein-coupled receptors,light-gated anion channelrhodopsins,neuronal silencing,optogenetics,synaptic transmission},
  file = {C\:\\Users\\johns\\Zotero\\storage\\SHI2I7Y9\\Wiegert et al_2017_Silencing Neurons.pdf}
}

@article{willett21,
  title = {High-Performance Brain-to-Text Communication via Handwriting},
  author = {Willett, Francis R. and Avansino, Donald T. and Hochberg, Leigh R. and Henderson, Jaimie M. and Shenoy, Krishna V.},
  year = {2021},
  month = may,
  journal = {Nature},
  volume = {593},
  number = {7858},
  pages = {249--254},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-021-03506-2},
  abstract = {Brain\textendash computer interfaces (BCIs) can restore communication to people who have lost the ability to move or speak. So far, a major focus of BCI research has been on restoring gross motor skills, such as reaching and grasping1\textendash 5 or point-and-click typing with a computer cursor6,7. However, rapid sequences of highly dexterous behaviours, such as handwriting or touch typing, might enable faster rates of communication. Here we developed an intracortical BCI that decodes attempted handwriting movements from neural activity in the motor cortex and translates it to text in real time, using a recurrent neural network decoding approach. With this BCI, our study participant, whose hand was paralysed from spinal cord injury, achieved typing speeds of 90~characters per minute with 94.1\% raw accuracy online, and greater than 99\% accuracy offline with a general-purpose autocorrect. To our knowledge, these typing speeds exceed those reported for any other BCI, and are comparable to typical smartphone typing speeds of individuals in the age group of our participant (115~characters per minute)8. Finally, theoretical considerations explain why temporally complex movements, such as handwriting, may be fundamentally easier to decode than point-to-point movements. Our results open a new approach for BCIs and demonstrate the feasibility of accurately decoding rapid, dexterous movements years after paralysis.},
  copyright = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english},
  keywords = {Brain–machine interface,Motor cortex},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Willett et al_2021_High-performance brain-to-text communication via handwriting.pdf}
}

@article{wilmes19,
  title = {Inhibitory Microcircuits for Top-down Plasticity of Sensory Representations},
  author = {Wilmes, Katharina Anna and Clopath, Claudia},
  year = {2019},
  month = nov,
  journal = {Nature Communications},
  volume = {10},
  number = {1},
  pages = {5055},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-019-12972-2},
  abstract = {Rewards influence plasticity of early sensory representations,~but the underlying changes in circuitry are unclear. Recent experimental findings suggest that inhibitory circuits regulate learning. In addition, inhibitory neurons are highly modulated by diverse long-range inputs, including reward signals. We, therefore, hypothesise that inhibitory plasticity plays a major role in adjusting stimulus representations. We investigate how top-down modulation by rewards interacts with local plasticity to induce long-lasting changes in circuitry. Using a computational model of layer 2/3 primary visual cortex, we demonstrate how interneuron circuits can store information about rewarded stimuli to instruct long-term changes in excitatory connectivity in the absence of further reward. In our model, stimulus-tuned somatostatin-positive interneurons develop strong connections to parvalbumin-positive interneurons during reward such that they selectively disinhibit the pyramidal layer henceforth. This triggers excitatory plasticity, leading to increased stimulus representation. We make specific testable predictions and show that this two-stage model allows for translation invariance of the learned representation.},
  copyright = {2019 The Author(s)},
  langid = {english},
  keywords = {Computational neuroscience,Learning algorithms,Network models},
  file = {C\:\\Users\\johns\\Zotero\\storage\\JFJDDUEY\\Wilmes_Clopath_2019_Inhibitory microcircuits for top-down plasticity of sensory representations.pdf}
}

@article{witt13,
  title = {Controlling the Oscillation Phase through Precisely Timed Closed-Loop Optogenetic Stimulation: A Computational Study},
  author = {Witt, Annette and Palmigiano, Agostina and Neef, Andreas and El Hady, Ahmed and Wolf, Fred and Battaglia, Demian},
  year = {2013},
  journal = {Frontiers in Neural Circuits},
  volume = {7},
  number = {April},
  pages = {1--17},
  issn = {1662-5110},
  doi = {10.3389/fncir.2013.00049},
  abstract = {Dynamic oscillatory coherence is believed to play a central role in flexible communication between brain circuits. To test this communication-through-coherence hypothesis, experimental protocols that allow a reliable control of phase-relations between neuronal populations are needed. In this modeling study, we explore the potential of closed-loop optogenetic stimulation for the control of functional interactions mediated by oscillatory coherence. The theory of non-linear oscillators predicts that the efficacy of local stimulation will depend not only on the stimulation intensity but also on its timing relative to the ongoing oscillation in the target area. Induced phase-shifts are expected to be stronger when the stimulation is applied within specific narrow phase intervals. Conversely, stimulations with the same or even stronger intensity are less effective when timed randomly. Stimulation should thus be properly phased with respect to ongoing oscillations (in order to optimally perturb them) and the timing of the stimulation onset must be determined by a real-time phase analysis of simultaneously recorded local field potentials (LFPs). Here, we introduce an electrophysiologically calibrated model of Channelrhodopsin 2 (ChR2)-induced photocurrents, based on fits holding over two decades of light intensity. Through simulations of a neural population which undergoes coherent gamma oscillations-either spontaneously or as an effect of continuous optogenetic driving-we show that precisely-timed photostimulation pulses can be used to shift the phase of oscillation, even at transduction rates smaller than 25\%. We consider then a canonic circuit with two inter-connected neural populations oscillating with gamma frequency in a phase-locked manner. We demonstrate that photostimulation pulses applied locally to a single population can induce, if precisely phased, a lasting reorganization of the phase-locking pattern and hence modify functional interactions between the two populations.},
  isbn = {1662-5110 (Electronic)\textbackslash n1662-5110 (Linking)},
  pmid = {23616748},
  keywords = {closed-loop systems,functional connectivity,modeling,optogenetic stimulation,oscillations,oscillations; functional connectivity; modeling; c,phase}
}

@article{wu20a,
  title = {Kilohertz Two-Photon Fluorescence Microscopy Imaging of Neural Activity in Vivo},
  author = {Wu, Jianglai and Liang, Yajie and Chen, Shuo and Hsu, Ching Lung and Chavarha, Mariya and Evans, Stephen W. and Shi, Dongqing and Lin, Michael Z. and Tsia, Kevin K. and Ji, Na},
  year = {2020},
  month = mar,
  journal = {Nature Methods},
  volume = {17},
  number = {3},
  pages = {287--290},
  publisher = {{Nature Publishing Group}},
  issn = {15487105},
  doi = {10.1038/s41592-020-0762-7},
  abstract = {Understanding information processing in the brain requires monitoring neuronal activity at high spatiotemporal resolution. Using an ultrafast two-photon fluorescence microscope empowered by all-optical laser scanning, we imaged neuronal activity in vivo at up to 3,000 frames per second and submicrometer spatial resolution. This imaging method enabled monitoring of both supra- and subthreshold electrical activity down to 345 {$\mu$}m below the brain surface in head-fixed awake mice.},
  pmid = {32123392},
  keywords = {Fluorescence imaging,Mouse,Multiphoton microscopy,Optical imaging,Visual system},
  file = {C\:\\Users\\johns\\Zotero\\storage\\JMUCEBFT\\Wu et al_2020_Kilohertz two-photon fluorescence microscopy imaging of neural activity in vivo.pdf}
}

@article{yamins14,
  title = {Performance-Optimized Hierarchical Models Predict Neural Responses in Higher Visual Cortex},
  author = {Yamins, Daniel L. K. and Hong, Ha and Cadieu, Charles F. and Solomon, Ethan A. and Seibert, Darren and DiCarlo, James J.},
  year = {2014},
  month = jun,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {111},
  number = {23},
  pages = {8619--8624},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.1403112111},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Yamins et al_2014_Performance-optimized hierarchical models predict neural responses in higher.pdf}
}

@article{yang19,
  title = {Task Representations in Neural Networks Trained to Perform Many Cognitive Tasks},
  author = {Yang, Guangyu Robert and Joglekar, Madhura R. and Song, H. Francis and Newsome, William T. and Wang, Xiao-Jing},
  year = {2019},
  month = feb,
  journal = {Nature Neuroscience},
  volume = {22},
  number = {2},
  pages = {297--306},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-018-0310-2},
  langid = {english},
  file = {C\:\\Users\\johns\\Zotero\\storage\\B8LB4PT5\\Yang et al. - 2019 - Task representations in neural networks trained to.pdf}
}

@article{yang20,
  title = {Closed-{{Loop Transcranial Ultrasound Stimulation}} for {{Real-Time Non-invasive Neuromodulation}} in Vivo},
  author = {Yang, Huifang and Yuan, Yi and Wang, Xingran and Li, Xin},
  year = {2020},
  month = may,
  journal = {Frontiers in Neuroscience},
  volume = {14},
  pages = {445},
  publisher = {{Frontiers Media S.A.}},
  issn = {1662453X},
  doi = {10.3389/fnins.2020.00445},
  abstract = {The closed-loop brain stimulation technique plays a key role in neural network information processing and therapies of neurological diseases. Transcranial ultrasound stimulation (TUS) is an established neuromodulation method for the neural oscillation in animals or human. All available TUS systems provide brain stimulation in an open-loop pattern. In this study, we developed a closed-loop transcranial ultrasound stimulation (CLTUS) system for real-time non-invasive neuromodulation in vivo. We used the CLTUS system to modulate the neural activities of the hippocampus of a wild-type mouse based on the phase of the theta rhythm recorded at the ultrasound-targeted location. In addition, we modulated the hippocampus of a temporal lobe epilepsy (TLE) mouse. The ultrasound stimulation increased the absolute power and reduced the relative power of the theta rhythm, which were independent of the specific phase of the theta rhythm. Compared with those of a sham stimulation, the latency of epileptic seizures was significantly increased, while the epileptic seizure duration was significantly decreased under the CLTUS. The above results indicate that the CLTUS can be used to not only modulate the neural oscillation through the theta-phase-specific manipulation of the hippocampus but also effectively inhibit the seizure of a TLE mouse in time. CLTUS has large application potentials for the understanding of the causal relationship of neural circuits as well as for timely, effective, and non-invasive therapies of neurological diseases such as epilepsy and Parkinson's disease.},
  keywords = {CLTUS,neural oscillation,neuromodulation,real-time,TLE},
  file = {C\:\\Users\\johns\\Zotero\\storage\\A539IE5N\\Yang et al_2020_Closed-Loop Transcranial Ultrasound Stimulation for Real-Time Non-invasive.pdf}
}

@article{yang21,
  title = {Modelling and Prediction of the Dynamic Responses of Large-Scale Brain Networks during Direct Electrical Stimulation},
  author = {Yang, Yuxiao and Qiao, Shaoyu and Sani, Omid G. and Sedillo, J. Isaac and Ferrentino, Breonna and Pesaran, Bijan and Shanechi, Maryam M.},
  year = {2021},
  month = feb,
  journal = {Nature Biomedical Engineering},
  volume = {5},
  number = {4},
  pages = {324--345},
  publisher = {{Nature Research}},
  issn = {2157846X},
  doi = {10.1038/s41551-020-00666-w},
  abstract = {Direct electrical stimulation can modulate the activity of brain networks for the treatment of several neurological and neuropsychiatric disorders and for restoring lost function. However, precise neuromodulation in an individual requires the accurate modelling and prediction of the effects of stimulation on the activity of their large-scale brain networks. Here, we report the development of dynamic input\textendash output models that predict multiregional dynamics of brain networks in response to temporally varying patterns of ongoing microstimulation. In experiments with two awake rhesus macaques, we show that the activities of brain networks are modulated by changes in both stimulation amplitude and frequency, that they exhibit damping and oscillatory response dynamics, and that variabilities in prediction accuracy and in estimated response strength across brain regions can be explained by an at-rest functional connectivity measure computed without stimulation. Input\textendash output models of brain dynamics may enable precise neuromodulation for the treatment of disease and facilitate the investigation of the functional organization of large-scale brain networks.},
  pmid = {33526909},
  keywords = {Biomedical engineering,Biotechnology,Computational neuroscience},
  file = {C\:\\Users\\johns\\Zotero\\storage\\R8TS9MGD\\full-text.pdf}
}

@article{yizhar11,
  title = {Optogenetics in {{Neural Systems}}},
  author = {Yizhar, Ofer and Fenno, Lief E. and Davidson, Thomas J. and Mogri, Murtaza and Deisseroth, Karl},
  year = {2011},
  month = jul,
  journal = {Neuron},
  volume = {71},
  number = {1},
  pages = {9--34},
  publisher = {{Elsevier}},
  issn = {08966273},
  doi = {10.1016/j.neuron.2011.06.004},
  abstract = {Both observational and perturbational technologies are essential for advancing the understanding of brain function and dysfunction. But while observational techniques have greatly advanced in the last century, techniques for perturbation that are matched to the speed and heterogeneity of neural systems have lagged behind. The technology of optogenetics represents a step toward addressing this disparity. Reliable and targetable single-component tools (which encompass both light sensation and effector function within a single protein) have enabled versatile new classes of investigation in the study of neural systems. Here we provide a primer on the application of optogenetics in neuroscience, focusing on the single-component tools and highlighting important problems, challenges, and technical considerations. \textcopyright{} 2011 Elsevier Inc.},
  pmid = {21745635},
  file = {C\:\\Users\\johns\\Zotero\\storage\\Y9AEBR7H\\Yizhar et al_2011_Optogenetics in Neural Systems.pdf}
}

@article{zeng22,
  title = {What Is a Cell Type and How to Define It?},
  author = {Zeng, Hongkui},
  year = {2022},
  month = jul,
  journal = {Cell},
  volume = {185},
  number = {15},
  pages = {2739--2755},
  issn = {0092-8674},
  doi = {10.1016/j.cell.2022.06.031},
  abstract = {Cell types are the basic functional units of an organism. Cell types exhibit diverse phenotypic properties at multiple levels, making them challenging to define, categorize, and understand. This review provides an overview of the basic principles of cell types rooted in evolution and development and discusses approaches to characterize and classify cell types and investigate how they contribute to the organism's function, using the mammalian brain as a primary example. I propose a roadmap toward a conceptual framework and knowledge base of cell types that will enable a deeper understanding of the dynamic changes of cellular function under healthy and diseased conditions.},
  langid = {english}
}

@article{zenke21,
  title = {The {{Remarkable Robustness}} of {{Surrogate Gradient Learning}} for {{Instilling Complex Function}} in {{Spiking Neural Networks}}},
  author = {Zenke, Friedemann and Vogels, Tim P.},
  year = {2021},
  month = mar,
  journal = {Neural Computation},
  volume = {33},
  number = {4},
  pages = {899--925},
  issn = {0899-7667},
  doi = {10.1162/neco_a_01367},
  abstract = {Brains process information in spiking neural networks. Their intricate connections shape the diverse functions these networks perform. Yet how network connectivity relates to function is poorly understood, and the functional capabilities of models of spiking networks are still rudimentary. The lack of both theoretical insight and practical algorithms to find the necessary connectivity poses a major impediment to both studying information processing in the brain and building efficient neuromorphic hardware systems. The training algorithms that solve this problem for artificial neural networks typically rely on gradient descent. But doing so in spiking networks has remained challenging due to the nondifferentiable nonlinearity of spikes. To avoid this issue, one can employ surrogate gradients to discover the required connectivity. However, the choice of a surrogate is not unique, raising the question of how its implementation influences the effectiveness of the method. Here, we use numerical simulations to systematically study how essential design parameters of surrogate gradients affect learning performance on a range of classification problems. We show that surrogate gradient learning is robust to different shapes of underlying surrogate derivatives, but the choice of the derivative's scale can substantially affect learning performance. When we combine surrogate gradients with suitable activity regularization techniques, spiking networks perform robust information processing at the sparse activity limit. Our study provides a systematic account of the remarkable robustness of surrogate gradient learning and serves as a practical guide to model functional spiking neural networks.},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Zenke_Vogels_2021_The Remarkable Robustness of Surrogate Gradient Learning for Instilling Complex.pdf}
}

@article{zhang18,
  title = {Closed-Loop All-Optical Interrogation of Neural Circuits in Vivo},
  author = {Zhang, Zihui and Russell, Lloyd E. and Packer, Adam M. and Gauld, Oliver M. and H{\"a}usser, Michael},
  year = {2018},
  month = dec,
  journal = {Nature Methods},
  volume = {15},
  number = {12},
  pages = {1037--1040},
  publisher = {{Nature Publishing Group}},
  issn = {15487105},
  doi = {10.1038/s41592-018-0183-z},
  abstract = {Understanding the causal relationship between neural activity and behavior requires the ability to perform rapid and targeted interventions in ongoing activity. Here we describe a closed-loop all-optical strategy for dynamically controlling neuronal activity patterns in awake mice. We rapidly tailored and delivered two-photon optogenetic stimulation based on online readout of activity using simultaneous two-photon imaging, thus enabling the manipulation of neural circuit activity `on the fly' during behavior.},
  pmid = {30420686},
  keywords = {Fluorescence imaging,Mouse,Neuroscience,Optogenetics},
  file = {C\:\\Users\\johns\\Zotero\\storage\\UJYEP7RU\\Zhang et al_2018_Closed-loop all-optical interrogation of neural circuits in vivo.pdf}
}

@article{zhang18b,
  title = {Theta and {{Alpha Oscillations Are Traveling Waves}} in the {{Human Neocortex}}},
  author = {Zhang, Honghui and Watrous, Andrew J. and Patel, Ansh and Jacobs, Joshua},
  year = {2018},
  month = jun,
  journal = {Neuron},
  volume = {98},
  number = {6},
  pages = {1269-1281.e4},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2018.05.019},
  abstract = {Human cognition requires the coordination of neural activity across widespread brain networks. Here, we describe a new mechanism for large-scale coordination in the human brain: traveling waves of theta and alpha oscillations. Examining direct brain recordings from neurosurgical patients performing a memory task, we found contiguous clusters of cortex in individual patients with oscillations at specific frequencies within 2 to 15~Hz. These oscillatory clusters displayed spatial phase gradients, indicating that they formed traveling waves that propagated at {$\sim$}0.25\textendash 0.75~m/s. Traveling waves were relevant behaviorally because their propagation correlated with task events and was more consistent when subjects performed the task well. Human traveling theta and alpha waves can be modeled by a network of coupled oscillators because the direction of wave propagation correlated with the spatial orientation of local frequency gradients. Our findings suggest that oscillations support brain connectivity by organizing neural processes across space and time.},
  langid = {english},
  keywords = {alpha,electrocorticography,electroencephalography,memory,oscillation,theta,traveling wave},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Zhang et al_2018_Theta and Alpha Oscillations Are Traveling Waves in the Human Neocortex.pdf}
}

@article{zhang19,
  title = {Sub-Second Dynamics of Theta-Gamma Coupling in Hippocampal {{CA1}}},
  author = {Zhang, Lu and Lee, John and Rozell, Christopher and Singer, Annabelle C.},
  year = {2019},
  month = jul,
  journal = {eLife},
  volume = {8},
  publisher = {{eLife Sciences Publications Ltd}},
  issn = {2050084X},
  doi = {10.7554/eLife.44320},
  abstract = {Oscillatory brain activity reflects different internal brain states including neurons' excitatory state and synchrony among neurons. However, characterizing these states is complicated by the fact that different oscillations are often coupled, such as gamma oscillations nested in theta in the hippocampus, and changes in coupling are thought to reflect distinct states. Here, we describe a new method to separate single oscillatory cycles into distinct states based on frequency and phase coupling. Using this method, we identified four theta-gamma coupling states in rat hippocampal CA1. These states differed in abundance across behaviors, phase synchrony with other hippocampal subregions, and neural coding properties suggesting that these states are functionally distinct. We captured cycle-to-cycle changes in oscillatory coupling states and found frequent switching between theta-gamma states showing that the hippocampus rapidly shifts between different functional states. This method provides a new approach to investigate oscillatory brain dynamics broadly.},
  pmid = {31355744},
  file = {C\:\\Users\\johns\\Zotero\\storage\\A76XCE7X\\full-text.pdf}
}

@article{zhang21,
  title = {Bounding {{Causal Effects}} on {{Continuous Outcome}}},
  author = {Zhang, Junzhe and Bareinboim, Elias},
  year = {2021},
  month = may,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {35},
  number = {13},
  pages = {12207--12215},
  issn = {2374-3468},
  doi = {10.1609/aaai.v35i13.17449},
  abstract = {We investigate the problem of bounding causal effects from experimental studies in which treatment assignment is randomized but the subject compliance is imperfect. It is well known that under such conditions, the actual causal effects are not point-identifiable due to uncontrollable unobserved confounding. In their seminal work, Balke and Pearl (1994) derived the tightest bounds over the causal effects in this settings by employing an algebra program to derive analytic expressions. However, Pearl's approach assumes the primary outcome to be discrete and finite. Solving such a program could be intractable when high-dimensional context variables are present. In this paper, we present novel non-parametric methods to bound causal effects on the continuous outcome from studies with imperfect compliance. These bounds could be generalized to settings with a high-dimensional context.},
  copyright = {Copyright (c) 2021 Association for the Advancement of Artificial Intelligence},
  langid = {english},
  keywords = {Graphical Models},
  file = {C\:\\Users\\johns\\OneDrive - Georgia Institute of Technology\\zotero\\Zhang_Bareinboim_2021_Bounding Causal Effects on Continuous Outcome.pdf}
}

@misc{zotero-4215,
  title = {{{2P}} Optogenetics : Simulation and Modeling for Optimized Thermal Dissipation and Current Integration - {{TEL}} - {{Th\`eses}} En Ligne},
  howpublished = {https://tel.archives-ouvertes.fr/tel-02469061/}
}

@misc{zotero-4372,
  title = {New Neural Activity Patterns Emerge with Long-Term Learning | {{PNAS}}},
  howpublished = {https://www.pnas.org/doi/full/10.1073/pnas.1820296116}
}

@misc{zotero-4407,
  title = {‪{{The}} Neuroconnectionist Research Programme‬},
  abstract = {‪A Doerig, R Sommers, K Seeliger, B Richards, J Ismael, G Lindsay, K Kording, T Konkle, MAJ Van Gerven, N Kriegeskorte\ldots ‬, ‪arXiv preprint arXiv:2209.03718, 2022‬},
  howpublished = {https://scholar.google.com/citations?view\_op=view\_citation\&hl=en\&user=YA6DPIcAAAAJ\&sortby=pubdate\&citation\_for\_view=YA6DPIcAAAAJ:-f6ydRqryjwC}
}
